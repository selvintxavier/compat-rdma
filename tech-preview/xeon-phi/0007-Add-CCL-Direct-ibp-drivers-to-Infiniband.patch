xeon-phi: Add CCL-Direct (ibp) drivers to Infiniband

This includes the base ibp server module as well as
the server modules for sa and cm
---
diff -ruN a6/drivers/infiniband/ibp/cm/cm_ibp_abi.h a7/drivers/infiniband/ibp/cm/cm_ibp_abi.h
--- a6/drivers/infiniband/ibp/cm/cm_ibp_abi.h	1969-12-31 16:00:00.000000000 -0800
+++ a7/drivers/infiniband/ibp/cm/cm_ibp_abi.h	2015-09-10 09:33:35.322900652 -0700
@@ -0,0 +1,399 @@
+/*
+ * Copyright (c) 2011-2013 Intel Corporation. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *	copyright notice, this list of conditions and the following
+ *	disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *	copyright notice, this list of conditions and the following
+ *	disclaimer in the documentation and/or other materials
+ *	provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#ifndef CM_IBP_ABI_H
+#define CM_IBP_ABI_H
+
+#include <linux/types.h>
+#include <rdma/ib_verbs.h>
+#include <rdma/ib_cm.h>
+
+/* Increment this value if any changes break compatibility. */
+#define IBP_CM_ABI_VERSION	1
+
+/*
+ * Make sure that all structs defined in this file are laid out to pack
+ * the same way on different architectures to avoid incompatibility.
+ *
+ * Specifically:
+ *  - Do not use pointer types -- pass pointers in a u64 instead.
+ *  - Make sure that any structure larger than 4 bytes is padded
+ *    to a multiple of 8 bytes; otherwise the structure size may
+ *    be different between architectures.
+ */
+
+struct ibp_event_msg {
+	struct ibp_msg_header		header;
+	u64				length;
+	u8				event[0];
+};
+
+
+struct ibp_sa_path_rec {
+	__be64				service_id;
+	u64				dgid_prefix;
+	u64				dgid_id;
+	u64				sgid_prefix;
+	u64				sgid_id;
+	__be16				dlid;
+	__be16				slid;
+	u32				raw_traffic;
+	__be32				flow_label;
+	u8				hop_limit;
+	u8				traffic_class;
+	u32				reversible;
+	u8				numb_path;
+	__be16				pkey;
+	__be16				qos_class;
+	u8				sl;
+	u8				mtu_selector;
+	u8				mtu;
+	u8				rate_selector;
+	u8				rate;
+	u8				packet_life_time_selector;
+	u8				packet_life_time;
+	u8				preference;
+};
+
+struct ibp_create_cm_id_cmd {
+	struct ibp_msg_header		header;
+	u64				device;
+};
+
+struct ibp_create_cm_id_resp {
+	u64				ibp_cm_id;
+	__be64				service_id;
+	__be64				service_mask;
+	__be32				local_id;
+	__be32				remote_id;
+	u32				remote_cm_qpn;
+	u32				filler;
+};
+
+struct ibp_destroy_cm_id_cmd {
+	struct ibp_msg_header		header;
+	u64				ibp_cm_id;
+};
+
+struct ibp_cm_listen_cmd {
+	struct ibp_msg_header		header;
+	u64				ibp_cm_id;
+	__be64				service_id;
+	__be64				service_mask;
+	u64				null_comp_data;
+	struct ib_cm_compare_data	compare_data;
+};
+
+struct ibp_send_cm_req_cmd {
+	struct ibp_msg_header		header;
+	u64				ibp_cm_id;
+	struct ibp_sa_path_rec		primary_path;
+	struct ibp_sa_path_rec		alternate_path;
+	__be64				service_id;
+	u32				qp_num;
+	enum ib_qp_type			qp_type;
+	u32				starting_psn;
+	u8				peer_to_peer;
+	u8				responder_resources;
+	u8				initiator_depth;
+	u8				remote_cm_response_timeout;
+	u8				flow_control;
+	u8				local_cm_response_timeout;
+	u8				retry_count;
+	u8				rnr_retry_count;
+	u8				max_cm_retries;
+	u8				srq;
+	u8				private_data_len;
+	char				private_data[0];
+};
+
+struct ibp_send_cm_rep_cmd {
+	struct ibp_msg_header		header;
+	u64				ibp_cm_id;
+	u32				qp_num;
+	u32				starting_psn;
+	u8				responder_resources;
+	u8				initiator_depth;
+	u8				failover_accepted;
+	u8				flow_control;
+	u8				rnr_retry_count;
+	u8				srq;
+	u8				private_data_len;
+	char				private_data[0];
+};
+
+struct ibp_send_cm_rtu_cmd {
+	struct ibp_msg_header		header;
+	u64				ibp_cm_id;
+	u8				private_data_len;
+	char				private_data[0];
+};
+
+struct ibp_send_cm_dreq_cmd {
+	struct ibp_msg_header		header;
+	u64				ibp_cm_id;
+	u8				private_data_len;
+	char				private_data[0];
+};
+
+struct ibp_send_cm_drep_cmd {
+	struct ibp_msg_header		header;
+	u64				ibp_cm_id;
+	u8				private_data_len;
+	char				private_data[0];
+};
+
+struct ibp_send_cm_rej_cmd {
+	struct ibp_msg_header		header;
+	u64				ibp_cm_id;
+	u64				reason;
+	u8				private_data_len;
+	u8				ari_length;
+	char				data[0];
+};
+
+struct ibp_send_cm_mra_cmd {
+	struct ibp_msg_header		header;
+	u64				ibp_cm_id;
+	u8				service_timeout;
+	u8				private_data_len;
+	char				private_data[0];
+};
+
+struct ibp_send_cm_lap_cmd {
+	struct ibp_msg_header		header;
+	u64				ibp_cm_id;
+	struct ibp_sa_path_rec		alternate_path;
+	u8				private_data_len;
+	char				private_data[0];
+};
+
+struct ibp_send_cm_apr_cmd {
+	struct ibp_msg_header		header;
+	u64				ibp_cm_id;
+	u64				status;
+	u8				private_data_len;
+	u8				info_length;
+	char				data[0];
+};
+
+struct ibp_send_cm_sidr_req_cmd {
+	struct ibp_msg_header		header;
+	u64				ibp_cm_id;
+	struct ibp_sa_path_rec		path;
+	__be64				service_id;
+	int				timeout_ms;
+	u8				max_cm_retries;
+	u8				private_data_len;
+	char				private_data[0];
+};
+
+struct ibp_send_cm_sidr_rep_cmd {
+	struct ibp_msg_header		header;
+	u64				ibp_cm_id;
+	u32				qp_num;
+	u32				qkey;
+	u64				status;
+	u8				info_length;
+	u8				private_data_len;
+	char				data[0];
+};
+
+struct ibp_cm_notify_cmd {
+	struct ibp_msg_header		header;
+	u64				ibp_cm_id;
+	u64				event;
+};
+
+struct ibp_cm_init_qp_attr_cmd {
+	struct ibp_msg_header		header;
+	u64				ibp_cm_id;
+	u64				qp_attr_state;
+};
+
+struct ibp_cm_init_qp_attr_resp {
+	u64				qp_attr_mask;
+	u64				qp_access_flags;
+	u64				qp_state;
+	u64				cur_qp_state;
+	u64				path_mtu;
+	u64				path_mig_state;
+	u32				qkey;
+	u32				rq_psn;
+	u32				sq_psn;
+	u64				dest_qp_num;
+
+	u32				cap_max_send_wr;
+	u32				cap_max_recv_wr;
+	u32				cap_max_send_sge;
+	u32				cap_max_recv_sge;
+	u32				cap_max_inline_data;
+
+	u64				ah_attr_grh_dgid_subnet_prefix;
+	u64				ah_attr_grh_dgid_interface_id;
+	u32				ah_attr_grh_flow_label;
+	u8				ah_attr_grh_sgid_index;
+	u8				ah_attr_grh_hop_limit;
+	u8				ah_attr_grh_traffic_class;
+	u16				ah_attr_dlid;
+	u8				ah_attr_sl;
+	u8				ah_attr_src_path_bits;
+	u8				ah_attr_static_rate;
+	u8				ah_attr_ah_flags;
+	u8				ah_attr_port_num;
+
+	u64				alt_attr_grh_dgid_subnet_prefix;
+	u64				alt_attr_grh_dgid_interface_id;
+	u32				alt_attr_grh_flow_label;
+	u8				alt_attr_grh_sgid_index;
+	u8				alt_attr_grh_hop_limit;
+	u8				alt_attr_grh_traffic_class;
+	u16				alt_attr_dlid;
+	u8				alt_attr_sl;
+	u8				alt_attr_src_path_bits;
+	u8				alt_attr_static_rate;
+	u8				alt_attr_ah_flags;
+	u8				alt_attr_port_num;
+
+	u16				pkey_index;
+	u16				alt_pkey_index;
+	u8				en_sqd_async_notify;
+	u8				sq_draining;
+	u8				max_rd_atomic;
+	u8				max_dest_rd_atomic;
+	u8				min_rnr_timer;
+	u8				port_num;
+	u8				timeout;
+	u8				retry_cnt;
+	u8				rnr_retry;
+	u8				alt_port_num;
+	u8				alt_timeout;
+
+};
+
+struct ibp_cm_req_event_resp {
+	struct ibp_sa_path_rec		primary_path;
+	struct ibp_sa_path_rec		alternate_path;
+	u64				listen_id;
+	__be64				remote_ca_guid;
+	__u32				remote_qkey;
+	__u32				remote_qpn;
+	__u32				qp_type;
+	__u32				starting_psn;
+	__u8				responder_resources;
+	__u8				initiator_depth;
+	__u8				local_cm_response_timeout;
+	__u8				flow_control;
+	__u8				remote_cm_response_timeout;
+	__u8				retry_count;
+	__u8				rnr_retry_count;
+	__u8				srq;
+	__u8				port;
+	__u8				reserved[7];
+};
+
+struct ibp_cm_rep_event_resp {
+	__be64				remote_ca_guid;
+	__u32				remote_qkey;
+	__u32				remote_qpn;
+	__u32				starting_psn;
+	__u8				responder_resources;
+	__u8				initiator_depth;
+	__u8				target_ack_delay;
+	__u8				failover_accepted;
+	__u8				flow_control;
+	__u8				rnr_retry_count;
+	__u8				srq;
+	__u8				reserved[5];
+};
+
+struct ibp_cm_rej_event_resp {
+	__u32				reason;
+};
+
+struct ibp_cm_mra_event_resp {
+	__u8				timeout;
+	__u8				reserved[3];
+};
+
+struct ibp_cm_lap_event_resp {
+	struct ibp_sa_path_rec		path;
+};
+
+struct ibp_cm_rtu_event_resp {
+	__u32				status;
+	__be32				local_id;
+	__be32				remote_id;
+};
+
+struct ibp_cm_apr_event_resp {
+	__u32				status;
+};
+
+struct ibp_cm_sidr_req_event_resp {
+	u64				listen_id;
+	__u16				pkey;
+	__u8				port;
+	__u8				reserved;
+};
+
+struct ibp_cm_sidr_rep_event_resp {
+	__u32				status;
+	__u32				qkey;
+	__u32				qpn;
+};
+
+struct ibp_cm_event {
+	enum ib_event_type		event_type;
+	union {
+		struct ibp_cm_req_event_resp		req_resp;
+		struct ibp_cm_rep_event_resp		rep_resp;
+		struct ibp_cm_rej_event_resp		rej_resp;
+		struct ibp_cm_rtu_event_resp		rtu_resp;
+		struct ibp_cm_mra_event_resp		mra_resp;
+		struct ibp_cm_lap_event_resp		lap_resp;
+		struct ibp_cm_apr_event_resp		apr_resp;
+		struct ibp_cm_sidr_req_event_resp	sidr_req_resp;
+		struct ibp_cm_sidr_rep_event_resp	sidr_rep_resp;
+
+		__u32			send_status;
+	} u;
+
+	u64				event_cm_id;
+	u64				ibp_cm_id;
+	u64				data_length;
+	u64				info_length;
+
+	u8				data[0];
+};
+
+#endif /* CM_IBP_ABI_H */
diff -ruN a6/drivers/infiniband/ibp/cm/cm_server_msg.c a7/drivers/infiniband/ibp/cm/cm_server_msg.c
--- a6/drivers/infiniband/ibp/cm/cm_server_msg.c	1969-12-31 16:00:00.000000000 -0800
+++ a7/drivers/infiniband/ibp/cm/cm_server_msg.c	2015-09-10 09:33:35.324900603 -0700
@@ -0,0 +1,1058 @@
+/*
+ * Copyright (c) 2011-2013 Intel Corporation. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *     - Redistributions of source code must retain the above
+ *	 copyright notice, this list of conditions and the following
+ *	 disclaimer.
+ *
+ *     - Redistributions in binary form must reproduce the above
+ *	 copyright notice, this list of conditions and the following
+ *	 disclaimer in the documentation and/or other materials
+ *	 provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include "server.h"
+
+LIST_HEAD(cm_entry_list);
+
+void ibp_copy_sa_path_rec(struct ibp_sa_path_rec *a, struct ib_sa_path_rec *b)
+{
+	/*Copy ibp_sa_path_rec to ib_sa_path_rec*/
+	b->service_id			= a->service_id;
+	b->dgid.global.subnet_prefix	= a->dgid_prefix;
+	b->dgid.global.interface_id	= a->dgid_id;
+	b->sgid.global.subnet_prefix	= a->sgid_prefix;
+	b->sgid.global.interface_id	= a->sgid_id;
+	b->dlid				= a->dlid;
+	b->slid				= a->slid;
+	b->raw_traffic			= a->raw_traffic;
+	b->flow_label			= a->flow_label;
+	b->hop_limit			= a->hop_limit;
+	b->traffic_class		= a->traffic_class;
+	b->reversible			= a->reversible;
+	b->numb_path			= a->numb_path;
+	b->pkey				= a->pkey;
+	b->qos_class			= a->qos_class;
+	b->sl				= a->sl;
+	b->mtu_selector			= a->mtu_selector;
+	b->mtu				= a->mtu;
+	b->rate_selector		= a->rate_selector;
+	b->rate				= a->rate;
+	b->packet_life_time_selector	= a->packet_life_time_selector;
+	b->packet_life_time		= a->packet_life_time;
+	b->preference			= a->preference;
+}
+
+void ib_copy_sa_path_rec(struct ibp_sa_path_rec *a, struct ib_sa_path_rec *b)
+{
+	/*Copy ib_sa_path_rec to ibp_sa_path_rec*/
+	a->service_id			= b->service_id;
+	a->dgid_prefix			= b->dgid.global.subnet_prefix;
+	a->dgid_id			= b->dgid.global.interface_id;
+	a->sgid_prefix			= b->sgid.global.subnet_prefix;
+	a->sgid_id			= b->sgid.global.interface_id;
+	a->dlid				= b->dlid;
+	a->slid				= b->slid;
+	a->raw_traffic			= b->raw_traffic;
+	a->flow_label			= b->flow_label;
+	a->hop_limit			= b->hop_limit;
+	a->traffic_class		= b->traffic_class;
+	a->reversible			= b->reversible;
+	a->numb_path			= b->numb_path;
+	a->pkey				= b->pkey;
+	a->qos_class			= b->qos_class;
+	a->sl				= b->sl;
+	a->mtu_selector			= b->mtu_selector;
+	a->mtu				= b->mtu;
+	a->rate_selector		= b->rate_selector;
+	a->rate				= b->rate;
+	a->packet_life_time_selector	= b->packet_life_time_selector;
+	a->packet_life_time		= b->packet_life_time;
+	a->preference			= b->preference;
+}
+
+void cleanup_cm_entry_list(void)
+{
+	struct cm_entry				*entry;
+	struct cm_entry				*next;
+
+	down_write(&list_rwsem);
+
+	list_for_each_entry_safe(entry, next, &cm_entry_list, list)
+		kfree(entry);
+
+	up_write(&list_rwsem);
+}
+
+static struct cm_entry *find_cm_entry(struct ib_cm_id *cm_id)
+{
+	struct cm_entry				*entry;
+
+	down_read(&list_rwsem);
+
+	list_for_each_entry(entry, &cm_entry_list, list)
+		if (entry->cm_id == cm_id)
+			goto out;
+
+	print_err("Could not find cm id %p\n", cm_id);
+	entry = NULL;
+
+out:
+	up_read(&list_rwsem);
+
+	return entry;
+}
+
+/* find the entry id for the listen cm id so we can add the new cm id
+ * that is being accepted to the list so it can be found on future events
+ */
+static struct cm_entry *find_cm_entry_and_add(struct ib_cm_id *listen_id,
+					      struct ib_cm_id *cm_id)
+{
+	struct cm_entry				*entry;
+	struct cm_entry				*listen_entry;
+
+	listen_entry = find_cm_entry(listen_id);
+	if (!listen_entry) {
+		print_err("Could not find listen id %p\n", listen_id);
+		return NULL;
+	}
+
+	entry = kzalloc(sizeof(struct cm_entry), GFP_KERNEL);
+	if (!entry) {
+		print_err("kzalloc failed\n");
+		return NULL;
+	}
+
+	entry->client = listen_entry->client;
+	entry->cm_id = cm_id;
+
+	down_write(&list_rwsem);
+	list_add(&entry->list, &cm_entry_list);
+	up_write(&list_rwsem);
+
+	return listen_entry;
+}
+
+static void ibp_event_req_get(struct ibp_cm_req_event_resp *proxy_req,
+			      struct ib_cm_req_event_param *req)
+
+{
+	proxy_req->listen_id		      = (u64) req->listen_id;
+	proxy_req->remote_ca_guid	      = req->remote_ca_guid;
+	proxy_req->remote_qkey		      = req->remote_qkey;
+	proxy_req->remote_qpn		      = req->remote_qpn;
+	proxy_req->qp_type		      = req->qp_type;
+	proxy_req->starting_psn		      = req->starting_psn;
+	proxy_req->responder_resources	      = req->responder_resources;
+	proxy_req->initiator_depth	      = req->initiator_depth;
+	proxy_req->local_cm_response_timeout  = req->local_cm_response_timeout;
+	proxy_req->flow_control		      = req->flow_control;
+	proxy_req->remote_cm_response_timeout = req->remote_cm_response_timeout;
+	proxy_req->retry_count		      = req->retry_count;
+	proxy_req->rnr_retry_count	      = req->rnr_retry_count;
+	proxy_req->srq			      = req->srq;
+	proxy_req->port			      = req->port;
+	ib_copy_sa_path_rec(&proxy_req->primary_path, req->primary_path);
+	if (req->alternate_path)
+		ib_copy_sa_path_rec(&proxy_req->alternate_path,
+				     req->alternate_path);
+}
+
+static void ibp_event_rep_get(struct ibp_cm_rep_event_resp *proxy_rep,
+			      struct ib_cm_rep_event_param *rep)
+{
+	proxy_rep->remote_ca_guid	= rep->remote_ca_guid;
+	proxy_rep->remote_qkey		= rep->remote_qkey;
+	proxy_rep->remote_qpn		= rep->remote_qpn;
+	proxy_rep->starting_psn		= rep->starting_psn;
+	proxy_rep->responder_resources	= rep->responder_resources;
+	proxy_rep->initiator_depth	= rep->initiator_depth;
+	proxy_rep->target_ack_delay	= rep->target_ack_delay;
+	proxy_rep->failover_accepted	= rep->failover_accepted;
+	proxy_rep->flow_control		= rep->flow_control;
+	proxy_rep->rnr_retry_count	= rep->rnr_retry_count;
+	proxy_rep->srq			= rep->srq;
+}
+
+static
+void ibp_event_sidr_rep_get(struct ibp_cm_sidr_rep_event_resp *proxy_resp,
+			    struct ib_cm_sidr_rep_event_param *rep)
+{
+	proxy_resp->status = rep->status;
+	proxy_resp->qkey   = rep->qkey;
+	proxy_resp->qpn    = rep->qpn;
+}
+
+static void ibp_event(struct work_struct *work)
+{
+	struct ibp_event			*event_work;
+	struct ibp_event_msg			*msg;
+	int					msg_len;
+	int					event_len;
+
+	print_trace("in\n");
+
+	event_work = (struct ibp_event *) work;
+
+	event_len = event_work->event.data_length +
+		    event_work->event.info_length +
+		    sizeof(struct ibp_cm_event);
+
+	msg_len = sizeof(struct ibp_event_msg) + event_len;
+
+	msg = kzalloc(msg_len, GFP_KERNEL);
+	if (!msg) {
+		print_err("kzmalloc failed\n");
+		goto err;
+	}
+
+	memcpy(msg->event, &(event_work->event), event_len);
+	msg->length = event_len;
+
+	IBP_INIT_MSG(NULL, msg, msg_len, IBP_EVENT);
+
+	ibp_send(event_work->client->ep, msg, msg_len);
+err:
+	kfree(event_work);
+}
+
+static int ibp_event_handler(struct ib_cm_id *cm_id,
+			     struct ib_cm_event *ib_cm_event)
+{
+	struct ibp_event			*event_work;
+	struct ibp_client			*client;
+	struct cm_entry				*entry;
+	void					*info = NULL;
+	int					info_length = 0;
+	int					data_length = 0;
+
+	print_trace("in\n");
+
+	switch (ib_cm_event->event) {
+	case IB_CM_REQ_RECEIVED:
+		data_length = IB_CM_REQ_PRIVATE_DATA_SIZE;
+		break;
+	case IB_CM_REP_RECEIVED:
+		data_length = IB_CM_REP_PRIVATE_DATA_SIZE;
+		break;
+	case IB_CM_RTU_RECEIVED:
+		data_length = IB_CM_RTU_PRIVATE_DATA_SIZE;
+		break;
+	case IB_CM_DREQ_RECEIVED:
+		data_length = IB_CM_DREQ_PRIVATE_DATA_SIZE;
+		break;
+	case IB_CM_DREP_RECEIVED:
+		data_length = IB_CM_DREP_PRIVATE_DATA_SIZE;
+		break;
+	case IB_CM_MRA_RECEIVED:
+		data_length = IB_CM_MRA_PRIVATE_DATA_SIZE;
+		break;
+	case IB_CM_REJ_RECEIVED:
+		data_length = IB_CM_REJ_PRIVATE_DATA_SIZE;
+		info_length = ib_cm_event->param.rej_rcvd.ari_length;
+		break;
+	case IB_CM_LAP_RECEIVED:
+		data_length = IB_CM_LAP_PRIVATE_DATA_SIZE;
+		break;
+	case IB_CM_APR_RECEIVED:
+		data_length = IB_CM_APR_PRIVATE_DATA_SIZE;
+		info_length = ib_cm_event->param.apr_rcvd.info_len;
+		break;
+	case IB_CM_SIDR_REQ_RECEIVED:
+		data_length = IB_CM_SIDR_REQ_PRIVATE_DATA_SIZE;
+		break;
+	case IB_CM_SIDR_REP_RECEIVED:
+		data_length = IB_CM_SIDR_REP_PRIVATE_DATA_SIZE;
+		info_length = ib_cm_event->param.sidr_rep_rcvd.info_len;
+		break;
+	default:
+		break;
+	}
+	event_work = kzalloc((sizeof(struct ibp_event)) +
+			     data_length + info_length, GFP_KERNEL);
+	if (!event_work) {
+		print_err("kzalloc failed\n");
+		return -ENOMEM;
+	}
+
+	if (ib_cm_event->event == IB_CM_REQ_RECEIVED) {
+		struct ib_cm_req_event_param *param;
+		param = &ib_cm_event->param.req_rcvd;
+		entry = find_cm_entry_and_add(param->listen_id, cm_id);
+	} else if (ib_cm_event->event == IB_CM_SIDR_REQ_RECEIVED) {
+		struct ib_cm_sidr_req_event_param *param;
+		param = &ib_cm_event->param.sidr_req_rcvd;
+		entry = find_cm_entry_and_add(param->listen_id, cm_id);
+	} else
+		entry = find_cm_entry(cm_id);
+
+	if (!entry) {
+		kfree(event_work);
+		return -EINVAL;
+	}
+
+	client = entry->client;
+
+	event_work->client		= client;
+	event_work->event.ibp_cm_id	= (u64) entry->cm_id;
+	event_work->event.event_cm_id	= (u64) cm_id;
+	event_work->event.event_type	= ib_cm_event->event;
+	event_work->event.data_length	= data_length;
+	event_work->event.info_length	= info_length;
+
+	/* parse and copy the proper event */
+	switch (ib_cm_event->event) {
+	case IB_CM_REQ_RECEIVED:
+		print_dbg("IB_CM_REQ_RECEIVED (%d)\n", ib_cm_event->event);
+		ibp_event_req_get(&event_work->event.u.req_resp,
+				  &ib_cm_event->param.req_rcvd);
+		break;
+	case IB_CM_REP_RECEIVED:
+		print_dbg("IB_CM_REP_RECEIVED (%d)\n", ib_cm_event->event);
+		ibp_event_rep_get(&event_work->event.u.rep_resp,
+				  &ib_cm_event->param.rep_rcvd);
+		break;
+	case IB_CM_MRA_RECEIVED:
+		print_dbg("IB_CM_MRA_RECEIVED (%d)\n", ib_cm_event->event);
+		event_work->event.u.mra_resp.timeout =
+			ib_cm_event->param.mra_rcvd.service_timeout;
+		break;
+	case IB_CM_REJ_RECEIVED:
+		print_dbg("IB_CM_REJ_RECEIVED (%d)\n", ib_cm_event->event);
+		event_work->event.u.rej_resp.reason =
+			ib_cm_event->param.rej_rcvd.reason;
+		info = ib_cm_event->param.rej_rcvd.ari;
+		break;
+	case IB_CM_RTU_RECEIVED:
+		print_dbg("IB_CM_RTU_RECEIVED (%d)\n", ib_cm_event->event);
+		event_work->event.u.rtu_resp.status =
+			ib_cm_event->param.send_status;
+		event_work->event.u.rtu_resp.local_id = cm_id->local_id;
+		event_work->event.u.rtu_resp.remote_id = cm_id->remote_id;
+		break;
+	case IB_CM_LAP_RECEIVED:
+		print_dbg("IB_CM_LAP_RECEIVED (%d)\n", ib_cm_event->event);
+		ib_copy_sa_path_rec(&event_work->event.u.lap_resp.path,
+				    ib_cm_event->param.lap_rcvd.alternate_path);
+		break;
+	case IB_CM_APR_RECEIVED:
+		print_dbg("IB_CM_APR_RECEIVED (%d)\n", ib_cm_event->event);
+		event_work->event.u.apr_resp.status =
+			ib_cm_event->param.apr_rcvd.ap_status;
+		info = ib_cm_event->param.apr_rcvd.apr_info;
+		break;
+	case IB_CM_SIDR_REQ_RECEIVED:
+		print_dbg("IB_CM_SIDR_REQ_RECEIVED (%d)\n",
+			    ib_cm_event->event);
+		event_work->event.u.sidr_req_resp.listen_id =
+			(u64) ib_cm_event->param.sidr_req_rcvd.listen_id;
+		event_work->event.u.sidr_req_resp.pkey =
+			ib_cm_event->param.sidr_req_rcvd.pkey;
+		event_work->event.u.sidr_req_resp.port =
+			ib_cm_event->param.sidr_req_rcvd.port;
+		break;
+	case IB_CM_SIDR_REP_RECEIVED:
+		print_dbg("IB_CM_SIDR_REP_RECEIVED (%d)\n",
+			    ib_cm_event->event);
+		ibp_event_sidr_rep_get(&event_work->event.u.sidr_rep_resp,
+				       &ib_cm_event->param.sidr_rep_rcvd);
+		info = ib_cm_event->param.sidr_rep_rcvd.info;
+		break;
+	case IB_CM_TIMEWAIT_EXIT:
+	case IB_CM_REQ_ERROR:
+	case IB_CM_REP_ERROR:
+	case IB_CM_DREQ_ERROR:
+	case IB_CM_LAP_ERROR:
+	case IB_CM_SIDR_REQ_ERROR:
+		print_dbg("IB_CM_..._ERROR (%d)\n", ib_cm_event->event);
+		event_work->event.u.send_status =
+			ib_cm_event->param.send_status;
+		break;
+
+	case IB_CM_USER_ESTABLISHED:
+		print_dbg("IB_CM_USER_ESTABLISHED (%d)\n",
+			    ib_cm_event->event);
+		event_work->event.u.send_status =
+			ib_cm_event->param.send_status;
+		break;
+	case IB_CM_DREQ_RECEIVED:
+		print_dbg("IB_CM_DREQ_RECEIVED (%d)\n", ib_cm_event->event);
+		event_work->event.u.send_status =
+			ib_cm_event->param.send_status;
+		break;
+	case IB_CM_DREP_RECEIVED:
+		print_dbg("IB_CM_DREP_RECEIVED (%d)\n", ib_cm_event->event);
+		event_work->event.u.send_status =
+			ib_cm_event->param.send_status;
+		break;
+	default:
+		print_dbg("event not handled %d\n", ib_cm_event->event);
+		break;
+	}
+
+	if (data_length)
+		memcpy(event_work->event.data, ib_cm_event->private_data,
+		       data_length);
+
+	if (info_length)
+		memcpy(event_work->event.data + data_length, info, info_length);
+
+	INIT_WORK(&event_work->work, ibp_event);
+	queue_work(client->workqueue, &event_work->work);
+
+	return 0;
+}
+
+int ibp_cmd_create_cm_id(struct ibp_client *client, struct ibp_msg_header *hdr)
+{
+	struct ibp_response_msg			*msg;
+	struct ibp_create_cm_id_cmd		*cmd;
+	struct ibp_create_cm_id_resp		*resp;
+	struct ib_device			*ib_device;
+	struct ib_cm_id				*cm_id = NULL;
+	struct cm_entry				*entry;
+	size_t					len;
+	int					status = 0;
+	int					ret;
+
+	print_trace("in\n");
+
+	cmd	= (struct ibp_create_cm_id_cmd *) hdr;
+	ib_device = (struct ib_device *) cmd->device;
+	msg	= (struct ibp_response_msg *) client->tx_buf;
+	len	= sizeof(*msg);
+
+	entry = kzalloc(sizeof(struct cm_entry), GFP_KERNEL);
+	if (!entry) {
+		print_err("kzalloc failed\n");
+		status = -ENOMEM;
+		goto send_resp;
+	}
+
+	cm_id = ib_create_cm_id(ib_device,
+				(ib_cm_handler) ibp_event_handler,
+				NULL);
+	if (IS_ERR(cm_id)) {
+		status = PTR_ERR(cm_id);
+		print_err("ib_create_cm_id returned %d\n", status);
+		goto send_resp;
+	}
+
+	len += sizeof(*resp);
+
+	resp = (struct ibp_create_cm_id_resp *) msg->data;
+
+	resp->ibp_cm_id		= (u64) cm_id;
+	resp->service_id	= cm_id->service_id;
+	resp->service_mask	= cm_id->service_mask;
+	resp->local_id		= cm_id->local_id;
+	resp->remote_id		= cm_id->remote_id;
+	resp->remote_cm_qpn	= cm_id->remote_cm_qpn;
+
+send_resp:
+	IBP_INIT_RESP(cm_id, msg, len, IBP_RESPONSE, hdr->request, status);
+
+	ret = ibp_send(client->ep, msg, len);
+	if (ret) {
+		kfree(entry);
+		print_err("ibp_send returned %d\n", ret);
+		return ret;
+	}
+	if (status) {
+		kfree(entry);
+		return status;
+	}
+
+	entry->client = client;
+	entry->cm_id = cm_id;
+
+	down_write(&list_rwsem);
+	list_add(&entry->list, &cm_entry_list);
+	up_write(&list_rwsem);
+
+	return 0;
+}
+
+int ibp_cmd_destroy_cm_id(struct ibp_client *client, struct ibp_msg_header *hdr)
+{
+	struct ibp_response_msg			*msg;
+	struct ibp_destroy_cm_id_cmd		*cmd;
+	struct ib_cm_id				*cm_id;
+	struct cm_entry				*entry;
+	size_t					len;
+	int					ret = 0;
+
+	print_trace("in\n");
+
+	cmd	= (struct ibp_destroy_cm_id_cmd *) hdr;
+	cm_id	= (struct ib_cm_id *) cmd->ibp_cm_id;
+	msg	= (struct ibp_response_msg *) client->tx_buf;
+	len	= sizeof(*msg);
+
+	entry = find_cm_entry(cm_id);
+	if (!entry)
+		goto send_resp;
+
+	down_write(&list_rwsem);
+	list_del(&entry->list);
+	up_write(&list_rwsem);
+
+	kfree(entry);
+
+	ib_destroy_cm_id(cm_id);
+
+send_resp:
+	IBP_INIT_RESP(cm_id, msg, len, IBP_RESPONSE, hdr->request, ret);
+	return ibp_send(client->ep, msg, len);
+}
+
+int ibp_cmd_cm_listen(struct ibp_client *client, struct ibp_msg_header *hdr)
+{
+	struct ibp_response_msg			*msg;
+	struct ibp_cm_listen_cmd		*cmd;
+	struct ib_cm_id				*cm_id;
+	struct ib_cm_compare_data		*data = NULL;
+	size_t					len;
+	int					ret;
+
+	print_trace("in\n");
+
+	cmd	= (struct ibp_cm_listen_cmd *) hdr;
+	cm_id	= (struct ib_cm_id *) cmd->ibp_cm_id;
+	msg	= (struct ibp_response_msg *) client->tx_buf;
+	len	= sizeof(*msg);
+
+	if (!cmd->null_comp_data)
+		data = &(cmd->compare_data);
+
+	ret = ib_cm_listen(cm_id, cmd->service_id, cmd->service_mask, data);
+	if (ret)
+		print_err("ib_cm_listen returned %d\n", ret);
+
+	IBP_INIT_RESP(cm_id, msg, len, IBP_RESPONSE, hdr->request, ret);
+
+	return ibp_send(client->ep, msg, len);
+}
+
+int ibp_cmd_send_cm_req(struct ibp_client *client, struct ibp_msg_header *hdr)
+{
+	struct ibp_response_msg			*msg;
+	struct ibp_send_cm_req_cmd		*cmd;
+	struct ib_cm_id				*cm_id;
+	struct ib_cm_req_param			param = {0};
+	struct ib_sa_path_rec			primary_path;
+	struct ib_sa_path_rec			alternate_path;
+	size_t					len;
+	int					ret;
+
+	print_trace("in\n");
+
+	cmd	= (struct ibp_send_cm_req_cmd *) hdr;
+	cm_id	= (struct ib_cm_id *) cmd->ibp_cm_id;
+	msg	= (struct ibp_response_msg *) client->tx_buf;
+	len	= sizeof(*msg);
+
+	if (cmd->alternate_path.pkey) {
+		param.alternate_path = &alternate_path;
+		ibp_copy_sa_path_rec(&cmd->alternate_path, &alternate_path);
+	}
+
+	param.primary_path = &primary_path;
+	ibp_copy_sa_path_rec(&cmd->primary_path, &primary_path);
+
+	param.service_id		 = cmd->service_id;
+	param.qp_num			 = cmd->qp_num;
+	param.qp_type			 = cmd->qp_type;
+	param.starting_psn		 = cmd->starting_psn;
+	param.peer_to_peer		 = cmd->peer_to_peer;
+	param.responder_resources	 = cmd->responder_resources;
+	param.initiator_depth		 = cmd->initiator_depth;
+	param.remote_cm_response_timeout = cmd->remote_cm_response_timeout;
+	param.flow_control		 = cmd->flow_control;
+	param.local_cm_response_timeout  = cmd->local_cm_response_timeout;
+	param.retry_count		 = cmd->retry_count;
+	param.rnr_retry_count		 = cmd->rnr_retry_count;
+	param.max_cm_retries		 = cmd->max_cm_retries;
+	param.srq			 = cmd->srq;
+	param.private_data_len		 = cmd->private_data_len;
+
+	if (cmd->private_data_len)
+		param.private_data	 = cmd->private_data;
+
+	ret = ib_send_cm_req(cm_id, &param);
+
+	if (ret)
+		print_err("send_cm_req returned %d\n", ret);
+
+	IBP_INIT_RESP(cm_id, msg, len, IBP_RESPONSE, hdr->request, ret);
+
+	return ibp_send(client->ep, msg, len);
+}
+
+int ibp_cmd_send_cm_rep(struct ibp_client *client, struct ibp_msg_header *hdr)
+{
+	struct ibp_response_msg			*msg;
+	struct ibp_send_cm_rep_cmd		*cmd;
+	struct ib_cm_id				*cm_id;
+	struct ib_cm_rep_param			param = {0};
+	size_t					len;
+	int					ret;
+
+	print_trace("in\n");
+
+	cmd	= (struct ibp_send_cm_rep_cmd *) hdr;
+	cm_id	= (struct ib_cm_id *) cmd->ibp_cm_id;
+	msg	= (struct ibp_response_msg *) client->tx_buf;
+	len	= sizeof(*msg);
+
+	param.qp_num		  = cmd->qp_num;
+	param.starting_psn	  = cmd->starting_psn;
+	param.responder_resources = cmd->responder_resources;
+	param.initiator_depth	  = cmd->initiator_depth;
+	param.failover_accepted   = cmd->failover_accepted;
+	param.rnr_retry_count	  = cmd->rnr_retry_count;
+	param.srq		  = cmd->srq;
+	param.private_data_len	  = cmd->private_data_len;
+
+	if (cmd->private_data_len)
+		param.private_data = cmd->private_data;
+
+	ret = ib_send_cm_rep(cm_id, &param);
+	if (ret)
+		print_err("send_cm_rep returned %d\n", ret);
+
+	IBP_INIT_RESP(cm_id, msg, len, IBP_RESPONSE, hdr->request, ret);
+
+	return ibp_send(client->ep, msg, len);
+}
+
+int ibp_cmd_send_cm_rtu(struct ibp_client *client, struct ibp_msg_header *hdr)
+{
+	struct ibp_send_cm_rtu_cmd		*cmd;
+	struct ibp_response_msg			*msg;
+	struct ib_cm_id				*cm_id;
+	void					*private_data = NULL;
+	size_t					len;
+	int					ret;
+
+	print_trace("in\n");
+
+	cmd	= (struct ibp_send_cm_rtu_cmd *) hdr;
+	cm_id	= (struct ib_cm_id *) cmd->ibp_cm_id;
+	msg	= (struct ibp_response_msg *) client->tx_buf;
+	len	= sizeof(*msg);
+
+	if (cmd->private_data_len)
+		private_data = cmd->private_data;
+
+	ret = ib_send_cm_rtu(cm_id, private_data, cmd->private_data_len);
+	if (ret)
+		print_err("send_cm_rtu returned %d\n", ret);
+
+	IBP_INIT_RESP(cm_id, msg, len, IBP_RESPONSE, hdr->request, ret);
+
+	return ibp_send(client->ep, msg, len);
+}
+
+int ibp_cmd_send_cm_dreq(struct ibp_client *client, struct ibp_msg_header *hdr)
+{
+	struct ibp_response_msg			*msg;
+	struct ibp_send_cm_dreq_cmd		*cmd;
+	struct ib_cm_id				*cm_id;
+	void					*private_data = NULL;
+	size_t					len;
+	int					ret;
+
+	print_trace("in\n");
+
+	cmd	= (struct ibp_send_cm_dreq_cmd *) hdr;
+	cm_id	= (struct ib_cm_id *) cmd->ibp_cm_id;
+	msg	= (struct ibp_response_msg *) client->tx_buf;
+	len	= sizeof(*msg);
+
+	if (cmd->private_data_len)
+		private_data = cmd->private_data;
+
+	ret = ib_send_cm_dreq(cm_id, private_data, cmd->private_data_len);
+	if (ret)
+		print_dbg("send_cm_dreq returned %d\n", ret);
+
+	IBP_INIT_RESP(cm_id, msg, len, IBP_RESPONSE, hdr->request, ret);
+
+	return ibp_send(client->ep, msg, len);
+}
+
+int ibp_cmd_send_cm_drep(struct ibp_client *client, struct ibp_msg_header *hdr)
+{
+	struct ibp_response_msg			*msg;
+	struct ibp_send_cm_drep_cmd		*cmd;
+	struct ib_cm_id				*cm_id;
+	void					*private_data = NULL;
+	size_t					len;
+	int					ret;
+
+	print_trace("in\n");
+
+	cmd	= (struct ibp_send_cm_drep_cmd *) hdr;
+	cm_id	= (struct ib_cm_id *) cmd->ibp_cm_id;
+	msg	= (struct ibp_response_msg *) client->tx_buf;
+	len	= sizeof(*msg);
+
+	if (cmd->private_data_len)
+		private_data = cmd->private_data;
+
+	ret = ib_send_cm_drep(cm_id, private_data, cmd->private_data_len);
+	if (ret)
+		print_dbg("send_cm_drep returned %d\n", ret);
+
+	IBP_INIT_RESP(cm_id, msg, len, IBP_RESPONSE, hdr->request, ret);
+
+	return ibp_send(client->ep, msg, len);
+}
+
+int ibp_cmd_send_cm_rej(struct ibp_client *client, struct ibp_msg_header *hdr)
+{
+	struct ibp_response_msg			*msg;
+	struct ibp_send_cm_rej_cmd		*cmd;
+	struct ib_cm_id				*cm_id;
+	void					*ari;
+	void					*private_data = NULL;
+	size_t					len;
+	int					ret;
+
+	print_trace("in\n");
+
+	cmd	= (struct ibp_send_cm_rej_cmd *) hdr;
+	cm_id	= (struct ib_cm_id *) cmd->ibp_cm_id;
+	msg	= (struct ibp_response_msg *) client->tx_buf;
+	len	= sizeof(*msg);
+
+	if (cmd->private_data_len)
+		private_data = cmd->data;
+
+	ari = &(cmd->data[cmd->private_data_len]);
+
+	ret = ib_send_cm_rej(cm_id, cmd->reason, ari, cmd->ari_length,
+			     private_data, cmd->private_data_len);
+	if (ret)
+		print_err("send_cm_rej returned %d\n", ret);
+
+	IBP_INIT_RESP(cm_id, msg, len, IBP_RESPONSE, hdr->request, ret);
+
+	return ibp_send(client->ep, msg, len);
+}
+
+int ibp_cmd_send_cm_mra(struct ibp_client *client, struct ibp_msg_header *hdr)
+{
+	struct ibp_response_msg			*msg;
+	struct ibp_send_cm_mra_cmd		*cmd;
+	struct ib_cm_id				*cm_id;
+	void					*private_data = NULL;
+	size_t					 len;
+	int					 ret;
+
+	print_trace("in\n");
+
+	cmd	= (struct ibp_send_cm_mra_cmd *) hdr;
+	cm_id	= (struct ib_cm_id *) cmd->ibp_cm_id;
+	msg	= (struct ibp_response_msg *) client->tx_buf;
+	len	= sizeof(*msg);
+
+	if (cmd->private_data_len)
+		private_data = cmd->private_data;
+
+	ret = ib_send_cm_mra(cm_id, cmd->service_timeout,
+			     private_data, cmd->private_data_len);
+	if (ret)
+		print_err("send_cm_mra returned %d\n", ret);
+
+	IBP_INIT_RESP(cm_id, msg, len, IBP_RESPONSE, hdr->request, ret);
+
+	return ibp_send(client->ep, msg, len);
+}
+
+int ibp_cmd_send_cm_lap(struct ibp_client *client, struct ibp_msg_header *hdr)
+{
+	struct ibp_response_msg			*msg;
+	struct ibp_send_cm_lap_cmd		*cmd;
+	struct ib_cm_id				*cm_id;
+	struct ib_sa_path_rec			alt_path;
+	void					*private_data = NULL;
+	size_t					len;
+	int					ret;
+
+	print_trace("in\n");
+
+	cmd	= (struct ibp_send_cm_lap_cmd *) hdr;
+	cm_id	= (struct ib_cm_id *) cmd->ibp_cm_id;
+	msg	= (struct ibp_response_msg *) client->tx_buf;
+	len	= sizeof(*msg);
+
+	if (cmd->private_data_len)
+		private_data = cmd->private_data;
+
+	ibp_copy_sa_path_rec(&cmd->alternate_path, &alt_path);
+
+	ret = ib_send_cm_lap(cm_id, &alt_path,
+			     private_data, cmd->private_data_len);
+	if (ret)
+		print_err("send_cm_lap returned %d\n", ret);
+
+	IBP_INIT_RESP(cm_id, msg, len, IBP_RESPONSE, hdr->request, ret);
+
+	return ibp_send(client->ep, msg, len);
+}
+
+int ibp_cmd_send_cm_apr(struct ibp_client *client, struct ibp_msg_header *hdr)
+{
+	struct ibp_response_msg			*msg;
+	struct ibp_send_cm_apr_cmd		*cmd;
+	struct ib_cm_id				*cm_id;
+	void					*info = NULL;
+	void					*private_data = NULL;
+	size_t					len;
+	int					ret;
+
+	print_trace("in\n");
+
+	cmd	= (struct ibp_send_cm_apr_cmd *) hdr;
+	cm_id	= (struct ib_cm_id *) cmd->ibp_cm_id;
+	msg	= (struct ibp_response_msg *) client->tx_buf;
+	len	= sizeof(*msg);
+
+	if (cmd->private_data_len)
+		private_data = cmd->data;
+	if (cmd->info_length)
+		info = &(cmd->data[cmd->private_data_len]);
+
+	ret = ib_send_cm_apr(cm_id, cmd->status, info, cmd->info_length,
+			     private_data, cmd->private_data_len);
+	if (ret)
+		print_err("send_cm_apr returned %d\n", ret);
+
+	IBP_INIT_RESP(cm_id, msg, len, IBP_RESPONSE, hdr->request, ret);
+
+	return ibp_send(client->ep, msg, len);
+}
+
+int
+ibp_cmd_send_cm_sidr_req(struct ibp_client *client, struct ibp_msg_header *hdr)
+{
+	struct ibp_response_msg			*msg;
+	struct ibp_send_cm_sidr_req_cmd		*cmd;
+	struct ib_cm_id				*cm_id;
+	struct ib_cm_sidr_req_param		param = {0};
+	struct ib_sa_path_rec			path;
+	size_t					len;
+	int					ret;
+
+	print_trace("in\n");
+
+	cmd	= (struct ibp_send_cm_sidr_req_cmd *) hdr;
+	cm_id	= (struct ib_cm_id *) cmd->ibp_cm_id;
+	msg	= (struct ibp_response_msg *) client->tx_buf;
+	len	= sizeof(*msg);
+
+	param.path = &path;
+	ibp_copy_sa_path_rec(&cmd->path, &path);
+
+	param.service_id       = cmd->service_id;
+	param.timeout_ms       = cmd->timeout_ms;
+	param.max_cm_retries   = cmd->max_cm_retries;
+	param.private_data_len = cmd->private_data_len;
+
+	if (cmd->private_data_len)
+		param.private_data = cmd->private_data;
+
+	ret = ib_send_cm_sidr_req(cm_id, &param);
+	if (ret)
+		print_err("send_cm_sidr_req returned %d\n", ret);
+
+	IBP_INIT_RESP(cm_id, msg, len, IBP_RESPONSE, hdr->request, ret);
+
+	return ibp_send(client->ep, msg, len);
+}
+
+int
+ibp_cmd_send_cm_sidr_rep(struct ibp_client *client, struct ibp_msg_header *hdr)
+{
+	struct ibp_response_msg			*msg;
+	struct ibp_send_cm_sidr_rep_cmd		*cmd;
+	struct ib_cm_sidr_rep_param		param = {0};
+	struct ib_cm_id				*cm_id;
+	size_t					len;
+	int					ret;
+
+	print_trace("in\n");
+
+	cmd	= (struct ibp_send_cm_sidr_rep_cmd *) hdr;
+	cm_id	= (struct ib_cm_id *) cmd->ibp_cm_id;
+	msg	= (struct ibp_response_msg *) client->tx_buf;
+	len	= sizeof(*msg);
+
+
+	param.qp_num		= cmd->qp_num;
+	param.qkey		= cmd->qkey;
+	param.status		= cmd->status;
+	param.info_length	= cmd->info_length;
+	param.private_data_len  = cmd->private_data_len;
+
+	if (cmd->private_data_len)
+		param.private_data = cmd->data;
+	if (cmd->info_length)
+		param.info = &(cmd->data[cmd->private_data_len]);
+
+	ret = ib_send_cm_sidr_rep(cm_id, &param);
+	if (ret)
+		print_err("send_cm_sidr_rep returned %d\n", ret);
+
+	IBP_INIT_RESP(cm_id, msg, len, IBP_RESPONSE, hdr->request, ret);
+
+	return ibp_send(client->ep, msg, len);
+}
+
+int ibp_cmd_cm_notify(struct ibp_client *client, struct ibp_msg_header *hdr)
+{
+	struct ibp_response_msg			*msg;
+	struct ibp_cm_notify_cmd		*cmd;
+	struct ib_cm_id				*cm_id;
+	size_t					len;
+	int					ret;
+
+	print_trace("in\n");
+
+	cmd	= (struct ibp_cm_notify_cmd	*) hdr;
+	cm_id	= (struct ib_cm_id *) cmd->ibp_cm_id;
+	msg	= (struct ibp_response_msg *) client->tx_buf;
+	len	= sizeof(*msg);
+
+	ret = ib_cm_notify(cm_id, cmd->event);
+	if (ret)
+		print_err("cm_notify returned %d\n", ret);
+
+	IBP_INIT_RESP(cm_id, msg, len, IBP_RESPONSE, hdr->request, ret);
+
+	return ibp_send(client->ep, msg, len);
+}
+
+int
+ibp_cmd_cm_init_qp_attr(struct ibp_client *client, struct ibp_msg_header *hdr)
+{
+	struct ibp_response_msg			*msg;
+	struct ibp_cm_init_qp_attr_cmd		*cmd;
+	struct ibp_cm_init_qp_attr_resp		*resp;
+	struct ib_cm_id				*cm_id;
+	struct ib_qp_attr			 qp_attr;
+	int					 qp_attr_mask;
+	size_t					 len;
+	int					 ret;
+
+	print_trace("in\n");
+
+	cmd	= (struct ibp_cm_init_qp_attr_cmd *) hdr;
+	cm_id	= (struct ib_cm_id *) cmd->ibp_cm_id;
+	msg	= (struct ibp_response_msg *) client->tx_buf;
+	len	= sizeof(*msg);
+
+	qp_attr.qp_state = cmd->qp_attr_state;
+
+	ret = ib_cm_init_qp_attr(cm_id, &qp_attr, &qp_attr_mask);
+	if (ret) {
+		print_err("init_qp_attr returned %d\n", ret);
+		goto send_resp;
+	}
+
+	/* Workaround to avoid modify_qp error from Xeon Phi IPoIB connected mode */
+	qp_attr_mask &= ~IB_QP_SMAC;
+
+	len += sizeof(*resp);
+
+	resp = (struct ibp_cm_init_qp_attr_resp *) msg->data;
+
+	resp->qp_attr_mask		= qp_attr_mask;
+	resp->qp_access_flags		= qp_attr.qp_access_flags;
+	resp->qp_state			= qp_attr.qp_state;
+	resp->cur_qp_state		= qp_attr.cur_qp_state;
+	resp->path_mtu			= qp_attr.path_mtu;
+	resp->path_mig_state		= qp_attr.path_mig_state;
+	resp->qkey			= qp_attr.qkey;
+	resp->rq_psn			= qp_attr.rq_psn;
+	resp->sq_psn			= qp_attr.sq_psn;
+	resp->dest_qp_num		= qp_attr.dest_qp_num;
+
+	resp->cap_max_send_wr		= qp_attr.cap.max_send_wr;
+	resp->cap_max_recv_wr		= qp_attr.cap.max_recv_wr;
+	resp->cap_max_send_sge		= qp_attr.cap.max_send_sge;
+	resp->cap_max_recv_sge		= qp_attr.cap.max_recv_sge;
+	resp->cap_max_inline_data	= qp_attr.cap.max_inline_data;
+
+	resp->ah_attr_grh_dgid_subnet_prefix =
+			qp_attr.ah_attr.grh.dgid.global.subnet_prefix;
+	resp->ah_attr_grh_dgid_interface_id =
+			qp_attr.ah_attr.grh.dgid.global.interface_id;
+	resp->ah_attr_grh_flow_label	= qp_attr.ah_attr.grh.flow_label;
+	resp->ah_attr_grh_sgid_index	= qp_attr.ah_attr.grh.sgid_index;
+	resp->ah_attr_grh_hop_limit	= qp_attr.ah_attr.grh.hop_limit;
+	resp->ah_attr_grh_traffic_class	= qp_attr.ah_attr.grh.traffic_class;
+	resp->ah_attr_dlid		= qp_attr.ah_attr.dlid;
+	resp->ah_attr_sl		= qp_attr.ah_attr.sl;
+	resp->ah_attr_src_path_bits	= qp_attr.ah_attr.src_path_bits;
+	resp->ah_attr_static_rate	= qp_attr.ah_attr.static_rate;
+	resp->ah_attr_ah_flags		= qp_attr.ah_attr.ah_flags;
+	resp->ah_attr_port_num		= qp_attr.ah_attr.port_num;
+
+	resp->alt_attr_grh_dgid_subnet_prefix =
+			qp_attr.alt_ah_attr.grh.dgid.global.subnet_prefix;
+	resp->alt_attr_grh_dgid_interface_id =
+			qp_attr.alt_ah_attr.grh.dgid.global.interface_id;
+	resp->alt_attr_grh_flow_label	= qp_attr.alt_ah_attr.grh.flow_label;
+	resp->alt_attr_grh_sgid_index	= qp_attr.alt_ah_attr.grh.sgid_index;
+	resp->alt_attr_grh_hop_limit	= qp_attr.alt_ah_attr.grh.hop_limit;
+	resp->alt_attr_grh_traffic_class
+					= qp_attr.alt_ah_attr.grh.traffic_class;
+	resp->alt_attr_dlid		= qp_attr.alt_ah_attr.dlid;
+	resp->alt_attr_sl		= qp_attr.alt_ah_attr.sl;
+	resp->alt_attr_src_path_bits	= qp_attr.alt_ah_attr.src_path_bits;
+	resp->alt_attr_static_rate	= qp_attr.alt_ah_attr.static_rate;
+	resp->alt_attr_ah_flags		= qp_attr.alt_ah_attr.ah_flags;
+	resp->alt_attr_port_num		= qp_attr.alt_ah_attr.port_num;
+
+	resp->pkey_index		= qp_attr.pkey_index;
+	resp->alt_pkey_index		= qp_attr.alt_pkey_index;
+	resp->en_sqd_async_notify	= qp_attr.en_sqd_async_notify;
+	resp->sq_draining		= qp_attr.sq_draining;
+	resp->max_rd_atomic		= qp_attr.max_rd_atomic;
+	resp->max_dest_rd_atomic	= qp_attr.max_dest_rd_atomic;
+	resp->min_rnr_timer		= qp_attr.min_rnr_timer;
+	resp->port_num			= qp_attr.port_num;
+	resp->timeout			= qp_attr.timeout;
+	resp->retry_cnt			= qp_attr.retry_cnt;
+	resp->rnr_retry			= qp_attr.rnr_retry;
+	resp->alt_port_num		= qp_attr.alt_port_num;
+	resp->alt_timeout		= qp_attr.alt_timeout;
+
+send_resp:
+	IBP_INIT_RESP(cm_id, msg, len, IBP_RESPONSE, hdr->request, ret);
+
+	return ibp_send(client->ep, msg, len);
+}
diff -ruN a6/drivers/infiniband/ibp/cm/common.h a7/drivers/infiniband/ibp/cm/common.h
--- a6/drivers/infiniband/ibp/cm/common.h	1969-12-31 16:00:00.000000000 -0800
+++ a7/drivers/infiniband/ibp/cm/common.h	2015-09-10 09:33:35.324900603 -0700
@@ -0,0 +1,106 @@
+/*
+ * Copyright (c) 2011-2013 Intel Corporation. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *	  copyright notice, this list of conditions and the following
+ *	  disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *	  copyright notice, this list of conditions and the following
+ *	  disclaimer in the documentation and/or other materials
+ *	  provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#ifndef COMMON_H
+#define COMMON_H
+
+#include <linux/module.h>
+#include <linux/kthread.h>
+#include <linux/types.h>
+#include <linux/slab.h>
+#include <linux/poll.h>
+#include <linux/mman.h>
+#include <linux/pci.h>
+#include <linux/net.h>
+#include <rdma/ib_verbs.h>
+#include <scif.h>
+
+#define DRV_DESC	"CCL Direct CM " DRV_ROLE
+#define DRV_VERSION	"1.0"
+#define DRV_BASE	"ibp_cm"
+#define PFX		DRV_BASE "_"
+#define DRV_PFX		DRV_NAME ": "
+
+#define DRV_COPYRIGHT	"Copyright (c) 2011-2013 Intel Corporation"
+#define DRV_SIGNON	DRV_DESC " v" DRV_VERSION "\n" DRV_COPYRIGHT "\n"
+
+#define MODULE_PARAM(name, var, type, value, desc)	\
+	type var = value;				\
+	module_param_named(name, var, type, 0644);	\
+	MODULE_PARM_DESC(name, desc)
+
+#ifdef IBP_DEBUG
+extern int debug_level;
+#endif
+
+enum {
+	IBP_DEBUG_NONE,
+	IBP_DEBUG_TARGETED,
+	IBP_DEBUG_VERBOSE,
+};
+
+#define _PRINTK(l, f, arg...)	\
+	printk(l DRV_PFX "%s(%d) " f, __func__, __LINE__, ##arg)
+
+#ifdef IBP_DEBUG
+#define PRINTK(dbg, l, f, arg...)				\
+	do {							\
+		if (debug_level >= dbg)				\
+			printk(l DRV_PFX "%s(%d) " f,		\
+			       __func__, __LINE__, ##arg);	\
+	} while (0)
+#else
+#define PRINTK(dbg, l, f, arg...) do { } while (0)
+#endif
+
+#define print_dbg(f, arg...) PRINTK(IBP_DEBUG_TARGETED, KERN_DEBUG, f, ##arg)
+#define print_err(f, arg...) _PRINTK(KERN_ERR, f, ##arg)
+#define print_info(f, arg...) pr_info(f, ##arg)
+
+#if 0
+#define FORCED_FUNCTION_TRACING
+#endif
+
+#ifdef FORCED_FUNCTION_TRACING
+#define print_trace(f, arg...) _PRINTK(KERN_ERR, f, ##arg)
+#else
+#define print_trace(f, arg...) PRINTK(IBP_DEBUG_VERBOSE, KERN_ERR, f, ##arg)
+#endif
+
+#ifndef IBP_CM_PORT		/* unique scif port for this service */
+#define IBP_CM_PORT		SCIF_OFED_PORT_3
+#endif
+
+int ibp_send(scif_epd_t ep, void *buf, size_t len);
+int ibp_recv(scif_epd_t ep, void *buf, size_t len);
+
+#endif /* COMMON_H */
diff -ruN a6/drivers/infiniband/ibp/cm/ibp-abi.h a7/drivers/infiniband/ibp/cm/ibp-abi.h
--- a6/drivers/infiniband/ibp/cm/ibp-abi.h	1969-12-31 16:00:00.000000000 -0800
+++ a7/drivers/infiniband/ibp/cm/ibp-abi.h	2015-09-10 09:33:35.325932447 -0700
@@ -0,0 +1,94 @@
+/*
+ * Copyright (c) 2011-2013 Intel Corporation. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *	copyright notice, this list of conditions and the following
+ *	disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *	copyright notice, this list of conditions and the following
+ *	disclaimer in the documentation and/or other materials
+ *	provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#ifndef IBP_ABI_H
+#define IBP_ABI_H
+
+#include <linux/types.h>
+#include <rdma/ib_verbs.h>
+#include <rdma/ib_cm.h>
+
+/* Increment this value if any changes break compatibility. */
+#define IBP_CM_ABI_VERSION	1
+
+/* Client to server message enums. */
+enum {
+	IBP_CREATE_CM_ID,
+	IBP_DESTROY_CM_ID,
+	IBP_CM_LISTEN,
+	IBP_CM_NOTIFY,
+	IBP_SEND_CM_REQ,
+	IBP_SEND_CM_REP,
+	IBP_SEND_CM_RTU,
+	IBP_SEND_CM_DREQ,
+	IBP_SEND_CM_DREP,
+	IBP_SEND_CM_REJ,
+	IBP_SEND_CM_MRA,
+	IBP_SEND_CM_LAP,
+	IBP_SEND_CM_APR,
+	IBP_SEND_CM_SIDR_REQ,
+	IBP_SEND_CM_SIDR_REP,
+	IBP_CM_INIT_QP_ATTR,
+};
+
+/* Server to client message enums. */
+enum {
+	IBP_IBP_EVENT,
+	IBP_IBP_RESPONSE,
+};
+
+/*
+ * Make sure that all structs defined in this file are laid out to pack
+ * the same way on different architectures to avoid incompatibility.
+ *
+ * Specifically:
+ *  - Do not use pointer types -- pass pointers in a u64 instead.
+ *  - Make sure that any structure larger than 4 bytes is padded
+ *    to a multiple of 8 bytes; otherwise the structure size may
+ *    be different between architectures.
+ */
+
+struct ibp_msg_header {			/* present in all messages */
+	u32			opcode;
+	u32			length;
+	u32			status;
+	u32			reserved;
+	u64			request;
+	u64			data[0];
+};
+
+struct ibp_response_msg {
+	struct ibp_msg_header		header;
+	u64				data[0];
+};
+
+#endif /* IBP_ABI_H */
diff -ruN a6/drivers/infiniband/ibp/cm/ibp_exports.h a7/drivers/infiniband/ibp/cm/ibp_exports.h
--- a6/drivers/infiniband/ibp/cm/ibp_exports.h	1969-12-31 16:00:00.000000000 -0800
+++ a7/drivers/infiniband/ibp/cm/ibp_exports.h	2015-09-10 09:33:35.325932447 -0700
@@ -0,0 +1,50 @@
+/*
+ * Copyright (c) 2011-2013 Intel Corporation. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *	  copyright notice, this list of conditions and the following
+ *	  disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *	  copyright notice, this list of conditions and the following
+ *	  disclaimer in the documentation and/or other materials
+ *	  provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#ifndef IBP_EXPORTS_H
+#define IBP_EXPORTS_H
+
+#include <rdma/ib_verbs.h>
+
+/*
+ ibp_resolve_ib_device - Return the host ib_device handle
+ @ibdev:Card IB device
+
+ Upper level drivers may require the host ib_device handle associated
+ with the card ib_device.  This routine resolves the card ib_device to
+ the cooresponding host ib_device handle.  A value of 0 is returned if
+ no match was found.
+*/
+u64 ibp_resolve_ib_device(struct ib_device *ibdev);
+
+
+#endif /* IBP_EXPORTS_H */
diff -ruN a6/drivers/infiniband/ibp/cm/Makefile a7/drivers/infiniband/ibp/cm/Makefile
--- a6/drivers/infiniband/ibp/cm/Makefile	1969-12-31 16:00:00.000000000 -0800
+++ a7/drivers/infiniband/ibp/cm/Makefile	2015-09-10 09:33:35.325932447 -0700
@@ -0,0 +1,26 @@
+KERNEL_V := $(shell uname -r)
+
+KDIR ?= /lib/modules/$(KERNEL_V)/build
+
+SCIF_INCL := /usr/src/kernels/$(KERNEL_V)/include/modules/
+
+obj-$(CONFIG_IBP_SERVER) += ibp_cm_server.o
+
+ccflags-y += -I$(SCIF_INCL)
+ccflags-$(CONFIG_IBP_DEBUG) += -g -DIBP_DEBUG
+
+ibp_cm_server-y :=	server.o		\
+			server_msg.o		\
+			cm_server_msg.o
+
+default:
+	$(MAKE) -C $(KDIR) M=`pwd`
+
+modules_install:
+	$(MAKE) -C $(KDIR) M=`pwd` modules_install
+
+clean:
+	rm -rf *.ko *.o .*.ko.cmd .*.o.cmd *.mod.c Module.* modules.order .tmp_versions
+
+unix:
+	dos2unix *.[ch] Kconfig Makefile
diff -ruN a6/drivers/infiniband/ibp/cm/server.c a7/drivers/infiniband/ibp/cm/server.c
--- a6/drivers/infiniband/ibp/cm/server.c	1969-12-31 16:00:00.000000000 -0800
+++ a7/drivers/infiniband/ibp/cm/server.c	2015-09-10 09:33:35.326924807 -0700
@@ -0,0 +1,221 @@
+/*
+ * Copyright (c) 2011-2013 Intel Corporation. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *	  copyright notice, this list of conditions and the following
+ *	  disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *	  copyright notice, this list of conditions and the following
+ *	  disclaimer in the documentation and/or other materials
+ *	  provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include "server.h"
+
+MODULE_AUTHOR("Jerrie Coffman");
+MODULE_AUTHOR("Phil Cayton");
+MODULE_AUTHOR("Jay Sternberg");
+MODULE_LICENSE("Dual BSD/GPL");
+MODULE_DESCRIPTION(DRV_DESC);
+MODULE_VERSION(DRV_VERSION);
+
+MODULE_PARAM(port, port, int, IBP_CM_PORT, "Connection port");
+MODULE_PARAM(backlog, backlog, int, 8, "Connection backlog");
+MODULE_PARAM(timeout, timeout, int, 1000, "Listen/Poll time in milliseconds");
+
+#ifdef IBP_DEBUG
+MODULE_PARAM(debug_level, debug_level, int, 0, "Debug: 0-none, 1-some, 2-all");
+#endif
+
+struct rw_semaphore				list_rwsem;
+
+LIST_HEAD(client_list);
+
+static struct task_struct			*listen_thread;
+
+static struct ibp_client *ibp_create_client(scif_epd_t ep, uint16_t node)
+{
+	struct ibp_client		*client;
+	int				ret = -ENOMEM;
+
+	client = kzalloc(sizeof(*client), GFP_KERNEL);
+	if (!client) {
+		print_err("kzalloc failed\n");
+		return ERR_PTR(ret);
+	}
+
+	client->ep = ep;
+
+	client->rx_buf = (void *)__get_free_page(GFP_KERNEL);
+	if (!client->rx_buf) {
+		print_err("__get_free_page rx_buf failed\n");
+		goto err0;
+	}
+
+	client->tx_buf = (void *)__get_free_page(GFP_KERNEL);
+	if (!client->tx_buf) {
+		print_err("__get_free_page tx_buf failed\n");
+		goto err1;
+	}
+
+	client->workqueue = create_singlethread_workqueue(DRV_NAME);
+	if (!client->workqueue) {
+		print_err("create_singlethread_workqueue failed\n");
+		goto err2;
+	}
+
+	down_write(&list_rwsem);
+	list_add(&client->list, &client_list);
+	up_write(&list_rwsem);
+
+	client->ibp_cm_client_thread = kthread_run(ibp_process_recvs,
+						   client, DRV_NAME);
+	if (!client->ibp_cm_client_thread) {
+		print_err("create cleint thread failed\n");
+		goto err3;
+	}
+
+	return client;
+err3:
+	down_write(&list_rwsem);
+	list_del(&client->list);
+	up_write(&list_rwsem);
+
+	destroy_workqueue(client->workqueue);
+err2:
+	free_page((uintptr_t)client->tx_buf);
+err1:
+	free_page((uintptr_t)client->rx_buf);
+err0:
+	kfree(client);
+	return ERR_PTR(ret);
+}
+
+static int ibp_cm_listen(void *data)
+{
+	struct ibp_client		*client;
+	struct scif_pollepd		listen;
+	struct scif_portID		peer;
+	scif_epd_t			ep;
+	int				ret;
+
+	listen.epd = scif_open();
+	if (!listen.epd) {
+		print_err("scif_open failed\n");
+		ret = -EIO;
+		goto err0;
+	}
+	listen.events = POLLIN;
+
+	ret = scif_bind(listen.epd, port);
+	if (ret < 0) {
+		print_err("scif_bind returned %d\n", ret);
+		goto err1;
+	}
+
+	ret = scif_listen(listen.epd, backlog);
+	if (ret) {
+		print_err("scif_listen returned %d\n", ret);
+		goto err1;
+	}
+
+	while (!kthread_should_stop()) {
+
+		schedule();
+
+		ret = scif_poll(&listen, 1, timeout);
+		if (ret == 0)	/* timeout */
+			continue;
+		if (ret < 0) {
+			print_err("scif_poll revents 0x%x\n", listen.revents);
+			continue;
+		}
+
+		ret = scif_accept(listen.epd, &peer, &ep, 0);
+		if (ret) {
+			print_err("scif_accept returned %d\n", ret);
+			continue;
+		}
+
+		print_dbg("accepted node %d port %d\n", peer.node, peer.port);
+
+		client = ibp_create_client(ep, peer.node);
+		if (IS_ERR(client)) {
+			ret = PTR_ERR(client);
+			print_err("ibp_create_client returned %d\n", ret);
+			scif_close(ep);
+		}
+	}
+err1:
+	scif_close(listen.epd);
+err0:
+	return ret;
+}
+
+static int __init ibp_cm_server_init(void)
+{
+	int				ret = 0;
+
+	print_info(DRV_SIGNON);
+
+	init_rwsem(&list_rwsem);
+
+	/* Start a thread for inbound connections. */
+	listen_thread = kthread_run(ibp_cm_listen, NULL, DRV_NAME);
+	if (IS_ERR(listen_thread)) {
+		ret = PTR_ERR(listen_thread);
+		print_err("kthread_run returned %d\n", ret);
+	}
+
+	return ret;
+}
+
+static void __exit ibp_cm_server_exit(void)
+{
+	struct ibp_client		*client, *next;
+	struct completion		done;
+
+	kthread_stop(listen_thread);
+
+	down_write(&list_rwsem);
+	list_for_each_entry_safe(client, next, &client_list, list) {
+		init_completion(&done);
+		client->done = &done;
+
+		/* Close scif ep to unblock the client thread scif_recv */
+		scif_close(client->ep);
+
+		up_write(&list_rwsem);
+
+		/* Wait for client thread to finish */
+		wait_for_completion(&done);
+
+		down_write(&list_rwsem);
+	}
+	up_write(&list_rwsem);
+
+	print_info(DRV_DESC " unloaded\n");
+}
+
+module_init(ibp_cm_server_init);
+module_exit(ibp_cm_server_exit);
diff -ruN a6/drivers/infiniband/ibp/cm/server.h a7/drivers/infiniband/ibp/cm/server.h
--- a6/drivers/infiniband/ibp/cm/server.h	1969-12-31 16:00:00.000000000 -0800
+++ a7/drivers/infiniband/ibp/cm/server.h	2015-09-10 09:33:35.326924807 -0700
@@ -0,0 +1,128 @@
+/*
+ * Copyright (c) 2011-2013 Intel Corporation. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *	  copyright notice, this list of conditions and the following
+ *	  disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *	  copyright notice, this list of conditions and the following
+ *	  disclaimer in the documentation and/or other materials
+ *	  provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#ifndef SERVER_H
+#define SERVER_H
+
+#include <linux/fs.h>
+#include <linux/cdev.h>
+#include <linux/anon_inodes.h>
+#include <rdma/ib_umem.h>
+#include "ibp-abi.h"
+#include "cm_ibp_abi.h"
+#include "common.h"
+
+#define DRV_ROLE	"Server"
+#define DRV_NAME	"ibp_cm_server"
+
+#define MAX_MSG_SIZE	PAGE_SIZE
+
+extern int			timeout;
+extern struct rw_semaphore	list_rwsem;
+extern struct list_head		client_list;
+extern struct list_head		cm_entry_list;
+
+struct ibp_client {
+	struct list_head	list;
+	scif_epd_t		ep;
+	void			*rx_buf;
+	void			*tx_buf;
+	struct completion	*done;
+	struct workqueue_struct	*workqueue;
+	struct task_struct	*ibp_cm_client_thread;
+};
+
+struct cm_entry {
+	struct list_head	list;
+	struct ib_cm_id		*cm_id;
+	struct ibp_client	*client;
+};
+
+struct ibp_event_get {
+	__u64 response;
+	__u64 data;
+	__u64 info;
+	__u8  data_len;
+	__u8  info_len;
+	__u8  reserved[6];
+};
+
+struct ibp_event {
+	struct work_struct      work;
+	struct ibp_client       *client;
+	struct ibp_cm_event	event;
+};
+
+#define IBP_INIT_MSG(device, msg, size, op)			\
+	do {							\
+		(msg)->header.opcode	= IBP_##op;		\
+		(msg)->header.length	= (size);		\
+		(msg)->header.status	= 0;			\
+		(msg)->header.reserved	= 0;			\
+		(msg)->header.request	= 0;			\
+	} while (0)
+
+#define IBP_INIT_RESP(device, resp, size, op, req, stat)	\
+	do {							\
+		(resp)->header.opcode	= IBP_##op;		\
+		(resp)->header.length	= (size);		\
+		(resp)->header.status	= (stat);		\
+		(resp)->header.reserved	= 0;			\
+		(resp)->header.request	= (req);		\
+	} while (0)
+
+int ibp_process_recvs(void *p);
+void cleanup_cm_entry_list(void);
+
+int ibp_cmd_create_cm_id(struct ibp_client *client, struct ibp_msg_header *hdr);
+int ibp_cmd_destroy_cm_id(struct ibp_client *client,
+			  struct ibp_msg_header *hdr);
+int ibp_cmd_cm_listen(struct ibp_client *client, struct ibp_msg_header *hdr);
+int ibp_cmd_cm_notify(struct ibp_client *client, struct ibp_msg_header *hdr);
+int ibp_cmd_send_cm_req(struct ibp_client *client, struct ibp_msg_header *hdr);
+int ibp_cmd_send_cm_rep(struct ibp_client *client, struct ibp_msg_header *hdr);
+int ibp_cmd_send_cm_rtu(struct ibp_client *client, struct ibp_msg_header *hdr);
+int ibp_cmd_send_cm_dreq(struct ibp_client *client, struct ibp_msg_header *hdr);
+int ibp_cmd_send_cm_drep(struct ibp_client *client, struct ibp_msg_header *hdr);
+int ibp_cmd_send_cm_rej(struct ibp_client *client, struct ibp_msg_header *hdr);
+int ibp_cmd_send_cm_mra(struct ibp_client *client, struct ibp_msg_header *hdr);
+int ibp_cmd_send_cm_lap(struct ibp_client *client, struct ibp_msg_header *hdr);
+int ibp_cmd_send_cm_apr(struct ibp_client *client, struct ibp_msg_header *hdr);
+int ibp_cmd_send_cm_sidr_req(struct ibp_client *client,
+			     struct ibp_msg_header *hdr);
+int ibp_cmd_send_cm_sidr_rep(struct ibp_client *client,
+			     struct ibp_msg_header *hdr);
+int ibp_cmd_cm_event(struct  ibp_client *client, struct ibp_msg_header *hdr);
+int ibp_cmd_cm_init_qp_attr(struct ibp_client *client,
+			    struct ibp_msg_header *hdr);
+
+#endif /* SERVER_H */
diff -ruN a6/drivers/infiniband/ibp/cm/server_msg.c a7/drivers/infiniband/ibp/cm/server_msg.c
--- a6/drivers/infiniband/ibp/cm/server_msg.c	1969-12-31 16:00:00.000000000 -0800
+++ a7/drivers/infiniband/ibp/cm/server_msg.c	2015-09-10 09:33:35.326924807 -0700
@@ -0,0 +1,176 @@
+/*
+ * Copyright (c) 2011-2013 Intel Corporation. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *	  copyright notice, this list of conditions and the following
+ *	  disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *	  copyright notice, this list of conditions and the following
+ *	  disclaimer in the documentation and/or other materials
+ *	  provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include "server.h"
+#include "cm_ibp_abi.h"
+
+int ibp_send(scif_epd_t ep, void *buf, size_t len)
+{
+	int				ret;
+
+	while (len) {
+		ret = scif_send(ep, buf, (uint32_t)len, SCIF_SEND_BLOCK);
+		if (ret < 0) {
+			print_dbg("scif_send returned %d\n", ret);
+			return ret;
+		}
+		buf += ret;
+		len -= ret;
+	}
+
+	return 0;
+}
+
+int ibp_recv(scif_epd_t ep, void *buf, size_t len)
+{
+	int				ret;
+
+	while (len) {
+		ret = scif_recv(ep, buf, (uint32_t)len, SCIF_RECV_BLOCK);
+		if (ret < 0) {
+			print_dbg("scif_recv returned %d\n", ret);
+			return ret;
+		}
+		buf += ret;
+		len -= ret;
+	}
+
+	return 0;
+}
+
+static int
+ibp_cmd_bad_request(struct ibp_client *client, struct ibp_msg_header *hdr)
+{
+	struct ibp_response_msg		*msg;
+	size_t				len;
+	int				status = -EBADRQC;
+
+	print_dbg("opcode 0x%x\n", hdr->opcode);
+
+	msg = (struct ibp_response_msg *) client->tx_buf;
+	len = sizeof(*msg);
+
+	IBP_INIT_RESP(NULL, msg, len, IBP_RESPONSE, hdr->request, status);
+	return ibp_send(client->ep, msg, len);
+}
+
+static void
+ibp_cm_destroy_client(struct ibp_client *client)
+{
+	struct cm_entry			*cm, *tmp;
+
+	down_write(&list_rwsem);
+	list_del(&client->list);
+	list_for_each_entry_safe(cm, tmp, &cm_entry_list, list)
+		if (cm->client == client) {
+			ib_destroy_cm_id(cm->cm_id);
+			list_del(&cm->list);
+			kfree(cm);
+		}
+	up_write(&list_rwsem);
+
+	destroy_workqueue(client->workqueue);
+
+	free_page((uintptr_t)client->tx_buf);
+	free_page((uintptr_t)client->rx_buf);
+
+	if (client->done)
+		complete(client->done);
+	else
+		scif_close(client->ep);
+
+	kfree(client);
+}
+
+static int
+(*ibp_msg_table[])(struct ibp_client *c, struct ibp_msg_header *h) = {
+	[IBP_CREATE_CM_ID]		= ibp_cmd_create_cm_id,
+	[IBP_DESTROY_CM_ID]		= ibp_cmd_destroy_cm_id,
+	[IBP_CM_LISTEN]			= ibp_cmd_cm_listen,
+	[IBP_CM_NOTIFY]			= ibp_cmd_cm_notify,
+	[IBP_SEND_CM_REQ]		= ibp_cmd_send_cm_req,
+	[IBP_SEND_CM_REP]		= ibp_cmd_send_cm_rep,
+	[IBP_SEND_CM_RTU]		= ibp_cmd_send_cm_rtu,
+	[IBP_SEND_CM_DREQ]		= ibp_cmd_send_cm_dreq,
+	[IBP_SEND_CM_DREP]		= ibp_cmd_send_cm_drep,
+	[IBP_SEND_CM_REJ]		= ibp_cmd_send_cm_rej,
+	[IBP_SEND_CM_MRA]		= ibp_cmd_send_cm_mra,
+	[IBP_SEND_CM_LAP]		= ibp_cmd_send_cm_lap,
+	[IBP_SEND_CM_APR]		= ibp_cmd_send_cm_apr,
+	[IBP_SEND_CM_SIDR_REQ]		= ibp_cmd_send_cm_sidr_req,
+	[IBP_SEND_CM_SIDR_REP]		= ibp_cmd_send_cm_sidr_rep,
+	[IBP_CM_INIT_QP_ATTR]		= ibp_cmd_cm_init_qp_attr,
+};
+
+int ibp_process_recvs(void *p)
+{
+	struct ibp_client		*client;
+	struct ibp_msg_header		*hdr;
+	int				ret;
+
+	client = (struct ibp_client *) p;
+	hdr = (struct ibp_msg_header *) client->rx_buf;
+
+	for (;;) {
+		ret = ibp_recv(client->ep, hdr, sizeof(*hdr));
+		if (ret)
+			break;
+
+		if (hdr->length > MAX_MSG_SIZE) {
+			print_err("message too large, len %u max %lu\n",
+				  hdr->length, MAX_MSG_SIZE);
+			ret = -EMSGSIZE;
+			break;
+		}
+
+		if (hdr->length > sizeof(*hdr)) {
+			ret = ibp_recv(client->ep, hdr->data,
+				       hdr->length - sizeof(*hdr));
+			if (ret)
+				break;
+		}
+
+		if ((hdr->opcode >= ARRAY_SIZE(ibp_msg_table)) ||
+		    !ibp_msg_table[hdr->opcode]) {
+			ibp_cmd_bad_request(client, hdr);
+			continue;
+		}
+
+		ret = ibp_msg_table[hdr->opcode](client, hdr);
+		if (ret)
+			break;
+	}
+
+	ibp_cm_destroy_client(client);
+
+	return ret;
+}
diff -ruN a6/drivers/infiniband/ibp/drv/common.h a7/drivers/infiniband/ibp/drv/common.h
--- a6/drivers/infiniband/ibp/drv/common.h	1969-12-31 16:00:00.000000000 -0800
+++ a7/drivers/infiniband/ibp/drv/common.h	2015-09-10 09:33:35.327932404 -0700
@@ -0,0 +1,109 @@
+/*
+ * Copyright (c) 2011-2013 Intel Corporation. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *	  copyright notice, this list of conditions and the following
+ *	  disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *	  copyright notice, this list of conditions and the following
+ *	  disclaimer in the documentation and/or other materials
+ *	  provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#ifndef COMMON_H
+#define COMMON_H
+
+#include <linux/module.h>
+#include <linux/kthread.h>
+#include <linux/types.h>
+#include <linux/slab.h>
+#include <linux/poll.h>
+#include <linux/mman.h>
+#include <linux/pci.h>
+#include <linux/net.h>
+#include <rdma/ib_verbs.h>
+#include <scif.h>
+
+#define DRV_DESC	"CCL Direct " DRV_ROLE
+#define DRV_VERSION	"1.0"
+#define DRV_BASE	"ibp"
+#define PFX		DRV_BASE "_"
+#define DRV_PFX		DRV_NAME ": "
+
+#define DRV_COPYRIGHT	"Copyright (c) 2011-2013 Intel Corporation"
+#define DRV_SIGNON	DRV_DESC " v" DRV_VERSION "\n" DRV_COPYRIGHT "\n"
+
+#define MODULE_PARAM(name, var, type, value, desc)	\
+	type var = value;				\
+	module_param_named(name, var, type, 0644);	\
+	MODULE_PARM_DESC(name, desc)
+
+#ifdef IBP_DEBUG
+extern int debug_level;
+#endif
+
+enum {
+	IBP_DEBUG_NONE,
+	IBP_DEBUG_TARGETED,
+	IBP_DEBUG_VERBOSE,
+};
+
+#define _PRINTK(l, f, arg...)	\
+	printk(l DRV_PFX "%s(%d) " f, __func__, __LINE__, ##arg)
+
+#ifdef IBP_DEBUG
+#define PRINTK(dbg, l, f, arg...)				\
+	do {							\
+		if (debug_level >= dbg)				\
+			printk(l DRV_PFX "%s(%d) " f,		\
+			       __func__, __LINE__, ##arg);	\
+	} while (0)
+#else
+#define PRINTK(dbg, l, f, arg...) do { } while (0)
+#endif
+
+#define print_dbg(f, arg...) PRINTK(IBP_DEBUG_TARGETED, KERN_DEBUG, f, ##arg)
+#define print_err(f, arg...) _PRINTK(KERN_ERR, f, ##arg)
+#define print_info(f, arg...) pr_info(f, ##arg)
+
+#if 0
+#define FORCED_FUNCTION_TRACING
+#endif
+
+#ifdef FORCED_FUNCTION_TRACING
+#define print_trace(f, arg...) _PRINTK(KERN_ERR, f, ##arg)
+#else
+#define print_trace(f, arg...) PRINTK(IBP_DEBUG_VERBOSE, KERN_ERR, f, ##arg)
+#endif
+
+#ifndef IBP_PORT		/* unique scif port for this service */
+#define IBP_PORT		SCIF_OFED_PORT_2
+#endif
+
+#define IS_NULL_OR_ERR(p) (!(p) || IS_ERR_VALUE((unsigned long)p))
+
+int ibp_init(void);
+
+void ibp_cleanup(void);
+
+#endif /* COMMON_H */
diff -ruN a6/drivers/infiniband/ibp/drv/ibp-abi.h a7/drivers/infiniband/ibp/drv/ibp-abi.h
--- a6/drivers/infiniband/ibp/drv/ibp-abi.h	1969-12-31 16:00:00.000000000 -0800
+++ a7/drivers/infiniband/ibp/drv/ibp-abi.h	2015-09-10 09:33:35.327932404 -0700
@@ -0,0 +1,649 @@
+/*
+ * Copyright (c) 2011-2013 Intel Corporation. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *	  copyright notice, this list of conditions and the following
+ *	  disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *	  copyright notice, this list of conditions and the following
+ *	  disclaimer in the documentation and/or other materials
+ *	  provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#ifndef IBP_ABI_H
+#define IBP_ABI_H
+
+#include <linux/types.h>
+
+/* Increment this value if any changes break compatibility. */
+#define IBP_ABI_VERSION	2
+
+/* Client to server message enums. */
+enum {
+	IBP_VERB_GET_PROTOCOL_STATS,
+	IBP_VERB_QUERY_DEVICE,
+	IBP_VERB_QUERY_PORT,
+	IBP_VERB_GET_LINK_LAYER,
+	IBP_VERB_QUERY_GID,
+	IBP_VERB_QUERY_PKEY,
+	IBP_VERB_MODIFY_DEVICE,
+	IBP_VERB_MODIFY_PORT,
+	IBP_VERB_ALLOC_UCONTEXT,
+	IBP_VERB_DEALLOC_UCONTEXT,
+	IBP_VERB_REG_BUF,
+	IBP_VERB_DEREG_BUF,
+	IBP_VERB_MMAP,
+	IBP_VERB_UNMMAP,
+	IBP_VERB_ALLOC_PD,
+	IBP_VERB_DEALLOC_PD,
+	IBP_VERB_CREATE_AH,
+	IBP_VERB_MODIFY_AH,
+	IBP_VERB_QUERY_AH,
+	IBP_VERB_DESTROY_AH,
+	IBP_VERB_CREATE_SRQ,
+	IBP_VERB_MODIFY_SRQ,
+	IBP_VERB_QUERY_SRQ,
+	IBP_VERB_DESTROY_SRQ,
+	IBP_VERB_POST_SRQ_RECV,
+	IBP_VERB_CREATE_QP,
+	IBP_VERB_MODIFY_QP,
+	IBP_VERB_QUERY_QP,
+	IBP_VERB_DESTROY_QP,
+	IBP_VERB_POST_SEND,
+	IBP_VERB_POST_RECV,
+	IBP_VERB_CREATE_CQ,
+	IBP_VERB_MODIFY_CQ,
+	IBP_VERB_DESTROY_CQ,
+	IBP_VERB_RESIZE_CQ,
+	IBP_VERB_POLL_CQ,
+	IBP_VERB_PEEK_CQ,
+	IBP_VERB_REQ_NOTIFY_CQ,
+	IBP_VERB_REQ_NCOMP_NOTIF,
+	IBP_VERB_GET_DMA_MR,
+	IBP_VERB_REG_PHYS_MR,
+	IBP_VERB_REG_USER_MR,
+	IBP_VERB_QUERY_MR,
+	IBP_VERB_DEREG_MR,
+	IBP_VERB_ALLOC_FAST_REG_MR,
+	IBP_VERB_ALLOC_FAST_REG_PAGE_LIST,
+	IBP_VERB_FREE_FAST_REG_PAGE_LIST,
+	IBP_VERB_REREG_PHYS_MR,
+	IBP_VERB_ALLOC_MW,
+	IBP_VERB_BIND_MW,
+	IBP_VERB_DEALLOC_MW,
+	IBP_VERB_ALLOC_FMR,
+	IBP_VERB_MAP_PHYS_FMR,
+	IBP_VERB_UNMAP_FMR,
+	IBP_VERB_DEALLOC_FMR,
+	IBP_VERB_ATTACH_MCAST,
+	IBP_VERB_DETACH_MCAST,
+	IBP_VERB_PROCESS_MAD,
+	IBP_VERB_ALLOC_XRCD,
+	IBP_VERB_DEALLOC_XRCD,
+};
+
+/* Server to client message enums. */
+enum {
+	IBP_ADD_DEVICE,
+	IBP_REMOVE_DEVICE,
+	IBP_VERB_RESPONSE,
+	IBP_QUEUED_RESPONSE,
+	IBP_ASYNC_EVENT,
+	IBP_CQ_COMP,
+};
+
+/*
+ * Make sure that all structs defined in this file are laid out to pack
+ * the same way on different architectures to avoid incompatibility.
+ *
+ * Specifically:
+ *  - Do not use pointer types -- pass pointers in a u64 instead.
+ *  - Make sure that any structure larger than 4 bytes is padded
+ *    to a multiple of 8 bytes; otherwise the structure size may
+ *    be different between architectures.
+ */
+
+struct ibp_msg_header {			/* present in all messages */
+	u32			opcode;
+	u32			length;
+	u32			status;
+	u32			reserved;
+	u64			device;
+	u64			request;
+	u64			data[0];
+};
+
+#define IBP_DEVICE_NAME_MAX	64
+
+struct ibp_add_device {
+	u8			name[IBP_DEVICE_NAME_MAX];
+	u32			vendor_id;
+	u32			device_id;
+	u64			ib_device;
+	u64			device;
+	__be64			node_guid;
+	u64			uverbs_cmd_mask;
+	u32			uverbs_abi_ver;
+	u32			ibp_abi_ver;
+	u32			num_comp_vectors;
+	u8			phys_port_cnt;
+	u8			reserved[7];
+};
+
+struct ibp_add_device_msg {
+	struct ibp_msg_header	header;
+	struct ibp_add_device	data;
+};
+
+struct ibp_remove_device_msg {
+	struct ibp_msg_header	header;
+};
+
+struct ibp_verb_response_msg {
+	struct ibp_msg_header	header;
+	u64			data[0];
+};
+
+struct ibp_queued_response_msg {
+	struct ibp_msg_header	header;
+	u64			data[0];
+};
+
+struct ibp_async_event {
+	u64			ibdev;
+	u64			context;
+	u32			type;
+	u8			reserved[4];
+};
+
+struct ibp_async_event_msg {
+	struct ibp_msg_header	header;
+	struct ibp_async_event	data;
+};
+
+struct ibp_cq_comp {
+	u64			cq_context;
+};
+
+struct ibp_cq_comp_msg {
+	struct ibp_msg_header	header;
+	struct ibp_cq_comp	data;
+};
+
+struct ibp_alloc_ucontext_cmd {
+	struct ibp_msg_header	header;
+	u64			ibdev;
+	u64			data[0];
+};
+
+struct ibp_alloc_ucontext_resp {
+	u64			ucontext;
+	u64			data[0];
+};
+
+struct ibp_dealloc_ucontext_cmd {
+	struct ibp_msg_header	header;
+	u64			ucontext;
+};
+
+struct ibp_mmap_cmd {
+	struct ibp_msg_header	header;
+	u64			len;
+	u64			prot;
+	u64			flags;
+	u64			pgoff;
+	u64			ucontext;
+};
+
+struct ibp_mmap_resp {
+	u64			mmap;
+	u64			scif_addr;
+};
+
+struct ibp_unmmap_cmd {
+	struct ibp_msg_header	header;
+	u64			mmap;
+};
+
+struct ibp_reg_buf_cmd {
+	struct ibp_msg_header	header;
+	u64			ucontext;
+	u64			virt_addr;
+	u64			scif_addr;
+	u64			length;
+	u32			offset;
+	u32			access;
+};
+
+struct ibp_reg_buf_resp {
+	u64			reg;
+};
+
+struct ibp_dereg_buf_cmd {
+	struct ibp_msg_header	header;
+	u64			reg;
+};
+
+struct ibp_query_device_cmd {
+	struct ibp_msg_header	header;
+};
+
+struct ibp_query_device_resp {
+	u64			fw_ver;
+	__be64			sys_image_guid;
+	u64			max_mr_size;
+	u64			page_size_cap;
+	u32			vendor_id;
+	u32			vendor_part_id;
+	u32			hw_ver;
+	u32			max_qp;
+	u32			max_qp_wr;
+	u32			device_cap_flags;
+	u32			max_sge;
+	u32			max_sge_rd;
+	u32			max_cq;
+	u32			max_cqe;
+	u32			max_mr;
+	u32			max_pd;
+	u32			max_qp_rd_atom;
+	u32			max_ee_rd_atom;
+	u32			max_res_rd_atom;
+	u32			max_qp_init_rd_atom;
+	u32			max_ee_init_rd_atom;
+	u32			atomic_cap;
+	u32			masked_atomic_cap;
+	u32			max_ee;
+	u32			max_rdd;
+	u32			max_mw;
+	u32			max_raw_ipv6_qp;
+	u32			max_raw_ethy_qp;
+	u32			max_mcast_grp;
+	u32			max_mcast_qp_attach;
+	u32			max_total_mcast_qp_attach;
+	u32			max_ah;
+	u32			max_fmr;
+	u32			max_map_per_fmr;
+	u32			max_srq;
+	u32			max_srq_wr;
+	u32			max_srq_sge;
+	u32			max_fast_reg_page_list_len;
+	u16			max_pkeys;
+	u8			local_ca_ack_delay;
+	u8			reserved[5];
+};
+
+struct ibp_query_port_cmd {
+	struct ibp_msg_header	header;
+	u8			port_num;
+	u8			reserved[7];
+};
+
+struct ibp_query_port_resp {
+	u32			port_cap_flags;
+	u32			max_msg_sz;
+	u32			bad_pkey_cntr;
+	u32			qkey_viol_cntr;
+	u32			gid_tbl_len;
+	u16			pkey_tbl_len;
+	u16			lid;
+	u16			sm_lid;
+	u8			state;
+	u8			max_mtu;
+	u8			active_mtu;
+	u8			lmc;
+	u8			max_vl_num;
+	u8			sm_sl;
+	u8			subnet_timeout;
+	u8			init_type_reply;
+	u8			active_width;
+	u8			active_speed;
+	u8			phys_state;
+	u8			link_layer;
+	u8			reserved[2];
+};
+
+struct ibp_query_gid_cmd {
+	struct ibp_msg_header	header;
+	u32			index;
+	u8			port_num;
+	u8			reserved[3];
+};
+
+struct ibp_query_gid_resp {
+	__be64			subnet_prefix;
+	__be64			interface_id;
+};
+
+struct ibp_query_pkey_cmd {
+	struct ibp_msg_header	header;
+	u32			index;
+	u8			port_num;
+	u8			reserved[3];
+};
+
+struct ibp_query_pkey_resp {
+	u16			pkey;
+	u8			reserved[6];
+};
+
+struct ibp_alloc_pd_cmd {
+	struct ibp_msg_header	header;
+	u64			ucontext;
+	u64			data[0];
+};
+
+struct ibp_alloc_pd_resp {
+	u64			pd;
+	u64			data[0];
+};
+
+struct ibp_dealloc_pd_cmd {
+	struct ibp_msg_header	header;
+	u64			pd;
+};
+
+struct ibp_global_route {
+	__be64			dgid_subnet_prefix;
+	__be64			dgid_interface_id;
+	u32			flow_label;
+	u8			sgid_index;
+	u8			hop_limit;
+	u8			traffic_class;
+	u8			reserved[1];
+};
+
+struct ibp_ah_attr {
+	struct ibp_global_route	grh;
+	u16			dlid;
+	u8			sl;
+	u8			src_path_bits;
+	u8			static_rate;
+	u8			ah_flags;
+	u8			port_num;
+	u8			reserved[1];
+};
+
+struct ibp_create_ah_cmd {
+	struct ibp_msg_header	header;
+	u64			pd;
+	struct ibp_ah_attr	ah_attr;
+};
+
+struct ibp_create_ah_resp {
+	u64			ah;
+};
+
+struct ibp_query_ah_cmd {
+	struct ibp_msg_header	header;
+	u64			ah;
+};
+
+struct ibp_query_ah_resp {
+	struct ibp_ah_attr	attr;
+};
+
+struct ibp_destroy_ah_cmd {
+	struct ibp_msg_header	header;
+	u64			ah;
+};
+
+struct ibp_srq_attr {
+	u32			max_wr;
+	u32			max_sge;
+	u32			srq_limit;
+	u8			reserved[4];
+};
+
+struct ibp_create_srq_cmd {
+	struct ibp_msg_header	header;
+	u64			pd;
+	u64			srq_context;
+	struct ibp_srq_attr	attr;
+	u64			data[0];
+};
+
+struct ibp_create_srq_resp {
+	u64			srq;
+	struct ibp_srq_attr	attr;
+	u64			data[0];
+};
+
+struct ibp_query_srq_cmd {
+	struct ibp_msg_header	header;
+	u64			srq;
+};
+
+struct ibp_query_srq_resp {
+	struct ibp_srq_attr	attr;
+};
+
+struct ibp_modify_srq_cmd {
+	struct ibp_msg_header	header;
+	u64			srq;
+	struct ibp_srq_attr	attr;
+	u32			srq_attr_mask;
+	u8			reserved[4];
+	u64			data[0];
+};
+
+struct ibp_modify_srq_resp {
+	struct ibp_srq_attr	attr;
+	u64			data[0];
+};
+
+struct ibp_destroy_srq_cmd {
+	struct ibp_msg_header	header;
+	u64			srq;
+};
+
+struct ibp_qp_cap {
+	u32			max_send_wr;
+	u32			max_recv_wr;
+	u32			max_send_sge;
+	u32			max_recv_sge;
+	u32			max_inline_data;
+	u8			reserved[4];
+};
+
+struct ibp_create_qp_cmd {
+	struct ibp_msg_header	header;
+	u64			pd;
+	u64			send_cq;
+	u64			recv_cq;
+	u64			srq;
+	u64			xrc_domain;
+	u64			qp_context;
+	struct ibp_qp_cap	cap;
+	u8			sq_sig_type;
+	u8			qp_type;
+	u8			create_flags;
+	u8			port_num;
+	u64			data[0];
+};
+
+struct ibp_create_qp_resp {
+	u64			qp;
+	struct ibp_qp_cap	cap;
+	u32			qpn;
+	u8			reserved[4];
+	u64			data[0];
+};
+
+struct ibp_query_qp_cmd {
+	struct ibp_msg_header	header;
+	u64			qp;
+	u32			qp_attr_mask;
+	u8			reserved[4];
+};
+
+struct ibp_query_qp_resp {
+	u32			qp_state;
+	u32			cur_qp_state;
+	u32			path_mtu;
+	u32			path_mig_state;
+	u32			qkey;
+	u32			rq_psn;
+	u32			sq_psn;
+	u32			dest_qp_num;
+	u32			qp_access_flags;
+	u32			init_create_flags;
+	struct ibp_qp_cap	init_cap;
+	struct ibp_qp_cap	cap;
+	struct ibp_ah_attr	ah;
+	struct ibp_ah_attr	alt_ah;
+	u16			pkey_index;
+	u16			alt_pkey_index;
+	u8			en_sqd_async_notify;
+	u8			sq_draining;
+	u8			max_rd_atomic;
+	u8			max_dest_rd_atomic;
+	u8			min_rnr_timer;
+	u8			port_num;
+	u8			timeout;
+	u8			retry_cnt;
+	u8			rnr_retry;
+	u8			alt_port_num;
+	u8			alt_timeout;
+	u8			init_sq_sig_type;
+};
+
+struct ibp_modify_qp_cmd {
+	struct ibp_msg_header	header;
+	u64			qp;
+	u32			qp_attr_mask;
+	u32			qp_state;
+	u32			cur_qp_state;
+	u32			path_mtu;
+	u32			path_mig_state;
+	u32			qkey;
+	u32			rq_psn;
+	u32			sq_psn;
+	u32			dest_qp_num;
+	u32			qp_access_flags;
+	struct ibp_qp_cap	cap;
+	struct ibp_ah_attr	ah;
+	struct ibp_ah_attr	alt_ah;
+	u16			pkey_index;
+	u16			alt_pkey_index;
+	u8			en_sqd_async_notify;
+	u8			sq_draining;
+	u8			max_rd_atomic;
+	u8			max_dest_rd_atomic;
+	u8			min_rnr_timer;
+	u8			port_num;
+	u8			timeout;
+	u8			retry_cnt;
+	u8			rnr_retry;
+	u8			alt_port_num;
+	u8			alt_timeout;
+	u8			reserved[1];
+	u64			data[0];
+};
+
+struct ibp_modify_qp_resp {
+	struct ibp_qp_cap	cap;
+	u64			data[0];
+};
+
+struct ibp_destroy_qp_cmd {
+	struct ibp_msg_header	header;
+	u64			qp;
+};
+
+struct ibp_create_cq_cmd {
+	struct ibp_msg_header	header;
+	u64			ucontext;
+	u64			cq_context;
+	u32			cqe;
+	u32			vector;
+	u64			data[0];
+};
+
+struct ibp_create_cq_resp {
+	u64			cq;
+	u32			cqe;
+	u8			reserved[4];
+	u64			data[0];
+};
+
+struct ibp_resize_cq_cmd {
+	struct ibp_msg_header	header;
+	u64			cq;
+	u32			cqe;
+	u8			reserved[4];
+	u64			data[0];
+};
+
+struct ibp_resize_cq_resp {
+	u32			cqe;
+	u8			reserved[4];
+	u64			data[0];
+};
+
+struct ibp_destroy_cq_cmd {
+	struct ibp_msg_header	header;
+	u64			cq;
+};
+
+struct ibp_reg_user_mr_cmd {
+	struct ibp_msg_header	header;
+	u64			pd;
+	u64			hca_va;
+	u64			scif_addr;
+	u64			length;
+	u32			offset;
+	u32			access;
+	u64			data[0];
+};
+
+struct ibp_reg_user_mr_resp {
+	u64			mr;
+	u32			lkey;
+	u32			rkey;
+	u64			data[0];
+};
+
+struct ibp_dereg_mr_cmd {
+	struct ibp_msg_header	header;
+	u64			mr;
+};
+
+struct ibp_attach_mcast_cmd {
+	struct ibp_msg_header	header;
+	u64			qp;
+	__be64			subnet_prefix;
+	__be64			interface_id;
+	u16			lid;
+	u8			data[6];
+};
+
+struct ibp_detach_mcast_cmd {
+	struct ibp_msg_header	header;
+	u64			qp;
+	__be64			subnet_prefix;
+	__be64			interface_id;
+	u16			lid;
+	u8			data[6];
+};
+
+#endif /* IBP_ABI_H */
diff -ruN a6/drivers/infiniband/ibp/drv/ibp.h a7/drivers/infiniband/ibp/drv/ibp.h
--- a6/drivers/infiniband/ibp/drv/ibp.h	1969-12-31 16:00:00.000000000 -0800
+++ a7/drivers/infiniband/ibp/drv/ibp.h	2015-09-10 09:33:35.328932470 -0700
@@ -0,0 +1,257 @@
+/*
+ * Copyright (c) 2011-2013 Intel Corporation. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *	  copyright notice, this list of conditions and the following
+ *	  disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *	  copyright notice, this list of conditions and the following
+ *	  disclaimer in the documentation and/or other materials
+ *	  provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#ifndef IBP_H
+#define IBP_H
+
+#include <rdma/ib_verbs.h>
+#include "ibp-abi.h"
+
+struct ibp_device {
+	char				name[IBP_DEVICE_NAME_MAX];
+	u32				vendor_id;
+	u32				device_id;
+	u64				ib_device;
+	u64				device;
+	__be64				node_guid;
+	u64				uverbs_cmd_mask;
+	u32				uverbs_abi_ver;
+	u32				ibp_abi_ver;
+	struct device			*linux_dev;
+	struct list_head		list;
+	u64				driver_data;
+	int				abi_version;
+	int				num_comp_vectors;
+	u8				phys_port_cnt;
+};
+
+struct ibp_id_table {
+	u32				vendor_id;
+	u32				device_id;
+};
+
+struct ibp_driver {
+	const char			*name;
+	const struct ibp_id_table	*id_table;
+	int				(*add)(struct ibp_device *device);
+	void				(*remove)(struct ibp_device *device);
+	u64				(*resolve)(struct ib_device *ibdev);
+
+	struct list_head		list;
+};
+
+struct ibp_rb {
+	u64				handle;
+};
+
+struct ibp_iomem {
+	void				*cookie;
+	void __iomem			*addr;
+};
+
+/**
+ * ibp_resolve_ib_device - Return the host ib_device handle
+ * @ibdev:Card IB device
+ *
+ * Upper level drivers may require the host ib_device handle associated
+ * with the card ib_device.  This routine resolves the card ib_device to
+ * the cooresponding host ib_device handle.  A value of 0 is returned if
+ * no match was found.
+ */
+u64 ibp_resolve_ib_device(struct ib_device *ibdev);
+
+/**
+ * ibp_register_driver - Register this driver
+ * @driver:Driver to register
+ *
+ * Lower level drivers use ibp_register_driver to register for callbacks
+ * on IB device addition and removal.  Only one low level driver registration
+ * is allowed for a each vendor/device id pair.  When an IB device is added,
+ * it is compared with each registered driver vendor and device id.  The add
+ * callback routine for the matching driver will be called.
+ */
+int ibp_register_driver(struct ibp_driver *driver);
+
+/**
+ * ibp_unregister_driver - Unregister this driver
+ * @client:Driver to unregister
+ *
+ * Lower level drivers use ibp_unregister_driver() to remove their
+ * registration.  When ibp_unregister_driver() is called, the driver
+ * will receive a remove callback for each IB device with matcing vendor
+ * and device ids.
+ */
+void ibp_unregister_driver(struct ibp_driver *driver);
+
+static inline void ibp_set_driver_data(struct ibp_device *device, u64 data)
+{
+	device->driver_data = data;
+}
+
+static inline u64 ibp_get_driver_data(struct ibp_device *device)
+{
+	return device->driver_data;
+}
+
+int ibp_cmd_alloc_ucontext(struct ibp_device *device, struct ib_device *ibdev,
+			   u64 *ucontext, struct ibp_alloc_ucontext_cmd *cmd,
+			   size_t cmd_size,
+			   struct ibp_alloc_ucontext_resp *resp,
+			   size_t resp_size);
+
+int ibp_cmd_dealloc_ucontext(struct ibp_device *device, u64 ucontext);
+
+/**
+ * ibp_reg_buf - Register a private buffer with this driver
+ * @device: the device on which to register
+ * @ucontext: peer driver ucontext handle
+ * @vaddr: starting virtual address of the buffer
+ * @length: length of the buffer
+ * @access: IB_ACCESS_xxx flags for buffer
+ *
+ * Lower level drivers use ibp_reg_buf() to register private buffers.
+ * Upon success, a pointer to a registered buffer structure is returned
+ * which contains an addr handle.  The addr handle can be shared with
+ * a peer driver on the host server for its use with ib_umem_get().
+ * This routine should not be used to register IB memory regions.
+ */
+struct ibp_rb *ibp_reg_buf(struct ibp_device *device, u64 ucontext,
+			   unsigned long vaddr, size_t length, int access);
+
+/**
+ * ibp_dereg_buf - Deregister a private buffer through this driver
+ * @device: the device on which to deregister
+ * @rb: pointer to the registered buffer structure; may be ERR or NULL
+ *
+ * Lower level drivers use ibp_dereg_buf() to deregister a private buffer.
+ */
+int ibp_dereg_buf(struct ibp_device *device, struct ibp_rb *rb);
+
+int ibp_cmd_mmap(struct ibp_device *device, u64 ucontext,
+		 struct vm_area_struct *vma);
+
+struct ibp_iomem *ibp_cmd_ioremap(struct ibp_device *device, u64 ucontext,
+				  phys_addr_t offset, unsigned long size);
+
+int ibp_cmd_iounmap(struct ibp_iomem *iomem);
+
+int ibp_cmd_query_device(struct ibp_device *device,
+			 struct ib_device_attr *device_attr);
+
+int ibp_cmd_query_port(struct ibp_device *device, u8 port_num,
+		       struct ib_port_attr *port_attr);
+
+int ibp_cmd_query_gid(struct ibp_device *device, u8 port_num, int index,
+		      union ib_gid *gid);
+
+int ibp_cmd_query_pkey(struct ibp_device *device, u8 port_num, int index,
+		       u16 *pkey);
+
+int ibp_cmd_alloc_pd(struct ibp_device *device, u64 ucontext, u64 *pd,
+		     struct ibp_alloc_pd_cmd *cmd, size_t cmd_size,
+		     struct ibp_alloc_pd_resp *resp, size_t resp_size);
+
+int ibp_cmd_dealloc_pd(struct ibp_device *device, u64 pd);
+
+int ibp_cmd_create_ah(struct ibp_device *device, u64 pd,
+		      struct ib_ah_attr *ah_attr,
+		      u64 *ah);
+
+int ibp_cmd_query_ah(struct ibp_device *device, u64 ah,
+		     struct ib_ah_attr *ah_attr);
+
+int ibp_cmd_destroy_ah(struct ibp_device *device, u64 ah);
+
+int ibp_cmd_create_srq(struct ibp_device *device, u64 pd,
+		       struct ib_srq_init_attr *init_attr,
+		       u64 *srq, struct ib_srq *ibsrq,
+		       struct ibp_create_srq_cmd *cmd, size_t cmd_size,
+		       struct ibp_create_srq_resp *resp, size_t resp_size);
+
+int ibp_cmd_query_srq(struct ibp_device *device, u64 srq,
+		      struct ib_srq_attr *attr);
+
+int ibp_cmd_modify_srq(struct ibp_device *device, u64 srq,
+		       struct ib_srq_attr *attr, enum ib_srq_attr_mask mask,
+		       struct ibp_modify_srq_cmd *cmd, size_t cmd_size,
+		       struct ibp_modify_srq_resp *resp, size_t resp_size);
+
+int ibp_cmd_destroy_srq(struct ibp_device *device, u64 srq);
+
+int ibp_cmd_create_qp(struct ibp_device *device, u64 pd,
+		      u64 send_cq, u64 recv_cq, u64 srq,
+		      struct ib_qp_init_attr *init_attr,
+		      u64 *qp, struct ib_qp *ibqp,
+		      struct ibp_create_qp_cmd *cmd, size_t cmd_size,
+		      struct ibp_create_qp_resp *resp, size_t resp_size);
+
+int ibp_cmd_query_qp(struct ibp_device *device, u64 qp,
+		     struct ib_qp_attr *attr, int qp_attr_mask,
+		     struct ib_qp_init_attr *init_attr);
+
+int ibp_cmd_modify_qp(struct ibp_device *device, u64 qp,
+		      struct ib_qp_attr *attr, int qp_attr_mask,
+		      struct ibp_modify_qp_cmd *cmd, size_t cmd_size,
+		      struct ibp_modify_qp_resp *resp, size_t resp_size);
+
+int ibp_cmd_destroy_qp(struct ibp_device *device, u64 qp);
+
+int ibp_cmd_create_cq(struct ibp_device *device, u64 ucontext,
+		      int entries, int vector, u64 *cq, struct ib_cq *ibcq,
+		      struct ibp_create_cq_cmd *cmd, size_t cmd_size,
+		      struct ibp_create_cq_resp *resp, size_t resp_size);
+
+int ibp_cmd_resize_cq(struct ibp_device *device, u64 cq,
+		      int entries, struct ib_cq *ibcq,
+		      struct ibp_resize_cq_cmd *cmd, size_t cmd_size,
+		      struct ibp_resize_cq_resp *resp, size_t resp_size);
+
+int ibp_cmd_destroy_cq(struct ibp_device *device, u64 cq);
+
+int ibp_cmd_reg_user_mr(struct ibp_device *device, u64 pd, u64 start,
+			u64 length, u64 virt_addr, int access, u64 *mr,
+			u32 *lkey, u32 *rkey,
+			struct ibp_reg_user_mr_cmd *cmd, size_t cmd_size,
+			struct ibp_reg_user_mr_resp *resp, size_t resp_size);
+
+int ibp_cmd_dereg_mr(struct ibp_device *device, u64 mr);
+
+int ibp_cmd_get_dma_mr(struct ibp_device *device, u64 pd, int access,
+		       u64 *mr, u32 *lkey, u32 *rkey);
+
+int ibp_cmd_attach_mcast(struct ibp_device *device, u64 qp,
+			 union ib_gid *gid, u16 lid);
+
+int ibp_cmd_detach_mcast(struct ibp_device *device, u64 qp,
+			 union ib_gid *gid, u16 lid);
+
+#endif /* IBP_H */
diff -ruN a6/drivers/infiniband/ibp/drv/Makefile a7/drivers/infiniband/ibp/drv/Makefile
--- a6/drivers/infiniband/ibp/drv/Makefile	1969-12-31 16:00:00.000000000 -0800
+++ a7/drivers/infiniband/ibp/drv/Makefile	2015-09-10 09:33:35.328932470 -0700
@@ -0,0 +1,26 @@
+KERNEL_V := $(shell uname -r)
+
+KDIR ?= /lib/modules/$(KERNEL_V)/build
+
+SCIF_INCL := /usr/src/kernels/$(KERNEL_V)/include/modules/
+
+obj-$(CONFIG_IBP_SERVER) += ibp_server.o
+
+ccflags-y += -I$(SCIF_INCL)
+ccflags-$(CONFIG_IBP_DEBUG) += -g -DIBP_DEBUG
+
+ibp_server-y :=		server.o	\
+			stack.o		\
+			server_msg.o
+
+default:
+	$(MAKE) -C $(KDIR) M=`pwd`
+
+modules_install:
+	$(MAKE) -C $(KDIR) M=`pwd` modules_install
+
+clean:
+	rm -rf *.ko *.o .*.ko.cmd .*.o.cmd *.mod.c Module.* modules.order .tmp_versions
+
+unix:
+	dos2unix *.[ch] Kconfig Makefile
diff -ruN a6/drivers/infiniband/ibp/drv/server.c a7/drivers/infiniband/ibp/drv/server.c
--- a6/drivers/infiniband/ibp/drv/server.c	1969-12-31 16:00:00.000000000 -0800
+++ a7/drivers/infiniband/ibp/drv/server.c	2015-09-17 08:39:39.412983116 -0700
@@ -0,0 +1,549 @@
+/*
+ * Copyright (c) 2011-2013 Intel Corporation. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *	  copyright notice, this list of conditions and the following
+ *	  disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *	  copyright notice, this list of conditions and the following
+ *	  disclaimer in the documentation and/or other materials
+ *	  provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include "server.h"
+
+MODULE_AUTHOR("Jerrie Coffman");
+MODULE_AUTHOR("Phil Cayton");
+MODULE_AUTHOR("Jay Sternberg");
+MODULE_LICENSE("Dual BSD/GPL");
+MODULE_DESCRIPTION(DRV_DESC);
+MODULE_VERSION(DRV_VERSION);
+
+MODULE_PARAM(port, port, int, IBP_PORT, "Connection port");
+MODULE_PARAM(backlog, backlog, int, 8, "Connection backlog");
+MODULE_PARAM(timeout, timeout, int, 1000, "Listen/Poll time in milliseconds");
+
+#ifdef IBP_DEBUG
+MODULE_PARAM(debug_level, debug_level, int, 0, "Debug: 0-none, 1-some, 2-all");
+#endif
+
+#ifdef MOFED
+void					*ibp_peer_mem_handle;
+invalidate_peer_memory			ib_invalidate;
+#endif
+
+struct rw_semaphore			list_rwsem;
+
+static struct class			*ibp_class;
+static struct task_struct		*listen_thread;
+
+static LIST_HEAD(device_list);
+static LIST_HEAD(client_list);
+static LIST_HEAD(cdev_list);
+
+static void ibp_add_one(struct ib_device *ib_dev);
+static void ibp_remove_one(struct ib_device *ib_dev);
+
+static struct ib_client ib_client = {
+	.name	= DRV_NAME,
+	.add	= ibp_add_one,
+	.remove	= ibp_remove_one
+};
+
+static int ibp_open(struct inode *inode, struct file *filp);
+static ssize_t ibp_write(struct file *filp, const char __user *buf,
+			 size_t count, loff_t *pos);
+static int ibp_close(struct inode *inode, struct file *filp);
+
+static const struct file_operations ibp_fops = {
+	.owner	 = THIS_MODULE,
+	.open	 = ibp_open,
+	.write	 = ibp_write,
+	.release = ibp_close,
+};
+
+static int ibp_create_cdev(struct ibp_client *client, uint16_t node)
+{
+	struct device			*device;
+	dev_t				devt;
+	int				ret;
+
+	ret = alloc_chrdev_region(&devt, 0, 1, DRV_BASE);
+	if (ret) {
+		print_err("alloc_chrdev_region returned %d\n", ret);
+		return ret;
+	}
+
+	cdev_init(&client->cdev, &ibp_fops);
+	client->cdev.owner = THIS_MODULE;
+
+	ret = cdev_add(&client->cdev, devt, 1);
+	if (ret) {
+		print_err("cdev_add returned %d\n", ret);
+		goto err0;
+	}
+
+	device = device_create(ibp_class, NULL, devt,
+			       NULL, DRV_BASE "%u", node);
+	if (IS_ERR(device)) {
+		ret = PTR_ERR(device);
+		goto err1;
+	}
+
+	/* Start on the cdev_list (until ibp_register_client). */
+	down_write(&list_rwsem);
+	list_add_tail(&client->list, &cdev_list);
+	up_write(&list_rwsem);
+
+	return 0;
+err1:
+	cdev_del(&client->cdev);
+err0:
+	unregister_chrdev_region(devt, 1);
+	return ret;
+}
+
+static void ibp_destroy_cdev(struct ibp_client *client)
+{
+	device_destroy(ibp_class, client->cdev.dev);
+	cdev_del(&client->cdev);
+	unregister_chrdev_region(client->cdev.dev, 1);
+}
+
+static struct ibp_client *ibp_create_client(scif_epd_t ep, uint16_t node)
+{
+	struct ibp_client		*client;
+	int				ret = -ENOMEM;
+
+	/* If a reconnect occurs while on the cdev_list just update the ep. */
+	down_read(&list_rwsem);
+	list_for_each_entry(client, &cdev_list, list) {
+		if (client->node == node) {
+			up_read(&list_rwsem);
+			scif_close(client->ep);
+			client->ep = ep;
+			return client;
+		}
+	}
+	up_read(&list_rwsem);
+
+	client = kzalloc(sizeof(*client), GFP_KERNEL);
+	if (!client) {
+		print_err("kzalloc failed\n");
+		goto err0;
+	}
+
+	client->ep = ep;
+	client->node = node;
+	atomic_set(&client->busy, 0);
+	atomic_set(&client->rx_in_process, 0);
+	init_waitqueue_head(&client->rx_wait_queue);
+	mutex_init(&client->ucontext_mutex);
+	INIT_LIST_HEAD(&client->ucontext_list);
+
+	client->workqueue = create_singlethread_workqueue(DRV_NAME);
+	if (!client->workqueue) {
+		print_err("create_singlethread_workqueue failed\n");
+		goto err1;
+	}
+
+	ret = ibp_create_cdev(client, node);
+	if (ret)
+		goto err2;
+
+	return client;
+err2:
+	destroy_workqueue(client->workqueue);
+err1:
+	kfree(client);
+err0:
+	return ERR_PTR(ret);
+}
+
+static void ibp_destroy_client(struct ibp_client *client)
+{
+	ibp_cleanup_ucontext(&client->ucontext_list);
+	scif_close(client->ep);
+	flush_workqueue(client->workqueue);
+	destroy_workqueue(client->workqueue);
+	ibp_destroy_cdev(client);
+	kfree(client);
+}
+
+static void ibp_register_client(struct ibp_client *client)
+{
+	struct ibp_device		*device;
+
+	down_write(&list_rwsem);
+
+	list_move(&client->list, &client_list);
+
+	list_for_each_entry(device, &device_list, list)
+		ibp_send_add(client, device);
+
+	up_write(&list_rwsem);
+}
+
+static void ibp_unregister_client(struct ibp_client *client)
+{
+	struct ibp_device		*device;
+
+	flush_workqueue(client->workqueue);
+
+	down_write(&list_rwsem);
+
+	list_del(&client->list);
+
+	list_for_each_entry(device, &device_list, list)
+		ibp_send_remove(client, device);
+
+	up_write(&list_rwsem);
+}
+
+static int ibp_open(struct inode *inode, struct file *filp)
+{
+	struct ibp_client		*client;
+
+	client = container_of(inode->i_cdev, struct ibp_client, cdev);
+
+	filp->private_data = client;
+
+	if (atomic_add_return(1, &client->busy) == 1)
+		ibp_register_client(client);
+
+	return 0;
+}
+
+static ssize_t ibp_write(struct file *filp, const char __user *buf,
+			 size_t count, loff_t *pos)
+{
+	struct ibp_client		*client;
+	void				*rx_buf;
+	void				*tx_buf;
+	int				ret = -ENOMEM;
+
+	client = filp->private_data;
+
+	rx_buf = (void *) __get_free_page(GFP_KERNEL);
+	if (!rx_buf) {
+		print_err("__get_free_page rx_buf failed\n");
+		goto err0;
+	}
+
+	tx_buf = (void *) __get_free_page(GFP_KERNEL);
+	if (!tx_buf) {
+		print_err("__get_free_page tx_buf failed\n");
+		goto err1;
+	}
+
+	ret = ibp_process_recvs(client, rx_buf, tx_buf);
+
+	free_page((uintptr_t) tx_buf);
+err1:
+	free_page((uintptr_t) rx_buf);
+err0:
+	return ret;
+}
+
+static int ibp_close(struct inode *inode, struct file *filp)
+{
+	struct ibp_client		*client;
+
+	client = filp->private_data;
+
+	if (atomic_sub_and_test(1, &client->busy)) {
+		ibp_unregister_client(client);
+		device_destroy(ibp_class, client->cdev.dev);
+		ibp_destroy_client(client);
+	}
+
+	return 0;
+}
+
+int ibp_get_device(struct ibp_device *device)
+{
+	struct ibp_device		*entry;
+
+	down_read(&list_rwsem);
+
+	list_for_each_entry(entry, &device_list, list) {
+		if (entry == device) {
+			kref_get(&device->ref);
+			break;
+		}
+	}
+
+	up_read(&list_rwsem);
+
+	return (entry == device) ? 0 : -ENODEV;
+}
+
+static void ibp_complete_device(struct kref *ref)
+{
+	struct ibp_device		*device;
+
+	device = container_of(ref, struct ibp_device, ref);
+	complete(&device->done);
+}
+
+void ibp_put_device(struct ibp_device *device)
+{
+	kref_put(&device->ref, ibp_complete_device);
+}
+
+static struct ibp_device *ibp_create_device(struct ib_device *ib_dev)
+{
+	struct ibp_device		*device;
+
+	device = kzalloc(sizeof(*device), GFP_KERNEL);
+	if (!device) {
+		print_err("kzalloc failed\n");
+		return ERR_PTR(-ENOMEM);
+	}
+	device->ib_dev = ib_dev;
+	kref_init(&device->ref);
+	init_completion(&device->done);
+
+	ib_set_client_data(ib_dev, &ib_client, device);
+
+	return device;
+}
+
+static void ibp_destroy_device(struct ibp_device *device)
+{
+	ibp_put_device(device);
+	wait_for_completion(&device->done);
+
+	ib_set_client_data(device->ib_dev, &ib_client, NULL);
+	kfree(device);
+}
+
+static void ibp_register_device(struct ibp_device *device)
+{
+	struct ibp_client		*client;
+
+	down_write(&list_rwsem);
+
+	list_add_tail(&device->list, &device_list);
+	list_for_each_entry(client, &client_list, list)
+		ibp_send_add(client, device);
+
+	up_write(&list_rwsem);
+}
+
+static void ibp_unregister_device(struct ibp_device *device)
+{
+	struct ibp_client		*client;
+
+	down_write(&list_rwsem);
+
+	list_for_each_entry(client, &client_list, list)
+		ibp_send_remove(client, device);
+
+	list_del(&device->list);
+
+	up_write(&list_rwsem);
+}
+
+static int ibp_ignore_ib_dev(struct ib_device *ib_dev)
+{
+	/*
+	 * Only allow PCI-based channel adapters and RNICs.
+	 * PCI is required in order to read the vendor id.
+	 */
+	return (!ib_dev->dma_device->bus			  ||
+		!ib_dev->dma_device->bus->name			  ||
+		strnicmp(ib_dev->dma_device->bus->name, "pci", 3) ||
+		((ib_dev->node_type != RDMA_NODE_IB_CA) &&
+		 (ib_dev->node_type != RDMA_NODE_RNIC))) ? 1 : 0;
+}
+
+static void ibp_add_one(struct ib_device *ib_dev)
+{
+	struct ibp_device		*device;
+
+	if (ibp_ignore_ib_dev(ib_dev))
+		return;
+
+	device = ibp_create_device(ib_dev);
+	if (IS_ERR(device))
+		return;
+
+	ibp_register_device(device);
+}
+
+static void ibp_remove_one(struct ib_device *ib_dev)
+{
+	struct ibp_device		*device;
+
+	device = ib_get_client_data(ib_dev, &ib_client);
+	if (!device)
+		return;
+
+	ibp_unregister_device(device);
+	ibp_destroy_device(device);
+}
+
+static int ibp_listen(void *data)
+{
+	struct ibp_client		*client;
+	struct scif_pollepd		listen;
+	struct scif_portID		peer;
+	scif_epd_t			ep;
+	int				ret;
+
+	listen.epd = scif_open();
+	if (!listen.epd) {
+		print_err("scif_open failed\n");
+		ret = -EIO;
+		goto err0;
+	}
+	listen.events = POLLIN;
+
+	ret = scif_bind(listen.epd, port);
+	if (ret < 0) {
+		print_err("scif_bind returned %d\n", ret);
+		goto err1;
+	}
+
+	ret = scif_listen(listen.epd, backlog);
+	if (ret) {
+		print_err("scif_listen returned %d\n", ret);
+		goto err1;
+	}
+
+	while (!kthread_should_stop()) {
+
+		schedule();
+
+		ret = scif_poll(&listen, 1, timeout);
+		if (ret == 0)	/* timeout */
+			continue;
+		if (ret < 0) {
+			print_err("scif_poll revents 0x%x\n", listen.revents);
+			continue;
+		}
+
+		ret = scif_accept(listen.epd, &peer, &ep, 0);
+		if (ret) {
+			print_err("scif_accept returned %d\n", ret);
+			continue;
+		}
+
+		print_dbg("accepted node %d port %d\n", peer.node, peer.port);
+
+		client = ibp_create_client(ep, peer.node);
+		if (IS_ERR(client)) {
+			ret = PTR_ERR(client);
+			print_err("ibp_create_client returned %d\n", ret);
+			scif_close(ep);
+		}
+	}
+err1:
+	scif_close(listen.epd);
+err0:
+	return ret;
+}
+
+static int __init ibp_server_init(void)
+{
+	int				ret;
+
+	print_info(DRV_SIGNON);
+
+	init_rwsem(&list_rwsem);
+
+	ret = ibp_init();
+	if (ret) {
+		print_err("ibp_init_server returned %d\n", ret);
+		return ret;
+	}
+
+	ibp_class = class_create(THIS_MODULE, "infiniband_proxy");
+	if (IS_ERR(ibp_class)) {
+		ret = PTR_ERR(ibp_class);
+		print_err("class_create returned %d\n", ret);
+		goto err0;
+	}
+
+	ret = ib_register_client(&ib_client);
+	if (ret) {
+		print_err("ib_register_client returned %d\n", ret);
+		goto err1;
+	}
+
+#ifdef MOFED
+	ibp_peer_mem_handle = ib_register_peer_memory_client(&ibp_peer_mem,
+							     &ib_invalidate);
+	if (IS_ERR(ibp_peer_mem_handle)) {
+		ret = PTR_ERR(ibp_peer_mem_handle);
+		print_err("ib_register_peer_memory_client returned %d\n", ret);
+		goto err2;
+	}
+#endif
+
+	/* Start a thread for inbound connections. */
+	listen_thread = kthread_run(ibp_listen, NULL, DRV_NAME);
+	if (IS_ERR(listen_thread)) {
+		ret = PTR_ERR(listen_thread);
+		print_err("kthread_run returned %d\n", ret);
+		goto err3;
+	}
+
+	return 0;
+err3:
+#ifdef MOFED
+	ib_unregister_peer_memory_client(ibp_peer_mem_handle);
+err2:
+#endif
+	ib_unregister_client(&ib_client);
+err1:
+	class_destroy(ibp_class);
+err0:
+	ibp_cleanup();
+	return ret;
+}
+
+static void __exit ibp_server_exit(void)
+{
+	struct ibp_client		*client;
+	struct ibp_client		*next;
+
+	kthread_stop(listen_thread);
+
+	list_for_each_entry_safe(client, next, &cdev_list, list)
+		ibp_destroy_client(client);
+
+#ifdef MOFED
+	ib_unregister_peer_memory_client(ibp_peer_mem_handle);
+#endif
+	ib_unregister_client(&ib_client);
+	class_destroy(ibp_class);
+
+	ibp_cleanup();
+
+	print_info(DRV_DESC " unloaded\n");
+}
+
+module_init(ibp_server_init);
+module_exit(ibp_server_exit);
diff -ruN a6/drivers/infiniband/ibp/drv/server.h a7/drivers/infiniband/ibp/drv/server.h
--- a6/drivers/infiniband/ibp/drv/server.h	1969-12-31 16:00:00.000000000 -0800
+++ a7/drivers/infiniband/ibp/drv/server.h	2015-09-10 09:33:35.329932324 -0700
@@ -0,0 +1,191 @@
+/*
+ * Copyright (c) 2011-2013 Intel Corporation. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *	  copyright notice, this list of conditions and the following
+ *	  disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *	  copyright notice, this list of conditions and the following
+ *	  disclaimer in the documentation and/or other materials
+ *	  provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#ifndef SERVER_H
+#define SERVER_H
+
+#include <linux/fs.h>
+#include <linux/cdev.h>
+#include <linux/anon_inodes.h>
+#include <linux/file.h>
+#include <rdma/ib_user_verbs.h>
+#include <rdma/ib_umem.h>
+#include "ibp-abi.h"
+#include "common.h"
+
+#define DRV_ROLE	"Server"
+#define DRV_NAME	"ibp_server"
+
+#define MAX_MSG_SIZE	PAGE_SIZE
+
+extern int			timeout;
+extern struct rw_semaphore	list_rwsem;
+
+struct ibp_device {
+	struct list_head	list;
+	struct ib_device	*ib_dev;
+	struct kref		ref;
+	struct completion	done;
+};
+
+struct ibp_client {
+	struct list_head	list;
+	scif_epd_t		ep;
+	struct workqueue_struct	*workqueue;
+	struct mutex		ucontext_mutex;
+	struct list_head	ucontext_list;
+	wait_queue_head_t	rx_wait_queue;
+	atomic_t		rx_in_process;
+	struct cdev		cdev;
+	atomic_t		busy;
+	uint16_t		node;
+};
+
+struct ibp_queued_response {
+	struct ibp_client	*client;
+	struct work_struct	work;
+	u64			msg[0];
+};
+
+struct ibp_event {
+	struct ibp_client	*client;
+	struct work_struct	work;
+	u64			context;
+	u64			ibdev;
+	enum ib_event_type	type;
+};
+
+struct ibp_comp {
+	struct ibp_client	*client;
+	struct work_struct	work;
+	void			*cq_context;
+};
+
+struct ibp_ucontext {
+	struct ib_ucontext	*ibucontext;
+	struct ibp_client	*client;
+	struct ibp_device	*device;
+	struct file		*filp;
+	struct ib_event_handler	event_handler;
+	u64			ibdev;
+	struct mutex		mutex;
+	struct list_head	list;
+	struct list_head	mmap_list;
+	struct rb_root		reg_tree;
+};
+
+struct ibp_qp {
+	struct ib_qp		*ibqp;
+	struct list_head	mcast;
+};
+
+struct ibp_mcast_entry {
+	struct list_head	list;
+	union ib_gid		gid;
+	u16			lid;
+};
+
+struct ibp_mmap {
+	struct list_head	list;
+	struct ibp_ucontext	*ucontext;
+	u64			len;
+	u64			prot;
+	u64			vaddr;
+	void __iomem		*io_addr;
+	off_t			scif_addr;
+};
+
+struct ibp_reg {
+	struct rb_node		node;
+	struct scif_range	*range;
+	struct ibp_ucontext	*ucontext;
+	struct kref		ref;
+	u64			virt_addr;
+	u64			length;
+	off_t			offset;
+	u32			access;
+};
+
+struct ibp_mr {
+	struct ib_mr		*ibmr;
+	struct ibp_reg		*reg;
+};
+
+#ifdef MOFED
+#include <rdma/peer_mem.h>
+extern struct peer_memory_client ibp_peer_mem;
+extern void			 *ibp_peer_mem_handle;
+extern invalidate_peer_memory    ib_invalidate;
+#else
+#define IBP_UMEM_MAX_PAGE_CHUNK						\
+	((PAGE_SIZE - offsetof(struct ib_umem_chunk, page_list)) /	\
+	 ((void *) &((struct ib_umem_chunk *) 0)->page_list[1] -	\
+	  (void *) &((struct ib_umem_chunk *) 0)->page_list[0]))
+#endif
+
+#define INIT_UDATA(udata, ibuf, obuf, ilen, olen)		\
+	do {							\
+		(udata)->ops		= &ibp_copy;		\
+		(udata)->inbuf		= (void *)(ibuf);	\
+		(udata)->outbuf		= (void *)(obuf);	\
+		(udata)->inlen		= (ilen);		\
+		(udata)->outlen		= (olen);		\
+	} while (0)
+
+#define IBP_INIT_MSG(handle, msg, size, op)			\
+	do {							\
+		(msg)->header.opcode	= IBP_##op;		\
+		(msg)->header.length	= (size);		\
+		(msg)->header.status	= 0;			\
+		(msg)->header.reserved	= 0;			\
+		(msg)->header.device	= (uintptr_t)(handle);	\
+		(msg)->header.request	= 0;			\
+	} while (0)
+
+#define IBP_INIT_RESP(handle, resp, size, op, req, stat)	\
+	do {							\
+		(resp)->header.opcode	= IBP_##op;		\
+		(resp)->header.length	= (size);		\
+		(resp)->header.status	= (stat);		\
+		(resp)->header.reserved	= 0;			\
+		(resp)->header.device	= (uintptr_t)(handle);	\
+		(resp)->header.request	= (req);		\
+	} while (0)
+
+int ibp_process_recvs(struct ibp_client *client, void *rx_buf, void *tx_buf);
+void ibp_cleanup_ucontext(struct list_head *ucontext_list);
+int ibp_send_add(struct ibp_client *client, struct ibp_device *device);
+int ibp_send_remove(struct ibp_client *client, struct ibp_device *device);
+int ibp_get_device(struct ibp_device *device);
+void ibp_put_device(struct ibp_device *device);
+
+#endif /* SERVER_H */
diff -ruN a6/drivers/infiniband/ibp/drv/server_msg.c a7/drivers/infiniband/ibp/drv/server_msg.c
--- a6/drivers/infiniband/ibp/drv/server_msg.c	1969-12-31 16:00:00.000000000 -0800
+++ a7/drivers/infiniband/ibp/drv/server_msg.c	2015-09-10 09:34:50.117900541 -0700
@@ -0,0 +1,3073 @@
+/*
+ * Copyright (c) 2011-2013 Intel Corporation. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *	  copyright notice, this list of conditions and the following
+ *	  disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *	  copyright notice, this list of conditions and the following
+ *	  disclaimer in the documentation and/or other materials
+ *	  provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <linux/delay.h>
+
+#include "server.h"
+#include "stack.h"
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(3,5,0)
+    #define MUNMAP(x,y,z)				\
+	do {						\
+	    down_write(&current->mm->mmap_sem);		\
+	    do_munmap(x,y,z);				\
+	    up_write(&current->mm->mmap_sem);		\
+	} while (0)
+#else
+    #define MUNMAP(x,y,z)				\
+	vm_munmap((unsigned long)y,z)
+#endif
+
+static struct ibp_stack			*o_stack;
+static struct ibp_stack			*a_stack;
+static struct ibp_stack			*c_stack;
+
+/*
+ * umem functions
+ */
+static int ibp_copy_from_udata(void *dest, struct ib_udata *udata, size_t len)
+{
+	size_t				bytes;
+
+	bytes = min(len, udata->inlen);
+
+	memcpy(dest, udata->inbuf, bytes);
+	if (bytes < len) {
+		memset(dest + bytes, 0, len - bytes);
+		return -EFAULT;
+	}
+	return 0;
+}
+
+static int ibp_copy_to_udata(struct ib_udata *udata, void *src, size_t len)
+{
+	size_t				bytes;
+
+	bytes = min(len, udata->outlen);
+
+	memcpy(udata->outbuf, src, bytes);
+	udata->outlen -= bytes;
+
+	return (bytes < len) ? -EFAULT : 0;
+}
+
+static struct ib_udata_ops ibp_copy = {
+	.copy_from = ibp_copy_from_udata,
+	.copy_to   = ibp_copy_to_udata
+};
+
+#ifdef MOFED
+
+static struct ibp_reg *__ibp_find_reg(struct ibp_ucontext *ucontext,
+				      unsigned long virt, size_t size)
+{
+	struct rb_node			*node;
+	struct ibp_reg			*reg;
+
+	node = ucontext->reg_tree.rb_node;
+
+	while (node) {
+		reg = rb_entry(node, struct ibp_reg, node);
+
+		if ((virt   == reg->virt_addr) &&
+		    (size   == reg->length))
+			return reg;
+
+		if (virt < reg->virt_addr)
+			node = node->rb_left;
+		else if (virt > reg->virt_addr)
+			node = node->rb_right;
+		else if (size < reg->length)
+			node = node->rb_left;
+		else if (size > reg->length)
+			node = node->rb_right;
+		else
+			node = node->rb_right;
+	}
+
+	return ERR_PTR(-EFAULT);
+}
+
+static struct ibp_reg *ibp_find_reg(struct ibp_ucontext *ucontext,
+				    unsigned long virt, size_t size)
+{
+	struct ibp_reg			*reg;
+
+	mutex_lock(&ucontext->mutex);
+	reg = __ibp_find_reg(ucontext, virt, size);
+	mutex_unlock(&ucontext->mutex);
+
+	return reg;
+}
+
+/* ibp_peer_acquire return code: 1 mine, 0 not mine */
+static int ibp_peer_acquire(unsigned long addr,
+			    size_t size, void* peer_mem_private_data,
+			    char* peer_mem_name, void** client_context)
+{
+	struct ibp_ucontext *ucontext;
+	struct ibp_reg	    *reg;
+
+	/* Verify private data is ours before ibp_ucontext cast. */
+	if (!peer_mem_name || !peer_mem_private_data ||
+	    strncmp(peer_mem_name, ibp_peer_mem.name,
+		    sizeof(ibp_peer_mem.name)))
+		return 0;
+
+	ucontext = (struct ibp_ucontext *) peer_mem_private_data;
+
+	reg = ibp_find_reg(ucontext, addr, size);
+	if (IS_ERR(reg)) {
+		print_err("ibp_find_reg returned %d\n", (int)PTR_ERR(reg));
+		return 0;
+	}
+
+	*client_context = (void *) reg;
+
+	return 1;
+}
+
+static int ibp_peer_get_pages(unsigned long addr, size_t size, int write,
+			      int force, struct sg_table *sg_head,
+			      void* client_context, void* core_context)
+{
+	struct ibp_reg	   *reg;
+	struct page	   *page;
+	struct scatterlist *sg;
+	void		   **va;
+	int npages, off, i, ret;
+
+	reg = (struct ibp_reg *) client_context;
+
+	off = (addr - reg->virt_addr) + reg->offset;
+	npages = PAGE_ALIGN(size + (off & ~PAGE_MASK)) >> PAGE_SHIFT;
+
+	ret = sg_alloc_table(sg_head, npages, GFP_KERNEL);
+	if (ret)
+		return ret;
+
+	va = reg->range->va;
+
+	for_each_sg(sg_head->sgl, sg, npages, i) {
+		page = vmalloc_to_page(va[i]);
+		if (!page) {
+			print_err("vmalloc_to_page failed\n");
+			ret = -EINVAL;
+			goto err;
+		}
+		sg_set_page(sg, page, PAGE_SIZE, 0);
+	}
+
+	return 0;
+err:
+	sg_free_table(sg_head);
+	return ret;
+}
+
+static int ibp_peer_dma_map(struct sg_table *sg_head, void *client_context,
+			    struct device *dma_device, int dmasync, int *nmap)
+{
+	DEFINE_DMA_ATTRS(attrs);
+	int ret = 0;
+
+	if (dmasync)
+		dma_set_attr(DMA_ATTR_WRITE_BARRIER, &attrs);
+
+	*nmap = dma_map_sg_attrs(dma_device,
+				 sg_head->sgl,
+				 sg_head->orig_nents,
+				 DMA_BIDIRECTIONAL,
+				 &attrs);
+
+	if (*nmap > 0)
+		sg_head->nents = *nmap;
+	else
+		ret = -ENOMEM;
+
+	return ret;
+}
+
+static int ibp_peer_dma_umap(struct sg_table *sg_head, void *client_context,
+			     struct device *dma_device)
+{
+	dma_unmap_sg(dma_device,
+		     sg_head->sgl,
+		     sg_head->nents,
+		     DMA_BIDIRECTIONAL);
+	return 0;
+}
+
+static void ibp_peer_put_pages(struct sg_table *sg_head, void *client_context)
+{
+	sg_free_table(sg_head);
+}
+
+static unsigned long ibp_peer_get_page_size(void *client_context)
+{
+	return PAGE_SIZE;
+}
+
+struct peer_memory_client ibp_peer_mem = {
+	.name		= DRV_NAME,
+	.version	= DRV_VERSION,
+	.acquire	= &ibp_peer_acquire,
+	.get_pages	= &ibp_peer_get_pages,
+	.dma_map	= &ibp_peer_dma_map,
+	.dma_unmap	= &ibp_peer_dma_umap,
+	.put_pages	= &ibp_peer_put_pages,
+	.get_page_size	= &ibp_peer_get_page_size,
+};
+
+#else /* MOFED */
+
+static struct ibp_reg *__ibp_find_reg(struct ibp_ucontext *ucontext,
+				      unsigned long virt, size_t size,
+				      int access)
+{
+	struct rb_node			*node;
+	struct ibp_reg			*reg;
+
+	node = ucontext->reg_tree.rb_node;
+
+	while (node) {
+		reg = rb_entry(node, struct ibp_reg, node);
+
+		if ((virt   == reg->virt_addr) &&
+		    (size   == reg->length)    &&
+		    (access == reg->access))
+			return reg;
+
+		if (virt < reg->virt_addr)
+			node = node->rb_left;
+		else if (virt > reg->virt_addr)
+			node = node->rb_right;
+		else if (size < reg->length)
+			node = node->rb_left;
+		else if (size > reg->length)
+			node = node->rb_right;
+		else if (access < reg->access)
+			node = node->rb_left;
+		else
+			node = node->rb_right;
+	}
+
+	return ERR_PTR(-EFAULT);
+}
+
+static struct ibp_reg *ibp_find_reg(struct ibp_ucontext *ucontext,
+				    unsigned long virt, size_t size,
+				    int access)
+{
+	struct ibp_reg			*reg;
+
+	mutex_lock(&ucontext->mutex);
+	reg = __ibp_find_reg(ucontext, virt, size, access);
+	mutex_unlock(&ucontext->mutex);
+
+	return reg;
+}
+
+static void __ibp_umem_release(struct ib_device *dev, struct ib_umem *umem,
+			       int dirty)
+{
+	struct scatterlist		*sg;
+	int				i;
+
+	if (umem->nmap > 0)
+		ib_dma_unmap_sg(dev, umem->sg_head.sgl,
+				umem->nmap, DMA_BIDIRECTIONAL);
+
+	if (umem->writable && dirty)
+		for_each_sg(umem->sg_head.sgl, sg, umem->npages, i)
+			set_page_dirty_lock(sg_page(sg));
+
+	sg_free_table(&umem->sg_head);
+}
+
+static struct ib_umem *ibp_umem_get(struct ib_ucontext *ibucontext,
+				    unsigned long addr, size_t size,
+				    int access, int dmasync)
+{
+	struct ibp_reg			*reg;
+	struct ib_umem			*umem;
+	struct device			*dma_device;
+	struct page			*page;
+	struct scatterlist		*sg;
+	void				**va;
+	dma_addr_t			*pa;
+	dma_addr_t			daddr;
+	unsigned int			dsize;
+	int				npages;
+	int				off;
+	int				i;
+	int				ret = 0;
+
+	DEFINE_DMA_ATTRS(attrs);
+
+	reg = ibp_find_reg(ibucontext->umem_private_data, addr, size, access);
+	if (IS_ERR(reg))
+		return  ERR_CAST(reg);
+
+	if (dmasync)
+		dma_set_attr(DMA_ATTR_WRITE_BARRIER, &attrs);
+
+	umem = kzalloc(sizeof(*umem), GFP_KERNEL);
+	if (!umem) {
+		print_err("kalloc failed\n");
+		return ERR_PTR(-ENOMEM);
+	}
+
+	umem->length    = size;
+	umem->offset    = addr & ~PAGE_MASK;
+	umem->page_size = PAGE_SIZE;
+	umem->pid	= get_task_pid(current, PIDTYPE_PID);
+	umem->writable  = !!(access & ~IB_ACCESS_REMOTE_READ);
+
+	dsize	   = 0;
+	daddr	   = 0;
+	va	   = reg->range->va;
+	pa	   = reg->range->phys_addr;
+	dma_device = ibucontext->device->dma_device;
+	off	   = (addr - reg->virt_addr) + reg->offset;
+	npages	   = PAGE_ALIGN(size + (off & ~PAGE_MASK)) >> PAGE_SHIFT;
+	off	 >>= PAGE_SHIFT;
+
+	ret = sg_alloc_table(&umem->sg_head, npages, GFP_KERNEL);
+	if (ret) {
+		print_err("sg_alloc_table failed\n");
+		goto err1;
+	}
+
+	/* Assume hugetlb unless proven otherwise. */
+	umem->hugetlb = 1;
+	for (i = 0; i < npages && umem->hugetlb; i++) {
+		if (!dsize) {
+			dsize = PAGE_SIZE;
+			daddr = pa[i + off];
+			/* Page must start on a huge page boundary. */
+			if ((daddr & ~HPAGE_MASK) >= PAGE_SIZE)
+				umem->hugetlb = 0;
+		} else if (daddr + dsize != pa[i + off])
+			/* Pages must be contiguous. */
+			umem->hugetlb = 0;
+		else {
+			dsize += PAGE_SIZE;
+			if (dsize == HPAGE_SIZE)
+				dsize = 0;
+		}
+	}
+	/* Page must end on a huge page boundary.*/
+	if (umem->hugetlb && ((daddr + dsize) & ~HPAGE_MASK))
+		umem->hugetlb = 0;
+
+	for_each_sg(umem->sg_head.sgl, sg, npages, i) {
+		page = vmalloc_to_page(va[i]);
+		if (!page) {
+			print_err("vmalloc_to_page failed\n");
+			ret = -EINVAL;
+			goto err2;
+		}
+		sg_set_page(sg, page, PAGE_SIZE, 0);
+	}
+
+	umem->npages = npages;
+
+	umem->nmap = ib_dma_map_sg_attrs(ibucontext->device,
+					 umem->sg_head.sgl,
+					 umem->npages,
+					 DMA_BIDIRECTIONAL,
+					 &attrs);
+	if (umem->nmap <= 0) {
+		print_err("map_sg_attrs failed\n");
+		ret = -ENOMEM;
+		goto err2;
+	}
+
+	return umem;
+err2:
+	__ibp_umem_release(ibucontext->device, umem, 0);
+err1:
+	put_pid(umem->pid);
+	kfree(umem);
+	return ERR_PTR(ret);
+}
+
+static void ibp_umem_release(struct ib_umem *umem)
+{
+	struct ib_ucontext		*ibucontext;
+
+	ibucontext = umem->context;
+
+	__ibp_umem_release(ibucontext->device, umem, 0);
+
+	put_pid(umem->pid);
+	kfree(umem);
+}
+
+static struct ib_umem_ops ibp_umem = {
+	.get	    = &ibp_umem_get,
+	.release    = &ibp_umem_release,
+};
+
+#endif	/* MOFED */
+
+static int ibp_send(scif_epd_t ep, void *buf, size_t len)
+{
+	int				ret;
+
+	while (len) {
+		ret = scif_send(ep, buf, (uint32_t) len, SCIF_SEND_BLOCK);
+		if (ret < 0) {
+			print_dbg("scif_send returned %d\n", ret);
+			return ret;
+		}
+		buf += ret;
+		len -= ret;
+	}
+
+	return 0;
+}
+
+static int ibp_recv(scif_epd_t ep, void *buf, size_t len)
+{
+	int				ret;
+
+	while (len) {
+		ret = scif_recv(ep, buf, (uint32_t) len, SCIF_RECV_BLOCK);
+		if (ret < 0) {
+			print_dbg("scif_recv returned %d\n", ret);
+			return ret;
+		}
+		buf += ret;
+		len -= ret;
+	}
+
+	return 0;
+}
+
+int ibp_send_add(struct ibp_client *client, struct ibp_device *device)
+{
+	struct pci_dev			*pdev;
+	struct ibp_add_device_msg	msg;
+
+	print_trace("in\n");
+
+	pdev = to_pci_dev(device->ib_dev->dma_device);
+
+	IBP_INIT_MSG(device, &msg, sizeof(msg), ADD_DEVICE);
+
+	strncpy(msg.data.name, device->ib_dev->name, sizeof(msg.data.name));
+	msg.data.vendor_id	  = pdev->vendor;
+	msg.data.device_id	  = pdev->device;
+
+	msg.data.ib_device	  = (uintptr_t) device->ib_dev;
+	msg.data.device		  = (uintptr_t) device;
+	msg.data.node_guid	  = device->ib_dev->node_guid;
+	msg.data.uverbs_cmd_mask  = device->ib_dev->uverbs_cmd_mask;
+	msg.data.uverbs_abi_ver	  = device->ib_dev->uverbs_abi_ver;
+	msg.data.ibp_abi_ver	  = IBP_ABI_VERSION;
+	msg.data.num_comp_vectors = device->ib_dev->num_comp_vectors;
+	msg.data.phys_port_cnt	  = device->ib_dev->phys_port_cnt;
+
+	return ibp_send(client->ep, &msg, sizeof(msg));
+}
+
+int ibp_send_remove(struct ibp_client *client, struct ibp_device *device)
+{
+	struct ibp_remove_device_msg	msg;
+
+	print_trace("in\n");
+
+	IBP_INIT_MSG(device, &msg, sizeof(msg), REMOVE_DEVICE);
+	return ibp_send(client->ep, &msg, sizeof(msg));
+}
+
+static void ibp_send_queued_response(struct work_struct *work)
+{
+	struct ibp_queued_response_msg	*msg;
+	struct ibp_queued_response	*resp;
+
+	resp = container_of(work, struct ibp_queued_response, work);
+	msg = (struct ibp_queued_response_msg *) resp->msg;
+
+	ibp_send(resp->client->ep, msg, msg->header.length);
+	kfree(resp);
+}
+
+static int ibp_queue_response(struct ibp_client *client,
+			      struct ibp_queued_response_msg *msg)
+{
+	struct ibp_queued_response	*resp;
+	size_t				len;
+
+	len = sizeof(*resp) + msg->header.length;
+
+	resp = kmalloc(len, GFP_ATOMIC);
+	if (!resp) {
+		print_err("kalloc failed\n");
+		return -ENOMEM;
+	}
+
+	resp->client = client;
+	memcpy(&resp->msg, msg, msg->header.length);
+
+	/* Queue to serialize behing any associated events. */
+	INIT_WORK(&resp->work, ibp_send_queued_response);
+	queue_work(client->workqueue, &resp->work);
+
+	return 0;
+}
+
+static int ibp_cmd_error(struct ibp_client *client,
+			 struct ibp_msg_header *hdr, void *tx_buf, int ret)
+{
+	struct ibp_verb_response_msg	*msg;
+	size_t				len;
+
+	msg = (struct ibp_verb_response_msg *) tx_buf;
+	len = sizeof(*msg);
+
+	IBP_INIT_RESP(hdr->device, msg, len, VERB_RESPONSE, hdr->request, ret);
+	return ibp_send(client->ep, msg, len);
+}
+
+static int ibp_cmd_bad_request(struct ibp_client *client,
+			       struct ibp_msg_header *hdr, void *tx_buf)
+{
+	print_dbg("opcode 0x%x\n", hdr->opcode);
+	return ibp_cmd_error(client, hdr, tx_buf, -EBADRQC);
+}
+
+static int ibp_cmd_not_supported(struct ibp_client *client,
+				 struct ibp_msg_header *hdr, void *tx_buf)
+{
+	print_dbg("opcode 0x%x\n", hdr->opcode);
+	return ibp_cmd_error(client, hdr, tx_buf, -ENOSYS);
+}
+
+static int ibp_cmd_query_device(struct ibp_client *client,
+				struct ibp_msg_header *hdr, void *tx_buf)
+{
+	struct ibp_device		*device;
+	struct ibp_verb_response_msg	*msg;
+	struct ibp_query_device_resp	*resp;
+	struct ib_device_attr		attr;
+	size_t				len;
+	int				ret;
+
+	print_trace("in\n");
+
+	device = (struct ibp_device *) hdr->device;
+	msg = (struct ibp_verb_response_msg *) tx_buf;
+	len = sizeof(*msg);
+
+	ret = ib_query_device(device->ib_dev, &attr);
+	if (ret) {
+		print_err("ib_query_device returned %d\n", ret);
+		goto send_resp;
+	}
+
+	resp = (struct ibp_query_device_resp *) msg->data;
+	len += sizeof(*resp);
+
+	resp->fw_ver			 = attr.fw_ver;
+	resp->sys_image_guid		 = attr.sys_image_guid;
+	resp->max_mr_size		 = attr.max_mr_size;
+	resp->page_size_cap		 = attr.page_size_cap;
+	resp->vendor_id			 = attr.vendor_id;
+	resp->vendor_part_id		 = attr.vendor_part_id;
+	resp->hw_ver			 = attr.hw_ver;
+	resp->max_qp			 = attr.max_qp;
+	resp->max_qp_wr			 = attr.max_qp_wr;
+	resp->device_cap_flags		 = attr.device_cap_flags;
+	resp->max_sge			 = attr.max_sge;
+	resp->max_sge_rd		 = attr.max_sge_rd;
+	resp->max_cq			 = attr.max_cq;
+	resp->max_cqe			 = attr.max_cqe;
+	resp->max_mr			 = attr.max_mr;
+	resp->max_pd			 = attr.max_pd;
+	resp->max_qp_rd_atom		 = attr.max_qp_rd_atom;
+	resp->max_ee_rd_atom		 = attr.max_ee_rd_atom;
+	resp->max_res_rd_atom		 = attr.max_res_rd_atom;
+	resp->max_qp_init_rd_atom	 = attr.max_qp_init_rd_atom;
+	resp->max_ee_init_rd_atom	 = attr.max_ee_init_rd_atom;
+	resp->atomic_cap		 = attr.atomic_cap;
+	resp->masked_atomic_cap		 = attr.masked_atomic_cap;
+	resp->max_ee			 = attr.max_ee;
+	resp->max_rdd			 = attr.max_rdd;
+	resp->max_mw			 = attr.max_mw;
+	resp->max_raw_ipv6_qp		 = attr.max_raw_ipv6_qp;
+	resp->max_raw_ethy_qp		 = attr.max_raw_ethy_qp;
+	resp->max_mcast_grp		 = attr.max_mcast_grp;
+	resp->max_mcast_qp_attach	 = attr.max_mcast_qp_attach;
+	resp->max_total_mcast_qp_attach  = attr.max_total_mcast_qp_attach;
+	resp->max_ah			 = attr.max_ah;
+	resp->max_fmr			 = attr.max_fmr;
+	resp->max_map_per_fmr		 = attr.max_map_per_fmr;
+	resp->max_srq			 = attr.max_srq;
+	resp->max_srq_wr		 = attr.max_srq_wr;
+	resp->max_srq_sge		 = attr.max_srq_sge;
+	resp->max_fast_reg_page_list_len = attr.max_fast_reg_page_list_len;
+	resp->max_pkeys			 = attr.max_pkeys;
+	resp->local_ca_ack_delay	 = attr.local_ca_ack_delay;
+
+send_resp:
+	IBP_INIT_RESP(device, msg, len, VERB_RESPONSE, hdr->request, ret);
+	return ibp_send(client->ep, msg, len);
+}
+
+static int ibp_cmd_query_port(struct ibp_client *client,
+			      struct ibp_msg_header *hdr, void *tx_buf)
+{
+	struct ibp_device		*device;
+	struct ibp_verb_response_msg	*msg;
+	struct ibp_query_port_cmd	*cmd;
+	struct ibp_query_port_resp	*resp;
+	struct ib_port_attr		attr;
+	size_t				len;
+	int				ret;
+
+	device	= (struct ibp_device *) hdr->device;
+	cmd	= (struct ibp_query_port_cmd *) hdr;
+	msg	= (struct ibp_verb_response_msg *) tx_buf;
+	len	= sizeof(*msg);
+
+	ret = ib_query_port(device->ib_dev, cmd->port_num, &attr);
+	if (ret) {
+		print_err("ib_query_port returned %d\n", ret);
+		goto send_resp;
+	}
+
+	resp = (struct ibp_query_port_resp *) msg->data;
+	len += sizeof(*resp);
+
+	resp->state		= attr.state;
+	resp->max_mtu		= attr.max_mtu;
+	resp->active_mtu	= attr.active_mtu;
+	resp->gid_tbl_len	= attr.gid_tbl_len;
+	resp->port_cap_flags	= attr.port_cap_flags;
+	resp->max_msg_sz	= attr.max_msg_sz;
+	resp->bad_pkey_cntr	= attr.bad_pkey_cntr;
+	resp->qkey_viol_cntr	= attr.qkey_viol_cntr;
+	resp->pkey_tbl_len	= attr.pkey_tbl_len;
+	resp->lid		= attr.lid;
+	resp->sm_lid		= attr.sm_lid;
+	resp->lmc		= attr.lmc;
+	resp->max_vl_num	= attr.max_vl_num;
+	resp->sm_sl		= attr.sm_sl;
+	resp->subnet_timeout	= attr.subnet_timeout;
+	resp->init_type_reply	= attr.init_type_reply;
+	resp->active_width	= attr.active_width;
+	resp->active_speed	= attr.active_speed;
+	resp->phys_state	= attr.phys_state;
+	resp->link_layer	= rdma_port_get_link_layer(device->ib_dev,
+							   cmd->port_num);
+
+send_resp:
+	IBP_INIT_RESP(device, msg, len, VERB_RESPONSE, hdr->request, ret);
+	return ibp_send(client->ep, msg, len);
+}
+
+static int ibp_cmd_query_gid(struct ibp_client *client,
+			     struct ibp_msg_header *hdr, void *tx_buf)
+{
+	struct ibp_device		*device;
+	struct ibp_verb_response_msg	*msg;
+	struct ibp_query_gid_cmd	*cmd;
+	struct ibp_query_gid_resp	*resp;
+	size_t				len;
+	union ib_gid			gid;
+	int				ret;
+
+	device	= (struct ibp_device *) hdr->device;
+	cmd	= (struct ibp_query_gid_cmd *) hdr;
+	msg	= (struct ibp_verb_response_msg *) tx_buf;
+	len	= sizeof(*msg);
+
+	ret = ib_query_gid(device->ib_dev, cmd->port_num, cmd->index, &gid);
+	if (ret) {
+		print_err("ib_query_gid returned %d\n", ret);
+		goto send_resp;
+	}
+
+	resp = (struct ibp_query_gid_resp *) msg->data;
+	len += sizeof(*resp);
+
+	resp->subnet_prefix = gid.global.subnet_prefix;
+	resp->interface_id  = gid.global.interface_id;
+
+send_resp:
+	IBP_INIT_RESP(device, msg, len, VERB_RESPONSE, hdr->request, ret);
+	return ibp_send(client->ep, msg, len);
+}
+
+static int ibp_cmd_query_pkey(struct ibp_client *client,
+			      struct ibp_msg_header *hdr, void *tx_buf)
+{
+	struct ibp_device		*device;
+	struct ibp_verb_response_msg	*msg;
+	struct ibp_query_pkey_cmd	*cmd;
+	struct ibp_query_pkey_resp	*resp;
+	size_t				len;
+	u16				pkey;
+	int				ret;
+
+	device	= (struct ibp_device *) hdr->device;
+	cmd	= (struct ibp_query_pkey_cmd *) hdr;
+	msg	= (struct ibp_verb_response_msg *) tx_buf;
+	len	= sizeof(*msg);
+
+	ret = ib_query_pkey(device->ib_dev, cmd->port_num, cmd->index, &pkey);
+	if (ret) {
+		print_err("ib_query_pkey returned %d\n", ret);
+		goto send_resp;
+	}
+	resp = (struct ibp_query_pkey_resp *) msg->data;
+	len += sizeof(*resp);
+
+	resp->pkey = pkey;
+
+send_resp:
+	IBP_INIT_RESP(device, msg, len, VERB_RESPONSE, hdr->request, ret);
+	return ibp_send(client->ep, msg, len);
+}
+
+static void ibp_async_event(struct work_struct *work)
+{
+	struct ibp_event		*event;
+	struct ibp_async_event_msg	msg;
+
+	event = container_of(work, struct ibp_event, work);
+
+	IBP_INIT_MSG(NULL, &msg, sizeof(msg), ASYNC_EVENT);
+
+	msg.data.context = (uintptr_t) event->context;
+	msg.data.type	 = event->type;
+
+	ibp_send(event->client->ep, &msg, sizeof(msg));
+
+	ibp_add_to_stack(a_stack, (void *) event);
+}
+
+static void ibp_event_handler(struct ib_event_handler *handler,
+			      struct ib_event *ibevent)
+{
+	struct ibp_ucontext	*ucontext;
+	struct ibp_client	*client;
+	struct ibp_event	*event;
+
+	ucontext = container_of(handler, struct ibp_ucontext, event_handler);
+
+	if (ucontext->ibucontext->closing) {
+		print_dbg("ignoring event, connection closing\n");
+		return;
+	}
+
+	event = (struct ibp_event *)
+		ibp_pull_from_stack(a_stack, sizeof(*event), GFP_ATOMIC);
+	if (!event) {
+		print_err("kalloc failed\n");
+		return;
+	}
+
+	client = ucontext->client;
+
+	event->client  = client;
+	event->context = ibevent->element.port_num;
+	event->type    = ibevent->event;
+	event->ibdev   = ucontext->ibdev;
+
+	INIT_WORK(&event->work, ibp_async_event);
+	queue_work(client->workqueue, &event->work);
+}
+
+static int ibp_mmap(struct file *filp, struct vm_area_struct *vma)
+{
+	struct ibp_ucontext		*ucontext;
+	struct ib_ucontext		*ibucontext;
+
+	ucontext = filp->private_data;
+	ibucontext = ucontext->ibucontext;
+
+	return (ibucontext->device->mmap) ?
+		ibucontext->device->mmap(ibucontext, vma) : -ENOSYS;
+}
+
+static const struct file_operations ibp_fops = {
+	.mmap = ibp_mmap,
+};
+
+static int ibp_cmd_alloc_ucontext(struct ibp_client *client,
+				  struct ibp_msg_header *hdr, void *tx_buf)
+{
+	struct ibp_device		*device;
+	struct ibp_verb_response_msg	*msg;
+	struct ibp_alloc_ucontext_cmd	*cmd;
+	struct ibp_alloc_ucontext_resp	*resp;
+	struct ibp_ucontext		*ucontext;
+	struct ib_ucontext		*ibucontext;
+	struct ib_udata			udata;
+	size_t				len;
+	size_t				outlen;
+	int				ret;
+
+	print_trace("in\n");
+
+	device	= (struct ibp_device *) hdr->device;
+	cmd	= (struct ibp_alloc_ucontext_cmd *) hdr;
+	msg	= (struct ibp_verb_response_msg *) tx_buf;
+	resp	= (struct ibp_alloc_ucontext_resp *) msg->data;
+	len	= hdr->length - sizeof(*cmd);
+	outlen	= MAX_MSG_SIZE - sizeof(*msg) - sizeof(*resp);
+
+	/* Workaround for len check in mlx5 driver (no impact to others) */
+	len += sizeof(struct ib_uverbs_cmd_hdr);
+
+	INIT_UDATA(&udata, cmd->data, resp->data, len, outlen);
+
+	len = sizeof(*msg);
+
+	ret = ibp_get_device(device);
+	if (ret) {
+		print_err("ibp_get_device returned %d\n", ret);
+		goto send_resp;
+	}
+
+	ucontext = kzalloc(sizeof(*ucontext), GFP_KERNEL);
+	if (!ucontext) {
+		print_err("kzalloc failed\n");
+		ret = -ENOMEM;
+		goto err1;
+	}
+	ucontext->device = device;
+
+	ibucontext = device->ib_dev->alloc_ucontext(device->ib_dev, &udata);
+	if (IS_ERR(ibucontext)) {
+		ret = PTR_ERR(ibucontext);
+		print_err("Invalid ibucontext %p\n", ibucontext);
+		goto err2;
+	}
+
+#ifdef MOFED
+	ibucontext->peer_mem_name = ibp_peer_mem.name;
+	ibucontext->peer_mem_private_data = ucontext;
+#else
+	ibucontext->umem_ops = &ibp_umem;
+	ibucontext->umem_private_data = ucontext;
+#endif
+
+	ibucontext->device = device->ib_dev;
+	ibucontext->closing = 0;
+
+	INIT_LIST_HEAD(&ibucontext->pd_list);
+	INIT_LIST_HEAD(&ibucontext->mr_list);
+	INIT_LIST_HEAD(&ibucontext->mw_list);
+	INIT_LIST_HEAD(&ibucontext->cq_list);
+	INIT_LIST_HEAD(&ibucontext->qp_list);
+	INIT_LIST_HEAD(&ibucontext->srq_list);
+	INIT_LIST_HEAD(&ibucontext->ah_list);
+	INIT_LIST_HEAD(&ibucontext->xrcd_list);
+
+	ucontext->filp = anon_inode_getfile("["DRV_NAME"]", &ibp_fops,
+					    ucontext, O_RDWR);
+	if (IS_ERR(ucontext->filp)) {
+		ret = PTR_ERR(ucontext->filp);
+		print_err("anon_inode_getfile returned %d\n", ret);
+		goto err3;
+	}
+
+	if (cmd->ibdev) {
+		ucontext->ibdev = cmd->ibdev;
+		INIT_IB_EVENT_HANDLER(&ucontext->event_handler, device->ib_dev,
+				      ibp_event_handler);
+		ret = ib_register_event_handler(&ucontext->event_handler);
+		if (ret) {
+			print_err("event_handler returned %d\n", ret);
+			goto err4;
+		}
+	}
+
+	ucontext->client = client;
+	ucontext->ibucontext = ibucontext;
+	mutex_init(&ucontext->mutex);
+	INIT_LIST_HEAD(&ucontext->mmap_list);
+	ucontext->reg_tree = RB_ROOT;
+
+	mutex_lock(&client->ucontext_mutex);
+	list_add_tail(&ucontext->list, &client->ucontext_list);
+	mutex_unlock(&client->ucontext_mutex);
+
+	len += sizeof(*resp);
+	len += outlen - udata.outlen;	/* add driver private data */
+
+	resp->ucontext = (uintptr_t)ucontext;
+
+	goto send_resp;
+
+err4:
+	fput(ucontext->filp);
+err3:
+	device->ib_dev->dealloc_ucontext(ibucontext);
+err2:
+	kfree(ucontext);
+err1:
+	ibp_put_device(device);
+
+send_resp:
+	IBP_INIT_RESP(device, msg, len, VERB_RESPONSE, hdr->request, ret);
+	return ibp_send(client->ep, msg, len);
+}
+
+static int ibp_cmd_dealloc_ucontext(struct ibp_client *client,
+				    struct ibp_msg_header *hdr, void *tx_buf)
+{
+	struct ibp_device		*device;
+	struct ibp_dealloc_ucontext_cmd	*cmd;
+	struct ibp_queued_response_msg	*msg;
+	struct ibp_ucontext		*ucontext;
+	struct ib_ucontext		*ibucontext;
+	size_t				len;
+	int				ret = -EINVAL;
+
+	print_trace("in\n");
+
+	device = (struct ibp_device *) hdr->device;
+	cmd = (struct ibp_dealloc_ucontext_cmd *) hdr;
+	ucontext = (struct ibp_ucontext *) cmd->ucontext;
+	msg = (struct ibp_queued_response_msg *) tx_buf;
+	len = sizeof(*msg);
+
+	if (IS_NULL_OR_ERR(ucontext)) {
+		print_err("Invalid ucontext %p\n", ucontext);
+		goto send_resp;
+	}
+
+	ibucontext = ucontext->ibucontext;
+
+	if (ucontext->ibdev)
+		ib_unregister_event_handler(&ucontext->event_handler);
+
+	fput(ucontext->filp);
+
+	if (device && device->ib_dev) {
+		ret = device->ib_dev->dealloc_ucontext(ibucontext);
+		if (ret) {
+			print_err("ib_dealloc_ucontext returned %d\n", ret);
+			goto send_resp;
+		}
+	}
+
+	mutex_lock(&client->ucontext_mutex);
+	list_del(&ucontext->list);
+	mutex_unlock(&client->ucontext_mutex);
+
+	ibp_put_device(device);
+	kfree(ucontext);
+
+send_resp:
+	IBP_INIT_RESP(device, msg, len, QUEUED_RESPONSE, hdr->request, ret);
+	return ibp_queue_response(client, msg);
+}
+
+static void ibp_dereg_buf(struct kref *ref)
+{
+	struct ibp_reg			*reg;
+	struct ibp_ucontext		*ucontext;
+
+	reg = container_of(ref, struct ibp_reg, ref);
+	ucontext = reg->ucontext;
+
+	if (!RB_EMPTY_NODE(&reg->node)) {
+		mutex_lock(&ucontext->mutex);
+		rb_erase(&reg->node, &ucontext->reg_tree);
+		mutex_unlock(&ucontext->mutex);
+	}
+
+	if (reg->range)
+		scif_put_pages(reg->range);
+
+	kfree(reg);
+}
+
+static struct ibp_reg *__ibp_insert_reg_buf(struct ibp_ucontext *ucontext,
+					    struct ibp_reg *reg)
+{
+	struct rb_node			**link;
+	struct rb_node			*parent;
+	struct ibp_reg			*cur_reg;
+
+	link = &ucontext->reg_tree.rb_node;
+	parent = NULL;
+
+	while (*link) {
+		parent = *link;
+		cur_reg = rb_entry(parent, struct ibp_reg, node);
+
+#ifdef MOFED
+		if ((reg->virt_addr == cur_reg->virt_addr) &&
+		    (reg->length    == cur_reg->length))
+			return cur_reg;
+#else
+		if ((reg->virt_addr == cur_reg->virt_addr) &&
+		    (reg->length    == cur_reg->length)	   &&
+		    (reg->access    == cur_reg->access))
+			return cur_reg;
+#endif
+
+		if (reg->virt_addr < cur_reg->virt_addr)
+			link = &(*link)->rb_left;
+		else if (reg->virt_addr > cur_reg->virt_addr)
+			link = &(*link)->rb_right;
+		else if (reg->length < cur_reg->length)
+			link = &(*link)->rb_left;
+		else if (reg->length > cur_reg->length)
+			link = &(*link)->rb_right;
+#ifndef MOFED
+		else if (reg->access < cur_reg->access)
+			link = &(*link)->rb_left;
+#endif
+		else
+			link = &(*link)->rb_right;
+	}
+
+	rb_link_node(&reg->node, parent, link);
+	rb_insert_color(&reg->node, &ucontext->reg_tree);
+
+	return NULL;
+}
+
+static struct ibp_reg *ibp_reg_buf(struct ibp_ucontext *ucontext,
+				   u64 virt_addr, u64 scif_addr, u64 length,
+				   u64 offset, u32 access)
+{
+	struct ibp_reg			*reg;
+	struct ibp_reg			*cur_reg;
+	int				ret;
+
+	reg = kzalloc(sizeof(*reg), GFP_KERNEL);
+	if (!reg) {
+		print_err("kzalloc failed\n");
+		return ERR_PTR(-ENOMEM);
+	}
+
+	kref_init(&reg->ref);
+	RB_CLEAR_NODE(&reg->node);
+	reg->ucontext  = ucontext;
+	reg->virt_addr = virt_addr;
+	reg->length    = length;
+	reg->offset    = offset;
+	reg->access    = access;
+
+	ret = scif_get_pages(ucontext->client->ep, scif_addr,
+			     PAGE_ALIGN(reg->length +
+			    (reg->virt_addr & ~PAGE_MASK)),
+			     &reg->range);
+	if (ret) {
+		print_err("scif_get_pages returned %d\n", ret);
+		kref_put(&reg->ref, ibp_dereg_buf);
+		return ERR_PTR(ret);
+	}
+
+	mutex_lock(&ucontext->mutex);
+
+	cur_reg = __ibp_insert_reg_buf(ucontext, reg);
+	if (cur_reg) {
+		print_dbg("__ibp_insert_reg_buf duplicate entry\n");
+		kref_get(&cur_reg->ref);
+	}
+
+	mutex_unlock(&ucontext->mutex);
+
+	if (cur_reg) {
+		kref_put(&reg->ref, ibp_dereg_buf);
+		reg = cur_reg;
+	}
+
+	return reg;
+}
+
+static int ibp_cmd_reg_buf(struct ibp_client *client,
+			   struct ibp_msg_header *hdr, void *tx_buf)
+{
+	struct ibp_device		*device;
+	struct ibp_reg_buf_cmd		*cmd;
+	struct ibp_reg_buf_resp		*resp;
+	struct ibp_ucontext		*ucontext;
+	struct ibp_verb_response_msg	*msg;
+	struct ibp_reg			*reg;
+	size_t				len;
+	int				ret = 0;
+
+	print_trace("in\n");
+
+	device = (struct ibp_device *) hdr->device;
+	cmd = (struct ibp_reg_buf_cmd *) hdr;
+	ucontext = (struct ibp_ucontext *) cmd->ucontext;
+	msg = (struct ibp_verb_response_msg *) tx_buf;
+	len = sizeof(*msg);
+
+	reg = ibp_reg_buf(ucontext, cmd->virt_addr, cmd->scif_addr,
+			  cmd->length, cmd->offset, cmd->access);
+	if (IS_ERR(reg)) {
+		ret = PTR_ERR(reg);
+		print_err("ibp_reg_buf returned %d\n", ret);
+		goto send_resp;
+	}
+
+	resp = (struct ibp_reg_buf_resp *) msg->data;
+	len += sizeof(*resp);
+
+	resp->reg = (uintptr_t)reg;
+
+send_resp:
+	IBP_INIT_RESP(device, msg, len, VERB_RESPONSE, hdr->request, ret);
+	return ibp_send(client->ep, msg, len);
+}
+
+static int ibp_cmd_dereg_buf(struct ibp_client *client,
+			     struct ibp_msg_header *hdr, void *tx_buf)
+{
+	struct ibp_device		*device;
+	struct ibp_dereg_buf_cmd	*cmd;
+	struct ibp_verb_response_msg	*msg;
+	struct ibp_reg			*reg;
+	size_t				len;
+
+	print_trace("in\n");
+
+	device	= (struct ibp_device *) hdr->device;
+	cmd	= (struct ibp_dereg_buf_cmd *) hdr;
+	reg	= (struct ibp_reg *) cmd->reg;
+	msg	= (struct ibp_verb_response_msg *) tx_buf;
+	len	= sizeof(*msg);
+
+	kref_put(&reg->ref, ibp_dereg_buf);
+
+	IBP_INIT_RESP(device, msg, len, VERB_RESPONSE, hdr->request, 0);
+	return ibp_send(client->ep, msg, len);
+}
+
+static int ibp_convert_prot_flags(unsigned long prot)
+{
+	int				prot_flags;
+
+	prot_flags = 0;
+
+	if (prot & PROT_READ)
+		prot_flags |= SCIF_PROT_READ;
+
+	if (prot & PROT_WRITE)
+		prot_flags |= SCIF_PROT_WRITE;
+
+	return prot_flags;
+}
+
+static int ibp_convert_map_flags(unsigned long flags)
+{
+	int				map_flags;
+
+	map_flags = SCIF_MAP_KERNEL;
+
+	if (flags & MAP_FIXED)
+		map_flags |= SCIF_MAP_FIXED;
+
+	return map_flags;
+}
+
+static int ibp_scif_register(struct ibp_client *client, struct ibp_mmap *mmap,
+			     unsigned long flags)
+{
+	struct vm_area_struct		*vma;
+	unsigned long			npages;
+	unsigned long			pfn;
+	int				offset;
+	int				ret;
+
+	print_trace("in\n");
+
+	offset = mmap->vaddr & ~PAGE_MASK;
+	npages = PAGE_ALIGN(mmap->len + offset) >> PAGE_SHIFT;
+	if (npages != 1) {
+		print_err("request %lu but only one page supported\n", npages);
+		return -EINVAL;
+	}
+
+	down_write(&current->mm->mmap_sem);
+	vma = find_vma(current->mm, mmap->vaddr);
+	if (!vma) {
+		up_write(&current->mm->mmap_sem);
+		print_err("find_vma failed\n");
+		return -EFAULT;
+	}
+
+	ret = follow_pfn(vma, mmap->vaddr, &pfn);
+
+	up_write(&current->mm->mmap_sem);
+	if (ret) {
+		print_err("follow_pfn returned %d\n", ret);
+		return ret;
+	}
+
+	mmap->io_addr = ioremap(page_to_phys(pfn_to_page(pfn)), mmap->len);
+	if (!mmap->io_addr) {
+		print_err("ioremap failed\n");
+		return -ENOMEM;
+	}
+
+	mmap->scif_addr = scif_register(client->ep, (void *) mmap->io_addr,
+					mmap->len, (off_t) mmap->io_addr,
+					ibp_convert_prot_flags(mmap->prot),
+					ibp_convert_map_flags(flags));
+	if (IS_ERR_VALUE(mmap->scif_addr)) {
+		ret = mmap->scif_addr;
+		print_err("scif_register returned %d\n", ret);
+		goto err0;
+
+	}
+
+	return 0;
+err0:
+	iounmap(mmap->io_addr);
+	return ret;
+}
+
+static
+void ibp_scif_unregister(struct ibp_client *client, struct ibp_mmap *mmap)
+{
+	int				ret;
+
+	print_trace("in\n");
+
+	ret = scif_unregister(client->ep, mmap->scif_addr, mmap->len);
+	if (ret) {
+		if (ret == -ECONNRESET)
+			print_dbg("scif connection reset\n");
+		else
+			print_err("scif_unregister returned %d\n", ret);
+	}
+
+	iounmap(mmap->io_addr);
+}
+
+static int ibp_cmd_mmap(struct ibp_client *client,
+			struct ibp_msg_header *hdr, void *tx_buf)
+{
+	struct ibp_device		*device;
+	struct ibp_mmap_cmd		*cmd;
+	struct ibp_mmap_resp		*resp;
+	struct ibp_ucontext		*ucontext;
+	struct ibp_verb_response_msg	*msg;
+	struct ibp_mmap			*mmap;
+	size_t				len;
+	int				ret;
+
+	print_trace("in\n");
+
+	device = (struct ibp_device *) hdr->device;
+	cmd = (struct ibp_mmap_cmd *) hdr;
+	ucontext = (struct ibp_ucontext *) cmd->ucontext;
+	msg = (struct ibp_verb_response_msg *) tx_buf;
+	len = sizeof(*msg);
+
+	mmap = kzalloc(sizeof(*mmap), GFP_KERNEL);
+	if (!mmap) {
+		print_err("kzalloc failed\n");
+		ret = -ENOMEM;
+		goto send_resp;
+	}
+	mmap->ucontext = ucontext;
+	mmap->len      = cmd->len;
+	mmap->prot     = cmd->prot;
+
+	/* The mmap syscall ignores these bits; do the same here. */
+	cmd->flags &= ~(MAP_EXECUTABLE | MAP_DENYWRITE);
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(3,5,0)
+	down_write(&current->mm->mmap_sem);
+	mmap->vaddr = do_mmap_pgoff(ucontext->filp, 0, cmd->len,
+				    cmd->prot, cmd->flags, cmd->pgoff);
+	up_write(&current->mm->mmap_sem);
+#else
+	mmap->vaddr = vm_mmap(ucontext->filp, 0, cmd->len, cmd->prot,
+			      cmd->flags, cmd->pgoff << PAGE_SHIFT);
+#endif
+
+	if (mmap->vaddr & ~PAGE_MASK) {
+		ret = mmap->vaddr;
+		print_err("mmap returned %d\n", ret);
+		goto err1;
+	}
+
+	ret = ibp_scif_register(client, mmap, cmd->flags);
+	if (ret) {
+		print_err("ibp_scif_register returned %d\n", ret);
+		goto err2;
+	}
+
+	mutex_lock(&ucontext->mutex);
+	list_add_tail(&mmap->list, &ucontext->mmap_list);
+	mutex_unlock(&ucontext->mutex);
+
+	resp = (struct ibp_mmap_resp *) msg->data;
+	len += sizeof(*resp);
+
+	resp->scif_addr = mmap->scif_addr;
+	resp->mmap	= (uintptr_t)mmap;
+
+	goto send_resp;
+err2:
+	MUNMAP(current->mm, mmap->vaddr, cmd->len);
+err1:
+	kfree(mmap);
+
+send_resp:
+	IBP_INIT_RESP(device, msg, len, VERB_RESPONSE, hdr->request, ret);
+	return ibp_send(client->ep, msg, len);
+}
+
+static int ibp_cmd_unmmap(struct ibp_client *client,
+			  struct ibp_msg_header *hdr, void *tx_buf)
+{
+	struct ibp_device		*device;
+	struct ibp_unmmap_cmd		*cmd;
+	struct ibp_mmap			*mmap;
+	struct ibp_verb_response_msg	*msg;
+	size_t				len;
+	int				ret = 0;
+
+	print_trace("in\n");
+
+	device	= (struct ibp_device *) hdr->device;
+	cmd	= (struct ibp_unmmap_cmd *) hdr;
+	mmap	= (struct ibp_mmap *) cmd->mmap;
+	msg	= (struct ibp_verb_response_msg *) tx_buf;
+	len	= sizeof(*msg);
+
+	if (IS_NULL_OR_ERR(mmap)) {
+		print_err("Invalid mmap %p\n", mmap);
+		ret = -EINVAL;
+		goto send_resp;
+	}
+
+	ibp_scif_unregister(client, mmap);
+
+	if (IS_NULL_OR_ERR(current) || IS_NULL_OR_ERR(current->mm)) {
+		print_err("Invalid current mm pointer\n");
+		ret = -EINVAL;
+		goto send_resp;
+	}
+
+	MUNMAP(current->mm, mmap->vaddr, mmap->len);
+
+	if (mmap->ucontext) {
+		mutex_lock(&mmap->ucontext->mutex);
+		list_del(&mmap->list);
+		mutex_unlock(&mmap->ucontext->mutex);
+	}
+
+	kfree(mmap);
+send_resp:
+	IBP_INIT_RESP(device, msg, len, VERB_RESPONSE, hdr->request, ret);
+	return ibp_send(client->ep, msg, len);
+}
+
+static struct ib_uobject *ibp_create_uobj(struct ibp_ucontext *ucontext)
+{
+	static struct lock_class_key	__key;
+	struct ib_uobject		*uobj;
+
+	if (IS_NULL_OR_ERR(ucontext))
+		return ERR_PTR(-EINVAL);
+
+	uobj = (struct ib_uobject *)
+		ibp_pull_from_stack(o_stack, sizeof(*uobj), GFP_ATOMIC);
+	if (!uobj)
+		return ERR_PTR(-ENOMEM);
+
+	/*
+	 * the uobj struct is updated since this is kernel-to-kernel,
+	 * so this structure is not fully setup as in ib_uverbs.
+	 */
+	uobj->context	  = ucontext->ibucontext;
+	uobj->user_handle = (uintptr_t)ucontext;
+	kref_init(&uobj->ref);
+	init_rwsem(&uobj->mutex);
+	INIT_LIST_HEAD(&uobj->list);
+	lockdep_set_class(&uobj->mutex, &__key);
+	uobj->live = 1;
+
+	return uobj;
+}
+
+static void ibp_destroy_uobj(struct ib_uobject *uobj)
+{
+	struct ibp_ucontext		*ucontext;
+
+	if (!IS_NULL_OR_ERR(uobj)) {
+		ucontext = (struct ibp_ucontext *) uobj->user_handle;
+
+		mutex_lock(&ucontext->mutex);
+		list_del(&uobj->list);
+		mutex_unlock(&ucontext->mutex);
+
+		ibp_add_to_stack(o_stack, (void *) uobj);
+	}
+}
+
+static int ibp_cmd_alloc_pd(struct ibp_client *client,
+			    struct ibp_msg_header *hdr, void *tx_buf)
+{
+	struct ibp_device		*device;
+	struct ibp_verb_response_msg	*msg;
+	struct ibp_alloc_pd_cmd		*cmd;
+	struct ibp_alloc_pd_resp	*resp;
+	struct ibp_ucontext		*ucontext;
+	struct ib_uobject		*uobj;
+	struct ib_udata			udata;
+	struct ib_pd			*pd;
+	size_t				len;
+	size_t				outlen;
+	int				ret = 0;
+
+	print_trace("in\n");
+
+	device = (struct ibp_device *) hdr->device;
+	cmd = (struct ibp_alloc_pd_cmd *) hdr;
+	ucontext = (struct ibp_ucontext *) cmd->ucontext;
+	msg = (struct ibp_verb_response_msg *) tx_buf;
+	resp = (struct ibp_alloc_pd_resp *) msg->data;
+	len  = hdr->length - sizeof(*cmd);
+	outlen = MAX_MSG_SIZE - sizeof(*msg) - sizeof(*resp);
+
+	INIT_UDATA(&udata, cmd->data, resp->data, len, outlen);
+
+	len = sizeof(*msg);
+
+	uobj = ibp_create_uobj(ucontext);
+	if (IS_ERR(uobj)) {
+		ret = PTR_ERR(uobj);
+		print_err("ibp_create_uobj returned %d\n", ret);
+		goto send_resp;
+	}
+
+	pd = device->ib_dev->alloc_pd(device->ib_dev, ucontext->ibucontext,
+				      &udata);
+	if (IS_ERR(pd)) {
+		ret = PTR_ERR(pd);
+		print_err("ib_alloc_pd returned %d\n", ret);
+		ibp_destroy_uobj(uobj);
+		goto send_resp;
+	}
+
+	pd->device = device->ib_dev;
+	atomic_set(&pd->usecnt, 0);
+
+	pd->uobject  = uobj;
+	uobj->object = pd;
+
+	mutex_lock(&ucontext->mutex);
+	list_add_tail(&uobj->list, &ucontext->ibucontext->pd_list);
+	mutex_unlock(&ucontext->mutex);
+
+	len += sizeof(*resp);
+	len += outlen - udata.outlen;	/* add driver private data */
+
+	resp->pd = (uintptr_t)pd;
+
+send_resp:
+	IBP_INIT_RESP(device, msg, len, VERB_RESPONSE, hdr->request, ret);
+	return ibp_send(client->ep, msg, len);
+}
+
+static int ibp_cmd_dealloc_pd(struct ibp_client *client,
+			      struct ibp_msg_header *hdr, void *tx_buf)
+{
+	struct ibp_device		*device;
+	struct ibp_dealloc_pd_cmd	*cmd;
+	struct ibp_verb_response_msg	*msg;
+	struct ib_uobject		*uobj;
+	struct ib_pd			*pd;
+	size_t				len;
+	int				ret;
+
+	print_trace("in\n");
+
+	device	= (struct ibp_device *) hdr->device;
+	cmd	= (struct ibp_dealloc_pd_cmd *) hdr;
+	pd	= (struct ib_pd *) cmd->pd;
+	msg	= (struct ibp_verb_response_msg *) tx_buf;
+	len	= sizeof(*msg);
+
+	if (IS_NULL_OR_ERR(pd)) {
+		print_err("Invalid pd %p\n", pd);
+		ret = -EINVAL;
+		goto send_resp;
+	}
+
+	uobj = pd->uobject;
+
+	ret = ib_dealloc_pd(pd);
+	if (unlikely(ret == -EBUSY)) {
+		msleep(100);
+		ret = ib_dealloc_pd(pd);
+	}
+	if (ret) {
+		print_err("ib_dealloc_pd returned %d\n", ret);
+		goto send_resp;
+	}
+
+	ibp_destroy_uobj(uobj);
+
+send_resp:
+	IBP_INIT_RESP(device, msg, len, VERB_RESPONSE, hdr->request, ret);
+	return ibp_send(client->ep, msg, len);
+}
+
+static int ibp_cmd_create_ah(struct ibp_client *client,
+			     struct ibp_msg_header *hdr, void *tx_buf)
+{
+	struct ibp_device		*device;
+	struct ibp_verb_response_msg	*msg;
+	struct ibp_create_ah_cmd	*cmd;
+	struct ibp_create_ah_resp	*resp;
+	struct ibp_ucontext		*ucontext;
+	struct ib_uobject		*uobj;
+	struct ib_pd			*pd;
+	struct ib_ah			*ah;
+	struct ib_ah_attr		attr;
+	size_t				len;
+	int				ret = 0;
+
+	print_trace("in\n");
+
+	device	= (struct ibp_device *) hdr->device;
+	cmd	= (struct ibp_create_ah_cmd *) hdr;
+	pd	= (struct ib_pd *) cmd->pd;
+	msg	= (struct ibp_verb_response_msg *) tx_buf;
+	len	= sizeof(*msg);
+
+	ucontext = (struct ibp_ucontext *) pd->uobject->user_handle;
+
+	uobj = ibp_create_uobj(ucontext);
+	if (IS_ERR(uobj)) {
+		ret = PTR_ERR(uobj);
+		print_err("ibp_create_uobj returned %d\n", ret);
+		goto send_resp;
+	}
+
+	memset(&attr, 0, sizeof(attr));
+
+	attr.dlid			   = cmd->ah_attr.dlid;
+	attr.sl				   = cmd->ah_attr.sl;
+	attr.src_path_bits		   = cmd->ah_attr.src_path_bits;
+	attr.static_rate		   = cmd->ah_attr.static_rate;
+	attr.ah_flags			   = cmd->ah_attr.ah_flags;
+	attr.port_num			   = cmd->ah_attr.port_num;
+	attr.grh.dgid.global.subnet_prefix =
+			cmd->ah_attr.grh.dgid_subnet_prefix;
+	attr.grh.dgid.global.interface_id  = cmd->ah_attr.grh.dgid_interface_id;
+	attr.grh.flow_label		   = cmd->ah_attr.grh.flow_label;
+	attr.grh.sgid_index		   = cmd->ah_attr.grh.sgid_index;
+	attr.grh.hop_limit		   = cmd->ah_attr.grh.hop_limit;
+	attr.grh.traffic_class		   = cmd->ah_attr.grh.traffic_class;
+
+	ah = ib_create_ah(pd, &attr);
+	if (IS_ERR(ah)) {
+		ret = PTR_ERR(ah);
+		print_err("ib_create_ah returned %d\n", ret);
+		ibp_destroy_uobj(uobj);
+		goto send_resp;
+	}
+
+	ah->uobject  = uobj;
+	uobj->object = ah;
+
+	mutex_lock(&ucontext->mutex);
+	list_add_tail(&uobj->list, &ucontext->ibucontext->ah_list);
+	mutex_unlock(&ucontext->mutex);
+
+	resp = (struct ibp_create_ah_resp *) msg->data;
+	len += sizeof(*resp);
+
+	resp->ah = (uintptr_t) ah;
+
+send_resp:
+	IBP_INIT_RESP(device, msg, len, VERB_RESPONSE, hdr->request, ret);
+	return ibp_send(client->ep, msg, len);
+}
+
+static int ibp_cmd_query_ah(struct ibp_client *client,
+			    struct ibp_msg_header *hdr, void *tx_buf)
+{
+	struct ibp_device		*device;
+	struct ibp_query_ah_cmd		*cmd;
+	struct ibp_query_ah_resp	*resp;
+	struct ibp_verb_response_msg	*msg;
+	struct ib_ah			*ah;
+	struct ib_ah_attr		attr;
+	size_t				len;
+	int				ret;
+
+	print_trace("in\n");
+
+	device	= (struct ibp_device *) hdr->device;
+	cmd	= (struct ibp_query_ah_cmd *) hdr;
+	ah	= (struct ib_ah *) cmd->ah;
+	msg	= (struct ibp_verb_response_msg *) tx_buf;
+	len	= sizeof(*msg);
+
+	ret = ib_query_ah(ah, &attr);
+	if (ret) {
+		print_err("ib_query_ah returned %d\n", ret);
+		goto send_resp;
+	}
+
+	resp = (struct ibp_query_ah_resp *) msg->data;
+	len += sizeof(*resp);
+
+	resp->attr.dlid			  = attr.dlid;
+	resp->attr.sl			  = attr.sl;
+	resp->attr.src_path_bits	  = attr.src_path_bits;
+	resp->attr.static_rate		  = attr.static_rate;
+	resp->attr.ah_flags		  = attr.ah_flags;
+	resp->attr.port_num		  = attr.port_num;
+	resp->attr.grh.dgid_subnet_prefix = attr.grh.dgid.global.subnet_prefix;
+	resp->attr.grh.dgid_interface_id  = attr.grh.dgid.global.interface_id;
+	resp->attr.grh.flow_label	  = attr.grh.flow_label;
+	resp->attr.grh.sgid_index	  = attr.grh.sgid_index;
+	resp->attr.grh.hop_limit	  = attr.grh.hop_limit;
+	resp->attr.grh.traffic_class	  = attr.grh.traffic_class;
+
+send_resp:
+	IBP_INIT_RESP(device, msg, len, VERB_RESPONSE, hdr->request, ret);
+	return ibp_send(client->ep, msg, len);
+}
+
+static int ibp_cmd_destroy_ah(struct ibp_client *client,
+			      struct ibp_msg_header *hdr, void *tx_buf)
+{
+	struct ibp_device		*device;
+	struct ibp_verb_response_msg	*msg;
+	struct ibp_destroy_ah_cmd	*cmd;
+	struct ib_uobject		*uobj;
+	struct ib_ah			*ah;
+	size_t				len;
+	int				ret;
+
+	print_trace("in\n");
+
+	device	= (struct ibp_device *) hdr->device;
+	cmd	= (struct ibp_destroy_ah_cmd *) hdr;
+	msg	= (struct ibp_verb_response_msg *) tx_buf;
+	ah	= (struct ib_ah *) cmd->ah;
+	len	= sizeof(*msg);
+
+	uobj = ah->uobject;
+
+	ret = ib_destroy_ah(ah);
+	if (ret) {
+		print_err("ib_destroy_ah returned %d\n", ret);
+		goto send_resp;
+	}
+
+	ibp_destroy_uobj(uobj);
+
+send_resp:
+	IBP_INIT_RESP(device, msg, len, VERB_RESPONSE, hdr->request, ret);
+	return ibp_send(client->ep, msg, len);
+}
+
+static void ibp_ibsrq_event(struct ib_event *ibevent, void *srq_context)
+{
+	struct ibp_ucontext		*ucontext;
+	struct ibp_client		*client;
+	struct ibp_event		*event;
+	struct ib_uobject		*uobj;
+
+	print_trace("in\n");
+
+	event = kmalloc(sizeof(*event), GFP_ATOMIC);
+	if (!event) {
+		print_err("kalloc failed\n");
+		return;
+	}
+
+	uobj = ibevent->element.srq->uobject;
+	ucontext = (struct ibp_ucontext *) uobj->user_handle;
+	client = ucontext->client;
+
+	event->client  = client;
+	event->context = (uintptr_t) srq_context;
+	event->type    = ibevent->event;
+	event->ibdev   = ucontext->ibdev;
+
+	INIT_WORK(&event->work, ibp_async_event);
+	queue_work(client->workqueue, &event->work);
+}
+
+static int ibp_cmd_create_srq(struct ibp_client *client,
+			      struct ibp_msg_header *hdr, void *tx_buf)
+{
+	struct ibp_device		*device;
+	struct ibp_verb_response_msg	*msg;
+	struct ibp_create_srq_cmd	*cmd;
+	struct ibp_create_srq_resp	*resp;
+	struct ibp_ucontext		*ucontext;
+	struct ib_uobject		*uobj;
+	struct ib_pd			*pd;
+	struct ib_srq			*srq;
+	struct ib_srq_init_attr		init_attr;
+	struct ib_udata			udata;
+	size_t				len;
+	size_t				outlen;
+	int				ret = 0;
+
+	print_trace("in\n");
+
+	device	= (struct ibp_device *) hdr->device;
+	cmd	= (struct ibp_create_srq_cmd *) hdr;
+	pd	= (struct ib_pd *) cmd->pd;
+	msg	= (struct ibp_verb_response_msg *) tx_buf;
+	resp	= (struct ibp_create_srq_resp *) msg->data;
+	len = hdr->length - sizeof(*cmd);
+	outlen = MAX_MSG_SIZE - sizeof(*msg) - sizeof(*resp);
+
+	INIT_UDATA(&udata, cmd->data, resp->data, len, outlen);
+
+	len = sizeof(*msg);
+
+	ucontext = (struct ibp_ucontext *) pd->uobject->user_handle;
+
+	uobj = ibp_create_uobj(ucontext);
+	if (IS_ERR(uobj)) {
+		ret = PTR_ERR(uobj);
+		print_err("ibp_create_uobj returned %d\n", ret);
+		goto send_resp;
+	}
+
+	memset(&init_attr, 0, sizeof(init_attr));
+
+	init_attr.event_handler	 = ibp_ibsrq_event;
+	init_attr.srq_context	 = (void *) cmd->srq_context;
+	init_attr.attr.max_wr	 = cmd->attr.max_wr;
+	init_attr.attr.max_sge	 = cmd->attr.max_sge;
+	init_attr.attr.srq_limit = cmd->attr.srq_limit;
+
+	srq = device->ib_dev->create_srq(pd, &init_attr, &udata);
+	if (IS_ERR(srq)) {
+		ret = PTR_ERR(srq);
+		print_err("ib_create_srq returned %d\n", ret);
+		ibp_destroy_uobj(uobj);
+		goto send_resp;
+	}
+
+	srq->device	   = device->ib_dev;
+	srq->pd		   = pd;
+	srq->event_handler = init_attr.event_handler;
+	srq->srq_context   = init_attr.srq_context;
+	srq->srq_type      = 0;
+	srq->ext.xrc.cq	   = NULL;
+	srq->ext.xrc.xrcd  = NULL;
+
+	atomic_inc(&pd->usecnt);
+	atomic_set(&srq->usecnt, 0);
+
+	srq->uobject = uobj;
+	uobj->object = srq;
+
+	mutex_lock(&ucontext->mutex);
+	list_add_tail(&uobj->list, &ucontext->ibucontext->srq_list);
+	mutex_unlock(&ucontext->mutex);
+
+	len += sizeof(*resp);
+	len += outlen - udata.outlen;	/* add driver private data */
+
+	resp->srq	     = (uintptr_t)srq;
+	resp->attr.max_wr    = init_attr.attr.max_wr;
+	resp->attr.max_sge   = init_attr.attr.max_sge;
+	resp->attr.srq_limit = init_attr.attr.srq_limit;
+
+send_resp:
+	IBP_INIT_RESP(device, msg, len, VERB_RESPONSE, hdr->request, ret);
+	return ibp_send(client->ep, msg, len);
+}
+
+static int ibp_cmd_modify_srq(struct ibp_client *client,
+			      struct ibp_msg_header *hdr, void *tx_buf)
+{
+	struct ibp_device		*device;
+	struct ibp_verb_response_msg	*msg;
+	struct ibp_modify_srq_cmd	*cmd;
+	struct ibp_modify_srq_resp	*resp;
+	struct ib_srq			*srq;
+	struct ib_srq_attr		attr;
+	struct ib_udata			udata;
+	size_t				len;
+	size_t				outlen;
+	int				ret;
+
+	print_trace("in\n");
+
+	device	= (struct ibp_device *) hdr->device;
+	cmd	= (struct ibp_modify_srq_cmd *) hdr;
+	srq	= (struct ib_srq *) cmd->srq;
+	msg	= (struct ibp_verb_response_msg *) tx_buf;
+	resp	= (struct ibp_modify_srq_resp *) msg->data;
+	len	= hdr->length - sizeof(*cmd);
+	outlen	= MAX_MSG_SIZE - sizeof(*msg) - sizeof(*resp);
+
+	INIT_UDATA(&udata, cmd->data, resp->data, len, outlen);
+
+	len = sizeof(*msg);
+
+	memset(&attr, 0, sizeof(attr));
+
+	attr.max_wr    = cmd->attr.max_wr;
+	attr.max_sge   = cmd->attr.max_sge;
+	attr.srq_limit = cmd->attr.srq_limit;
+
+	ret = device->ib_dev->modify_srq(srq, &attr, cmd->srq_attr_mask,
+					 &udata);
+	if (ret) {
+		print_err("ib_modify_srq returned %d\n", ret);
+		goto send_resp;
+	}
+
+	len += sizeof(*resp);
+	len += outlen - udata.outlen;	/* add driver private data */
+
+	resp->attr.max_wr    = attr.max_wr;
+	resp->attr.max_sge   = attr.max_sge;
+	resp->attr.srq_limit = attr.srq_limit;
+
+send_resp:
+	IBP_INIT_RESP(device, msg, len, VERB_RESPONSE, hdr->request, ret);
+	return ibp_send(client->ep, msg, len);
+}
+
+static int ibp_cmd_query_srq(struct ibp_client *client,
+			     struct ibp_msg_header *hdr, void *tx_buf)
+{
+	struct ibp_device		*device;
+	struct ibp_verb_response_msg	*msg;
+	struct ibp_query_srq_cmd	*cmd;
+	struct ibp_query_srq_resp	*resp;
+	struct ib_srq			*srq;
+	struct ib_srq_attr		attr;
+	size_t				len;
+	int				ret;
+
+	print_trace("in\n");
+
+	device	= (struct ibp_device *) hdr->device;
+	cmd	= (struct ibp_query_srq_cmd *) hdr;
+	srq	= (struct ib_srq *) cmd->srq;
+	msg	= (struct ibp_verb_response_msg *) tx_buf;
+	len	= sizeof(*msg);
+
+	ret = ib_query_srq(srq, &attr);
+	if (ret) {
+		print_err("ib_query_srq returned %d\n", ret);
+		goto send_resp;
+	}
+
+	resp = (struct ibp_query_srq_resp *) msg->data;
+	len += sizeof(*resp);
+
+	resp->attr.max_wr    = attr.max_wr;
+	resp->attr.max_sge   = attr.max_sge;
+	resp->attr.srq_limit = attr.srq_limit;
+
+send_resp:
+	IBP_INIT_RESP(device, msg, len, VERB_RESPONSE, hdr->request, ret);
+	return ibp_send(client->ep, msg, len);
+}
+
+static int ibp_cmd_destroy_srq(struct ibp_client *client,
+			       struct ibp_msg_header *hdr, void *tx_buf)
+{
+	struct ibp_device		*device;
+	struct ibp_queued_response_msg	*msg;
+	struct ibp_destroy_srq_cmd	*cmd;
+	struct ib_uobject		*uobj;
+	struct ib_srq			*srq;
+	size_t				len;
+	int				ret;
+
+	print_trace("in\n");
+
+	device	= (struct ibp_device *) hdr->device;
+	cmd	= (struct ibp_destroy_srq_cmd *) hdr;
+	srq	= (struct ib_srq *) cmd->srq;
+	msg	= (struct ibp_queued_response_msg *) tx_buf;
+	len	= sizeof(*msg);
+
+	uobj = srq->uobject;
+
+	ret = ib_destroy_srq(srq);
+	if (unlikely(ret == -EBUSY)) {
+		msleep(100);
+		ret = ib_destroy_srq(srq);
+	}
+	if (ret) {
+		print_err("ib_destroy_srq returned %d\n", ret);
+		goto send_resp;
+	}
+
+	ibp_destroy_uobj(uobj);
+
+send_resp:
+	IBP_INIT_RESP(device, msg, len, QUEUED_RESPONSE, hdr->request, ret);
+	return ibp_queue_response(client, msg);
+}
+
+static void ibp_ibqp_event(struct ib_event *ibevent, void *qp_context)
+{
+	struct ibp_ucontext		*ucontext;
+	struct ibp_client		*client;
+	struct ibp_event		*event;
+	struct ib_uobject		*uobj;
+
+	event = kmalloc(sizeof(*event), GFP_ATOMIC);
+	if (!event) {
+		print_err("kalloc failed\n");
+		return;
+	}
+
+	uobj = ibevent->element.qp->uobject;
+	ucontext = (struct ibp_ucontext *) uobj->user_handle;
+	client = ucontext->client;
+
+	event->client  = client;
+	event->context = (uintptr_t) qp_context;
+	event->type    = ibevent->event;
+	event->ibdev   = ucontext->ibdev;
+
+	INIT_WORK(&event->work, ibp_async_event);
+	queue_work(client->workqueue, &event->work);
+}
+
+static int ibp_cmd_create_qp(struct ibp_client *client,
+			     struct ibp_msg_header *hdr, void *tx_buf)
+{
+	struct ibp_device		*device;
+	struct ibp_verb_response_msg	*msg;
+	struct ibp_create_qp_cmd	*cmd;
+	struct ibp_create_qp_resp	*resp;
+	struct ibp_ucontext		*ucontext;
+	struct ib_uobject		*uobj;
+	struct ib_pd			*pd;
+	struct ibp_qp			*qp;
+	struct ib_qp_init_attr		init_attr;
+	struct ib_udata			udata;
+	size_t				len;
+	size_t				outlen;
+	int				ret = 0;
+
+	print_trace("in\n");
+
+	device	= (struct ibp_device *) hdr->device;
+	cmd	= (struct ibp_create_qp_cmd *) hdr;
+	pd	= (struct ib_pd *) cmd->pd;
+	msg	= (struct ibp_verb_response_msg *) tx_buf;
+	resp	= (struct ibp_create_qp_resp *) msg->data;
+	len	= hdr->length - sizeof(*cmd);
+	outlen	= MAX_MSG_SIZE - sizeof(*msg) - sizeof(*resp);
+
+	INIT_UDATA(&udata, cmd->data, resp->data, len, outlen);
+
+	len = sizeof(*msg);
+
+	qp = kzalloc(sizeof *qp, GFP_KERNEL);
+	if (!qp) {
+		print_err("kzalloc failed\n");
+		ret = -ENOMEM;
+		goto send_resp;
+	}
+	INIT_LIST_HEAD(&qp->mcast);
+
+	ucontext = (struct ibp_ucontext *) pd->uobject->user_handle;
+
+	uobj = ibp_create_uobj(ucontext);
+	if (IS_ERR(uobj)) {
+		ret = PTR_ERR(uobj);
+		print_err("ibp_create_uobj returned %d\n", ret);
+		goto send_resp;
+	}
+
+	memset(&init_attr, 0, sizeof(init_attr));
+
+	init_attr.send_cq	      = (struct ib_cq *) cmd->send_cq;
+	init_attr.recv_cq	      = (struct ib_cq *) cmd->recv_cq;
+	init_attr.srq		      = (struct ib_srq *) cmd->srq;
+	init_attr.xrcd		      = (struct ib_xrcd *) cmd->xrc_domain;
+	init_attr.cap.max_send_wr     = cmd->cap.max_send_wr;
+	init_attr.cap.max_recv_wr     = cmd->cap.max_recv_wr;
+	init_attr.cap.max_send_sge    = cmd->cap.max_send_sge;
+	init_attr.cap.max_recv_sge    = cmd->cap.max_recv_sge;
+	init_attr.cap.max_inline_data = cmd->cap.max_inline_data;
+	init_attr.sq_sig_type	      = cmd->sq_sig_type;
+	init_attr.qp_type	      = cmd->qp_type;
+	init_attr.create_flags	      = cmd->create_flags;
+	init_attr.port_num	      = cmd->port_num;
+
+	qp->ibqp = device->ib_dev->create_qp(pd, &init_attr, &udata);
+	if (IS_ERR(qp->ibqp)) {
+		ret = PTR_ERR(qp->ibqp);
+		print_err("ib_create_qp returned %d\n", ret);
+		ibp_destroy_uobj(uobj);
+		goto send_resp;
+	}
+
+	qp->ibqp->device	= device->ib_dev;
+	qp->ibqp->pd		= pd;
+	qp->ibqp->send_cq	= init_attr.send_cq;
+	qp->ibqp->recv_cq	= init_attr.recv_cq;
+	qp->ibqp->srq		= init_attr.srq;
+	qp->ibqp->event_handler = ibp_ibqp_event;
+	qp->ibqp->qp_context	= (void *) cmd->qp_context;
+	qp->ibqp->qp_type	= init_attr.qp_type;
+
+	if (qp->ibqp->qp_type == IB_QPT_XRC_TGT) {
+		qp->ibqp->xrcd = init_attr.xrcd;
+		atomic_inc(&qp->ibqp->xrcd->usecnt);
+	} else {
+		qp->ibqp->xrcd = NULL;
+		qp->ibqp->real_qp = qp->ibqp;
+	}
+	atomic_set(&qp->ibqp->usecnt, 0);
+
+	atomic_inc(&pd->usecnt);
+	atomic_inc(&init_attr.send_cq->usecnt);
+	atomic_inc(&init_attr.recv_cq->usecnt);
+
+	if (init_attr.srq)
+		atomic_inc(&init_attr.srq->usecnt);
+
+	qp->ibqp->uobject  = uobj;
+	uobj->object = qp;
+
+	mutex_lock(&ucontext->mutex);
+	list_add_tail(&uobj->list, &ucontext->ibucontext->qp_list);
+	mutex_unlock(&ucontext->mutex);
+
+	len += sizeof(*resp);
+	len += outlen - udata.outlen;	/* add driver private data */
+
+	resp->qp		  = (uintptr_t) qp;
+	resp->qpn		  = qp->ibqp->qp_num;
+	resp->cap.max_send_wr	  = init_attr.cap.max_send_wr;
+	resp->cap.max_recv_wr	  = init_attr.cap.max_recv_wr;
+	resp->cap.max_send_sge	  = init_attr.cap.max_send_sge;
+	resp->cap.max_recv_sge	  = init_attr.cap.max_recv_sge;
+	resp->cap.max_inline_data = init_attr.cap.max_inline_data;
+
+send_resp:
+	if (ret)
+		kfree(qp);
+
+	IBP_INIT_RESP(device, msg, len, VERB_RESPONSE, hdr->request, ret);
+	return ibp_send(client->ep, msg, len);
+}
+
+static int ibp_cmd_modify_qp(struct ibp_client *client,
+			     struct ibp_msg_header *hdr, void *tx_buf)
+{
+	struct ibp_device		*device;
+	struct ibp_verb_response_msg	*msg;
+	struct ibp_modify_qp_cmd	*cmd;
+	struct ibp_modify_qp_resp	*resp;
+	struct ibp_qp			*qp;
+	struct ib_qp_attr		attr;
+	struct ib_udata			udata;
+	size_t				len;
+	size_t				outlen;
+	int				ret;
+
+	print_trace("in\n");
+
+	device	= (struct ibp_device *) hdr->device;
+	cmd	= (struct ibp_modify_qp_cmd *) hdr;
+	qp	= (struct ibp_qp *) cmd->qp;
+	msg	= (struct ibp_verb_response_msg *) tx_buf;
+	resp	= (struct ibp_modify_qp_resp *) msg->data;
+	len	= hdr->length - sizeof(*cmd);
+	outlen	= MAX_MSG_SIZE - sizeof(*msg) - sizeof(*resp);
+
+	INIT_UDATA(&udata, cmd->data, resp->data, len, outlen);
+
+	len = sizeof(*msg);
+
+	memset(&attr, 0, sizeof(attr));
+
+	attr.qp_state			= cmd->qp_state;
+	attr.cur_qp_state		= cmd->cur_qp_state;
+	attr.path_mtu			= cmd->path_mtu;
+	attr.path_mig_state		= cmd->path_mig_state;
+	attr.qkey			= cmd->qkey;
+	attr.rq_psn			= cmd->rq_psn;
+	attr.sq_psn			= cmd->sq_psn;
+	attr.dest_qp_num		= cmd->dest_qp_num;
+	attr.qp_access_flags		= cmd->qp_access_flags;
+	attr.cap.max_send_wr		= cmd->cap.max_send_wr;
+	attr.cap.max_recv_wr		= cmd->cap.max_recv_wr;
+	attr.cap.max_send_sge		= cmd->cap.max_send_sge;
+	attr.cap.max_recv_sge		= cmd->cap.max_recv_sge;
+	attr.cap.max_inline_data	= cmd->cap.max_inline_data;
+	attr.ah_attr.grh.dgid.global.subnet_prefix =
+			cmd->ah.grh.dgid_subnet_prefix;
+	attr.ah_attr.grh.dgid.global.interface_id  =
+			cmd->ah.grh.dgid_interface_id;
+	attr.ah_attr.grh.flow_label	= cmd->ah.grh.flow_label;
+	attr.ah_attr.grh.sgid_index	= cmd->ah.grh.sgid_index;
+	attr.ah_attr.grh.hop_limit	= cmd->ah.grh.hop_limit;
+	attr.ah_attr.grh.traffic_class  = cmd->ah.grh.traffic_class;
+	attr.ah_attr.dlid		= cmd->ah.dlid;
+	attr.ah_attr.sl			= cmd->ah.sl;
+	attr.ah_attr.src_path_bits	= cmd->ah.src_path_bits;
+	attr.ah_attr.static_rate	= cmd->ah.static_rate;
+	attr.ah_attr.ah_flags		= cmd->ah.ah_flags;
+	attr.ah_attr.port_num		= cmd->ah.port_num;
+	attr.alt_ah_attr.grh.dgid.global.subnet_prefix =
+			cmd->alt_ah.grh.dgid_subnet_prefix;
+	attr.alt_ah_attr.grh.dgid.global.interface_id  =
+			cmd->alt_ah.grh.dgid_interface_id;
+	attr.alt_ah_attr.grh.flow_label	= cmd->alt_ah.grh.flow_label;
+	attr.alt_ah_attr.grh.sgid_index	= cmd->alt_ah.grh.sgid_index;
+	attr.alt_ah_attr.grh.hop_limit	= cmd->alt_ah.grh.hop_limit;
+	attr.alt_ah_attr.grh.traffic_class = cmd->alt_ah.grh.traffic_class;
+	attr.alt_ah_attr.dlid		= cmd->alt_ah.dlid;
+	attr.alt_ah_attr.sl		= cmd->alt_ah.sl;
+	attr.alt_ah_attr.src_path_bits	= cmd->alt_ah.src_path_bits;
+	attr.alt_ah_attr.static_rate	= cmd->alt_ah.static_rate;
+	attr.alt_ah_attr.ah_flags	= cmd->alt_ah.ah_flags;
+	attr.alt_ah_attr.port_num	= cmd->alt_ah.port_num;
+	attr.pkey_index			= cmd->pkey_index;
+	attr.alt_pkey_index		= cmd->alt_pkey_index;
+	attr.en_sqd_async_notify	= cmd->en_sqd_async_notify;
+	attr.sq_draining		= cmd->sq_draining;
+	attr.max_rd_atomic		= cmd->max_rd_atomic;
+	attr.max_dest_rd_atomic		= cmd->max_dest_rd_atomic;
+	attr.min_rnr_timer		= cmd->min_rnr_timer;
+	attr.port_num			= cmd->port_num;
+	attr.timeout			= cmd->timeout;
+	attr.retry_cnt			= cmd->retry_cnt;
+	attr.rnr_retry			= cmd->rnr_retry;
+	attr.alt_port_num		= cmd->alt_port_num;
+	attr.alt_timeout		= cmd->alt_timeout;
+
+	ret = device->ib_dev->modify_qp(qp->ibqp, &attr, cmd->qp_attr_mask, &udata);
+	if (ret) {
+		print_err("ib_modify_qp returned %d\n", ret);
+		goto send_resp;
+	}
+
+	len += sizeof(*resp);
+	len += outlen - udata.outlen;	/* add driver private data */
+
+	resp->cap.max_send_wr	  = attr.cap.max_send_wr;
+	resp->cap.max_recv_wr	  = attr.cap.max_recv_wr;
+	resp->cap.max_send_sge	  = attr.cap.max_send_sge;
+	resp->cap.max_recv_sge	  = attr.cap.max_recv_sge;
+	resp->cap.max_inline_data = attr.cap.max_inline_data;
+
+send_resp:
+	IBP_INIT_RESP(device, msg, len, VERB_RESPONSE, hdr->request, ret);
+	return ibp_send(client->ep, msg, len);
+}
+
+static int ibp_cmd_query_qp(struct ibp_client *client,
+			    struct ibp_msg_header *hdr, void *tx_buf)
+{
+	struct ibp_device		*device;
+	struct ibp_verb_response_msg	*msg;
+	struct ibp_query_qp_cmd		*cmd;
+	struct ibp_query_qp_resp	*resp;
+	struct ibp_qp			*qp;
+	struct ib_qp_attr		qp_attr;
+	struct ib_qp_init_attr		qp_init_attr;
+	size_t				len;
+	int				ret;
+
+	print_trace("in\n");
+
+	device	= (struct ibp_device *) hdr->device;
+	cmd	= (struct ibp_query_qp_cmd *) hdr;
+	qp	= (struct ibp_qp *) cmd->qp;
+	msg	= (struct ibp_verb_response_msg *) tx_buf;
+	len	= sizeof(*msg);
+
+	ret = ib_query_qp(qp->ibqp, &qp_attr, cmd->qp_attr_mask, &qp_init_attr);
+	if (ret) {
+		print_err("ib_query_qp returned %d\n", ret);
+		goto send_resp;
+	}
+
+	resp = (struct ibp_query_qp_resp *) msg->data;
+	len += sizeof(*resp);
+
+	resp->qp_state	      = qp_attr.qp_state;
+	resp->cur_qp_state    = qp_attr.cur_qp_state;
+	resp->path_mtu	      = qp_attr.path_mtu;
+	resp->path_mig_state  = qp_attr.path_mig_state;
+	resp->qkey	      = qp_attr.qkey;
+	resp->rq_psn	      = qp_attr.rq_psn;
+	resp->sq_psn	      = qp_attr.sq_psn;
+	resp->dest_qp_num     = qp_attr.dest_qp_num;
+	resp->qp_access_flags = qp_attr.qp_access_flags;
+
+	resp->init_cap.max_send_wr     = qp_init_attr.cap.max_send_wr;
+	resp->init_cap.max_recv_wr     = qp_init_attr.cap.max_recv_wr;
+	resp->init_cap.max_send_sge    = qp_init_attr.cap.max_send_sge;
+	resp->init_cap.max_recv_sge    = qp_init_attr.cap.max_recv_sge;
+	resp->init_cap.max_inline_data = qp_init_attr.cap.max_inline_data;
+	resp->init_create_flags	       = qp_init_attr.create_flags;
+	resp->init_sq_sig_type	       = qp_init_attr.sq_sig_type;
+
+	resp->cap.max_send_wr	  = qp_attr.cap.max_send_wr;
+	resp->cap.max_recv_wr	  = qp_attr.cap.max_recv_wr;
+	resp->cap.max_send_sge	  = qp_attr.cap.max_send_sge;
+	resp->cap.max_recv_sge	  = qp_attr.cap.max_recv_sge;
+	resp->cap.max_inline_data = qp_attr.cap.max_inline_data;
+
+	resp->ah.grh.dgid_subnet_prefix	=
+			qp_attr.ah_attr.grh.dgid.global.subnet_prefix;
+	resp->ah.grh.dgid_interface_id	=
+			qp_attr.ah_attr.grh.dgid.global.interface_id;
+	resp->ah.grh.flow_label	   = qp_attr.ah_attr.grh.flow_label;
+	resp->ah.grh.sgid_index	   = qp_attr.ah_attr.grh.sgid_index;
+	resp->ah.grh.hop_limit	   = qp_attr.ah_attr.grh.hop_limit;
+	resp->ah.grh.traffic_class = qp_attr.ah_attr.grh.traffic_class;
+	resp->ah.dlid		   = qp_attr.ah_attr.dlid;
+	resp->ah.sl		   = qp_attr.ah_attr.sl;
+	resp->ah.src_path_bits	   = qp_attr.ah_attr.src_path_bits;
+	resp->ah.static_rate	   = qp_attr.ah_attr.static_rate;
+	resp->ah.ah_flags	   = qp_attr.ah_attr.ah_flags;
+	resp->ah.port_num	   = qp_attr.ah_attr.port_num;
+
+	resp->alt_ah.grh.dgid_subnet_prefix =
+			qp_attr.alt_ah_attr.grh.dgid.global.subnet_prefix;
+	resp->alt_ah.grh.dgid_interface_id  =
+			qp_attr.alt_ah_attr.grh.dgid.global.interface_id;
+	resp->alt_ah.grh.flow_label    = qp_attr.alt_ah_attr.grh.flow_label;
+	resp->alt_ah.grh.sgid_index    = qp_attr.alt_ah_attr.grh.sgid_index;
+	resp->alt_ah.grh.hop_limit     = qp_attr.alt_ah_attr.grh.hop_limit;
+	resp->alt_ah.grh.traffic_class = qp_attr.alt_ah_attr.grh.traffic_class;
+	resp->alt_ah.dlid	       = qp_attr.alt_ah_attr.dlid;
+	resp->alt_ah.sl		       = qp_attr.alt_ah_attr.sl;
+	resp->alt_ah.src_path_bits     = qp_attr.alt_ah_attr.src_path_bits;
+	resp->alt_ah.static_rate       = qp_attr.alt_ah_attr.static_rate;
+	resp->alt_ah.ah_flags	       = qp_attr.alt_ah_attr.ah_flags;
+	resp->alt_ah.port_num	       = qp_attr.alt_ah_attr.port_num;
+
+	resp->pkey_index	  = qp_attr.pkey_index;
+	resp->alt_pkey_index	  = qp_attr.alt_pkey_index;
+	resp->en_sqd_async_notify = qp_attr.en_sqd_async_notify;
+	resp->sq_draining	  = qp_attr.sq_draining;
+	resp->max_rd_atomic	  = qp_attr.max_rd_atomic;
+	resp->max_dest_rd_atomic  = qp_attr.max_dest_rd_atomic;
+	resp->min_rnr_timer	  = qp_attr.min_rnr_timer;
+	resp->port_num		  = qp_attr.port_num;
+	resp->timeout		  = qp_attr.timeout;
+	resp->retry_cnt		  = qp_attr.retry_cnt;
+	resp->rnr_retry		  = qp_attr.rnr_retry;
+	resp->alt_port_num	  = qp_attr.alt_port_num;
+	resp->alt_timeout	  = qp_attr.alt_timeout;
+
+send_resp:
+	IBP_INIT_RESP(device, msg, len, VERB_RESPONSE, hdr->request, ret);
+	return ibp_send(client->ep, msg, len);
+}
+
+static int ibp_cmd_destroy_qp(struct ibp_client *client,
+			      struct ibp_msg_header *hdr, void *tx_buf)
+{
+	struct ibp_device		*device;
+	struct ibp_queued_response_msg	*msg;
+	struct ibp_destroy_qp_cmd	*cmd;
+	struct ib_uobject		*uobj;
+	struct ibp_qp			*qp;
+	size_t				len;
+	int				ret;
+
+	print_trace("in\n");
+
+	device	= (struct ibp_device *) hdr->device;
+	cmd	= (struct ibp_destroy_qp_cmd *) hdr;
+	qp	= (struct ibp_qp *) cmd->qp;
+	msg	= (struct ibp_queued_response_msg *) tx_buf;
+	len	= sizeof(*msg);
+
+	uobj = qp->ibqp->uobject;
+
+	ret = ib_destroy_qp(qp->ibqp);
+	if (ret) {
+		print_err("ib_destroy_qp returned %d\n", ret);
+		goto send_resp;
+	}
+
+	ibp_destroy_uobj(uobj);
+
+	kfree(qp);
+
+send_resp:
+	IBP_INIT_RESP(device, msg, len, QUEUED_RESPONSE, hdr->request, ret);
+	return ibp_queue_response(client, msg);
+}
+
+static void ibp_ibcq_event(struct ib_event *ibevent, void *cq_context)
+{
+	struct ibp_ucontext		*ucontext;
+	struct ibp_client		*client;
+	struct ibp_event		*event;
+	struct ib_uobject		*uobj;
+
+	event = kmalloc(sizeof(*event), GFP_ATOMIC);
+	if (!event) {
+		print_err("kalloc failed\n");
+		return;
+	}
+
+	uobj = (struct ib_uobject *) ibevent->element.cq->uobject;
+	ucontext = (void *) uobj->user_handle;
+	client = ucontext->client;
+
+	event->client  = client;
+	event->context = (uintptr_t) cq_context;
+	event->type    = ibevent->event;
+	event->ibdev   = ucontext->ibdev;
+
+	INIT_WORK(&event->work, ibp_async_event);
+	queue_work(client->workqueue, &event->work);
+}
+
+static void ibp_cq_comp(struct work_struct *work)
+{
+	struct ibp_comp			*comp;
+	struct ibp_cq_comp_msg		msg;
+
+	comp = container_of(work, struct ibp_comp, work);
+
+	IBP_INIT_MSG(NULL, &msg, sizeof(msg), CQ_COMP);
+
+	msg.data.cq_context = (uintptr_t) comp->cq_context;
+
+	ibp_send(comp->client->ep, &msg, sizeof(msg));
+
+	ibp_add_to_stack(c_stack, (void *) comp);
+}
+
+static void ibp_ibcq_comp(struct ib_cq *ibcq, void *cq_context)
+{
+	struct ibp_ucontext		*ucontext;
+	struct ibp_client		*client;
+	struct ibp_comp			*comp;
+
+	ucontext = (struct ibp_ucontext *) ibcq->uobject->user_handle;
+
+	if (ucontext->ibucontext->closing) {
+		print_dbg("ignoring cq completion, connection closing\n");
+		return;
+	}
+
+	comp = (struct ibp_comp *)
+		ibp_pull_from_stack(c_stack, sizeof(*comp), GFP_ATOMIC);
+	if (!comp) {
+		print_err("kalloc failed\n");
+		return;
+	}
+
+	client = ucontext->client;
+
+	comp->client	 = client;
+	comp->cq_context = cq_context;
+
+	INIT_WORK(&comp->work, ibp_cq_comp);
+	queue_work(client->workqueue, &comp->work);
+}
+
+static int ibp_cmd_create_cq(struct ibp_client *client,
+			     struct ibp_msg_header *hdr, void *tx_buf)
+{
+	struct ibp_device		*device;
+	struct ibp_verb_response_msg	*msg;
+	struct ibp_create_cq_cmd	*cmd;
+	struct ibp_create_cq_resp	*resp;
+	struct ibp_ucontext		*ucontext;
+	struct ib_uobject		*uobj;
+	struct ib_udata			udata;
+	struct ib_cq			*cq;
+	size_t				len;
+	size_t				outlen;
+	int				ret = 0;
+#ifdef MOFED
+	struct ib_cq_init_attr		attr;
+#endif
+
+	print_trace("in\n");
+
+	device = (struct ibp_device *) hdr->device;
+	cmd = (struct ibp_create_cq_cmd *) hdr;
+	ucontext = (struct ibp_ucontext *) cmd->ucontext;
+	msg = (struct ibp_verb_response_msg *) tx_buf;
+	resp = (struct ibp_create_cq_resp *) msg->data;
+	len = hdr->length - sizeof(*cmd);
+	outlen = MAX_MSG_SIZE - sizeof(*msg) - sizeof(*resp);
+
+	INIT_UDATA(&udata, cmd->data, resp->data, len, outlen);
+
+	len = sizeof(*msg);
+
+	uobj = ibp_create_uobj(ucontext);
+	if (IS_ERR(uobj)) {
+		ret = PTR_ERR(uobj);
+		print_err("ibp_create_uobj returned %d\n", ret);
+		goto send_resp;
+	}
+
+#ifdef  MOFED
+	memset(&attr, 0, sizeof(attr));
+	attr.cqe = cmd->cqe;
+	attr.comp_vector = cmd->vector;
+
+	cq = device->ib_dev->create_cq(device->ib_dev, &attr,
+				       ucontext->ibucontext, &udata);
+#else
+	cq = device->ib_dev->create_cq(device->ib_dev, (int) cmd->cqe,
+				      (int) cmd->vector,
+				       ucontext->ibucontext, &udata);
+#endif
+	if (IS_ERR(cq)) {
+		ret = PTR_ERR(cq);
+		print_err("ib_create_cq returned %d\n", ret);
+		ibp_destroy_uobj(uobj);
+		goto send_resp;
+	}
+
+	cq->device	  = device->ib_dev;
+	cq->event_handler = ibp_ibcq_event;
+	cq->comp_handler  = ibp_ibcq_comp;
+	cq->cq_context    = (void *) cmd->cq_context;
+	atomic_set(&cq->usecnt, 0);
+
+	cq->uobject  = uobj;
+	uobj->object = cq;
+
+	mutex_lock(&ucontext->mutex);
+	list_add_tail(&uobj->list, &ucontext->ibucontext->cq_list);
+	mutex_unlock(&ucontext->mutex);
+
+	len += sizeof(*resp);
+	len += outlen - udata.outlen;	/* add driver private data */
+
+	resp->cq  = (uintptr_t)cq;
+	resp->cqe = cq->cqe;
+
+send_resp:
+	IBP_INIT_RESP(device, msg, len, VERB_RESPONSE, hdr->request, ret);
+	return ibp_send(client->ep, msg, len);
+}
+
+static int ibp_cmd_destroy_cq(struct ibp_client *client,
+			      struct ibp_msg_header *hdr, void *tx_buf)
+{
+	struct ibp_device		*device;
+	struct ibp_queued_response_msg	*msg;
+	struct ibp_destroy_cq_cmd	*cmd;
+	struct ib_uobject		*uobj;
+	struct ib_cq			*cq;
+	size_t				len;
+	int				ret;
+
+	print_trace("in\n");
+
+	device	= (struct ibp_device *) hdr->device;
+	cmd	= (struct ibp_destroy_cq_cmd *) hdr;
+	cq	= (struct ib_cq *) cmd->cq;
+	msg	= (struct ibp_queued_response_msg *) tx_buf;
+	len	= sizeof(*msg);
+
+	uobj = cq->uobject;
+
+	ret = ib_destroy_cq(cq);
+	if (unlikely(ret == -EBUSY)) {
+		msleep(100);
+		ret = ib_destroy_cq(cq);
+	}
+	if (ret) {
+		print_err("ib_destroy_cq returned %d\n", ret);
+		goto send_resp;
+	}
+
+	ibp_destroy_uobj(uobj);
+
+send_resp:
+	IBP_INIT_RESP(device, msg, len, QUEUED_RESPONSE, hdr->request, ret);
+	return ibp_queue_response(client, msg);
+}
+
+static int ibp_cmd_resize_cq(struct ibp_client *client,
+			     struct ibp_msg_header *hdr, void *tx_buf)
+{
+	struct ibp_device		*device;
+	struct ibp_verb_response_msg	*msg;
+	struct ibp_resize_cq_cmd	*cmd;
+	struct ibp_resize_cq_resp	*resp;
+	struct ib_cq			*cq;
+	struct ib_udata			udata;
+	size_t				len;
+	size_t				outlen;
+	int				ret;
+
+	device	= (struct ibp_device *) hdr->device;
+	cmd	= (struct ibp_resize_cq_cmd *) hdr;
+	cq	= (struct ib_cq *) cmd->cq;
+	msg	= (struct ibp_verb_response_msg *) tx_buf;
+	resp	= (struct ibp_resize_cq_resp *) msg->data;
+	len	= hdr->length - sizeof(*cmd);
+	outlen	= MAX_MSG_SIZE - sizeof(*msg) - sizeof(*resp);
+
+	INIT_UDATA(&udata, cmd->data, resp->data, len, outlen);
+
+	len = sizeof(*msg);
+
+	ret = device->ib_dev->resize_cq ?
+		device->ib_dev->resize_cq(cq, (int) cmd->cqe, &udata) : -ENOSYS;
+	if (ret) {
+		print_err("ib_resize_cq returned %d\n", ret);
+		goto send_resp;
+	}
+
+	len += sizeof(*resp);
+	len += outlen - udata.outlen;	/* add driver private data */
+
+	resp->cqe = cq->cqe;
+
+send_resp:
+	IBP_INIT_RESP(device, msg, len, VERB_RESPONSE, hdr->request, ret);
+	return ibp_send(client->ep, msg, len);
+}
+
+static int ibp_cmd_reg_user_mr(struct ibp_client *client,
+			       struct ibp_msg_header *hdr, void *tx_buf)
+{
+	struct ibp_device		*device;
+	struct ibp_verb_response_msg	*msg;
+	struct ibp_reg_user_mr_cmd	*cmd;
+	struct ibp_reg_user_mr_resp	*resp;
+	struct ibp_mr			*mr;
+	struct ibp_ucontext		*ucontext;
+	struct ib_uobject		*uobj;
+	struct ib_udata			udata;
+	struct ib_pd			*pd;
+	size_t				len;
+	size_t				outlen;
+	int				ret = 0;
+
+	print_trace("in\n");
+
+	device	= (struct ibp_device *) hdr->device;
+	cmd	= (struct ibp_reg_user_mr_cmd *) hdr;
+	msg	= (struct ibp_verb_response_msg *) tx_buf;
+	resp	= (struct ibp_reg_user_mr_resp *) msg->data;
+	len	= hdr->length - sizeof(*cmd);
+	outlen	= MAX_MSG_SIZE - sizeof(*msg) - sizeof(*resp);
+
+	INIT_UDATA(&udata, cmd->data, resp->data, len, outlen);
+
+	len = sizeof(*msg);
+
+	mr = kzalloc(sizeof(*mr), GFP_KERNEL);
+	if (!mr) {
+		print_err("kzalloc failed\n");
+		ret = -ENOMEM;
+		goto send_resp;
+	}
+
+	pd = (struct ib_pd *) cmd->pd;
+
+	ucontext = (struct ibp_ucontext *) pd->uobject->user_handle;
+
+	mr->reg = ibp_reg_buf(ucontext, cmd->hca_va, cmd->scif_addr,
+			      cmd->length, cmd->offset, cmd->access);
+	if (IS_ERR(mr->reg)) {
+		ret = PTR_ERR(mr->reg);
+		print_err("ibp_reg_buf returned %d\n", ret);
+		goto send_resp;
+	}
+
+	uobj = ibp_create_uobj(ucontext);
+	if (IS_ERR(uobj)) {
+		ret = PTR_ERR(uobj);
+		print_err("ibp_create_uobj returned %d\n", ret);
+		kref_put(&mr->reg->ref, ibp_dereg_buf);
+		goto send_resp;
+	}
+
+#ifdef MOFED
+	mr->ibmr = pd->device->reg_user_mr(pd, cmd->hca_va, cmd->length,
+					   cmd->hca_va, cmd->access, &udata, 0);
+#else
+	mr->ibmr = pd->device->reg_user_mr(pd, cmd->hca_va, cmd->length,
+					   cmd->hca_va, cmd->access, &udata);
+#endif
+	if (IS_ERR(mr->ibmr)) {
+		ret = PTR_ERR(mr->ibmr);
+		print_err("ib_reg_user_mr returned %d\n", ret);
+		kref_put(&mr->reg->ref, ibp_dereg_buf);
+		ibp_destroy_uobj(uobj);
+		goto  send_resp;
+	}
+
+	mr->ibmr->pd     = pd;
+	mr->ibmr->device = pd->device;
+	atomic_inc(&pd->usecnt);
+	atomic_set(&mr->ibmr->usecnt, 0);
+
+	mr->ibmr->uobject = uobj;
+	uobj->object = mr;
+
+	mutex_lock(&ucontext->mutex);
+	list_add_tail(&uobj->list, &ucontext->ibucontext->mr_list);
+	mutex_unlock(&ucontext->mutex);
+
+	len += sizeof(*resp);
+	len += outlen - udata.outlen;	/* add driver private data */
+
+	resp->mr   = (uintptr_t) mr;
+	resp->lkey = mr->ibmr->lkey;
+	resp->rkey = mr->ibmr->rkey;
+
+send_resp:
+	if (ret)
+		kfree(mr);
+
+	IBP_INIT_RESP(device, msg, len, VERB_RESPONSE, hdr->request, ret);
+	return ibp_send(client->ep, msg, len);
+}
+
+static int ibp_cmd_dereg_mr(struct ibp_client *client,
+			    struct ibp_msg_header *hdr, void *tx_buf)
+{
+	struct ibp_device		*device;
+	struct ibp_verb_response_msg	*msg;
+	struct ibp_dereg_mr_cmd		*cmd;
+	struct ibp_mr			*mr;
+	struct ib_uobject		*uobj;
+	size_t				len;
+	int				ret;
+
+	device	= (struct ibp_device *) hdr->device;
+	cmd	= (struct ibp_dereg_mr_cmd *) hdr;
+	mr	= (struct ibp_mr *) cmd->mr;
+	msg	= (struct ibp_verb_response_msg *) tx_buf;
+	len	= sizeof(*msg);
+
+	if (IS_NULL_OR_ERR(mr)) {
+		print_err("Invalid mr %p\n", mr);
+		ret = -EINVAL;
+		goto send_resp;
+	}
+
+	uobj = mr->ibmr->uobject;
+
+	ret = ib_dereg_mr(mr->ibmr);
+	if (unlikely(ret == -EBUSY)) {
+		msleep(100);
+		ret = ib_dereg_mr(mr->ibmr);
+	}
+	if (ret) {
+		print_err("ib_dereg_mr returned %d\n", ret);
+		goto send_resp;
+	}
+
+	ibp_destroy_uobj(uobj);
+
+	if (mr->reg)
+		kref_put(&mr->reg->ref, ibp_dereg_buf);
+
+	kfree(mr);
+
+send_resp:
+	IBP_INIT_RESP(device, msg, len, VERB_RESPONSE, hdr->request, ret);
+	return ibp_send(client->ep, msg, len);
+}
+
+static int ibp_cmd_attach_mcast(struct ibp_client *client,
+				struct ibp_msg_header *hdr, void *tx_buf)
+{
+	struct ibp_device		*device;
+	struct ibp_verb_response_msg	*msg;
+	struct ibp_attach_mcast_cmd	*cmd;
+	struct ibp_mcast_entry		*mcast;
+	struct ibp_ucontext		*ucontext;
+	struct ibp_qp			*qp;
+	union ib_gid			gid;
+	size_t				len;
+	int				ret;
+
+	print_trace("in\n");
+
+	device	= (struct ibp_device *) hdr->device;
+	cmd	= (struct ibp_attach_mcast_cmd *) hdr;
+	qp	= (struct ibp_qp *) cmd->qp;
+	msg	= (struct ibp_verb_response_msg *) tx_buf;
+	len	= sizeof(*msg);
+
+	ucontext = (struct ibp_ucontext *) qp->ibqp->uobject->user_handle;
+
+	mcast = kzalloc(sizeof *mcast, GFP_KERNEL);
+	if (!mcast) {
+		print_err("kzalloc failed\n");
+		ret = -ENOMEM;
+		goto send_resp;
+	}
+
+	gid.global.subnet_prefix = cmd->subnet_prefix;
+	gid.global.interface_id  = cmd->interface_id;
+
+	ret = ib_attach_mcast(qp->ibqp, &gid, cmd->lid);
+	if (ret) {
+		print_err("ib_attach_mcast returned %d\n", ret);
+		kfree(mcast);
+		goto send_resp;
+	}
+
+	mcast->lid = cmd->lid;
+	mcast->gid.global.subnet_prefix = cmd->subnet_prefix;
+	mcast->gid.global.interface_id  = cmd->interface_id;
+
+	mutex_lock(&ucontext->mutex);
+	list_add_tail(&mcast->list, &qp->mcast);
+	mutex_unlock(&ucontext->mutex);
+
+send_resp:
+	IBP_INIT_RESP(device, msg, len, VERB_RESPONSE, hdr->request, ret);
+	return ibp_send(client->ep, msg, len);
+}
+
+static int ibp_cmd_detach_mcast(struct ibp_client *client,
+				struct ibp_msg_header *hdr, void *tx_buf)
+{
+	struct ibp_device		*device;
+	struct ibp_verb_response_msg	*msg;
+	struct ibp_detach_mcast_cmd	*cmd;
+	struct ibp_mcast_entry		*mcast;
+	struct ibp_ucontext		*ucontext;
+	struct ibp_qp			*qp;
+	union ib_gid			gid;
+	size_t				len;
+	int				ret;
+
+	print_trace("in\n");
+
+	device	= (struct ibp_device *) hdr->device;
+	cmd	= (struct ibp_detach_mcast_cmd *) hdr;
+	qp	= (struct ibp_qp *) cmd->qp;
+	msg	= (struct ibp_verb_response_msg *) tx_buf;
+	len	= sizeof(*msg);
+
+	ucontext = (struct ibp_ucontext *) qp->ibqp->uobject->user_handle;
+
+	gid.global.subnet_prefix = cmd->subnet_prefix;
+	gid.global.interface_id  = cmd->interface_id;
+
+	ret = ib_detach_mcast(qp->ibqp, &gid, cmd->lid);
+	if (ret) {
+		print_err("ib_detach_mcast returned %d\n", ret);
+		goto send_resp;
+	}
+
+	mutex_lock(&ucontext->mutex);
+	list_for_each_entry(mcast, &qp->mcast, list)
+		if (cmd->lid == mcast->lid &&
+		    !memcmp(&gid , mcast->gid.raw, sizeof mcast->gid.raw)) {
+			list_del(&mcast->list);
+			kfree(mcast);
+			break;
+		}
+	mutex_unlock(&ucontext->mutex);
+
+send_resp:
+	IBP_INIT_RESP(device, msg, len, VERB_RESPONSE, hdr->request, ret);
+	return ibp_send(client->ep, msg, len);
+}
+
+static void ibp_detach_mcast(struct ibp_qp *qp)
+{
+	struct ibp_mcast_entry		*mcast, *tmp;
+
+	list_for_each_entry_safe(mcast, tmp, &qp->mcast, list) {
+		ib_detach_mcast(qp->ibqp, &mcast->gid, mcast->lid);
+		list_del(&mcast->list);
+		kfree(mcast);
+	}
+}
+
+static void ibp_destroy_ucontext(struct ibp_ucontext *ucontext)
+{
+	struct ib_ucontext		*ibuctx;
+	struct ib_uobject		*uobj;
+	struct ib_uobject		*tmp;
+	struct ibp_mmap			*mmap;
+	struct ibp_mmap			*tmp_mmap;
+
+	ibuctx = ucontext->ibucontext;
+	if (!ibuctx)
+		goto out;
+
+	ibuctx->closing = 1;
+
+	synchronize_sched();
+
+	down_write(&list_rwsem);
+
+	list_for_each_entry_safe(uobj, tmp, &ibuctx->ah_list, list) {
+		struct ib_ah *ibah = uobj->object;
+		ib_destroy_ah(ibah);
+		ibp_destroy_uobj(uobj);
+	}
+
+	list_for_each_entry_safe(uobj, tmp, &ibuctx->qp_list, list) {
+		struct ibp_qp *qp = uobj->object;
+		ibp_detach_mcast(qp);
+		ib_destroy_qp(qp->ibqp);
+		ibp_destroy_uobj(uobj);
+		kfree(qp);
+	}
+
+	list_for_each_entry_safe(uobj, tmp, &ibuctx->cq_list, list) {
+		struct ib_cq *ibcq = uobj->object;
+		ib_destroy_cq(ibcq);
+		ibp_destroy_uobj(uobj);
+	}
+
+	list_for_each_entry_safe(uobj, tmp, &ibuctx->srq_list, list) {
+		struct ib_srq *ibsrq = uobj->object;
+		ib_destroy_srq(ibsrq);
+		ibp_destroy_uobj(uobj);
+	}
+
+	list_for_each_entry_safe(uobj, tmp, &ibuctx->mr_list, list) {
+		struct ibp_mr *mr = uobj->object;
+		ib_dereg_mr(mr->ibmr);
+		ibp_destroy_uobj(uobj);
+		kref_put(&mr->reg->ref, ibp_dereg_buf);
+		kfree(mr);
+	}
+
+	list_for_each_entry_safe(uobj, tmp, &ibuctx->xrcd_list, list) {
+		struct ib_xrcd *ibxrcd = uobj->object;
+		ib_dealloc_xrcd(ibxrcd);
+		ibp_destroy_uobj(uobj);
+	}
+
+	list_for_each_entry_safe(uobj, tmp, &ibuctx->pd_list, list) {
+		struct ib_pd *ibpd = uobj->object;
+		ib_dealloc_pd(ibpd);
+		ibp_destroy_uobj(uobj);
+	}
+
+	up_write(&list_rwsem);
+
+	synchronize_sched();
+
+	ibuctx->device->dealloc_ucontext(ibuctx);
+out:
+	if (ucontext->ibdev)
+		ib_unregister_event_handler(&ucontext->event_handler);
+
+	list_for_each_entry_safe(mmap, tmp_mmap, &ucontext->mmap_list, list) {
+		ibp_scif_unregister(ucontext->client, mmap);
+
+		if (!IS_NULL_OR_ERR(current) && !IS_NULL_OR_ERR(current->mm)) {
+			MUNMAP(current->mm, mmap->vaddr, mmap->len);
+		}
+		kfree(mmap);
+	}
+
+	while (!RB_EMPTY_ROOT(&ucontext->reg_tree)) {
+		struct ibp_reg *reg;
+		reg = rb_entry(ucontext->reg_tree.rb_node, struct ibp_reg,
+			       node);
+		kref_put(&reg->ref, ibp_dereg_buf);
+	}
+
+	ibp_put_device(ucontext->device);
+	fput(ucontext->filp);
+	kfree(ucontext);
+}
+
+void ibp_cleanup_ucontext(struct list_head *ucontext_list)
+{
+	struct ibp_ucontext		*ucontext;
+	struct ibp_ucontext		*next;
+
+	list_for_each_entry_safe(ucontext, next, ucontext_list, list)
+		ibp_destroy_ucontext(ucontext);
+}
+
+static int (*ibp_msg_table[])(struct ibp_client *client,
+			      struct ibp_msg_header *hdr, void *tx_buf) = {
+	[IBP_VERB_GET_PROTOCOL_STATS]		= ibp_cmd_not_supported,
+	[IBP_VERB_QUERY_DEVICE]			= ibp_cmd_query_device,
+	[IBP_VERB_QUERY_PORT]			= ibp_cmd_query_port,
+	[IBP_VERB_GET_LINK_LAYER]		= ibp_cmd_not_supported,
+	[IBP_VERB_QUERY_GID]			= ibp_cmd_query_gid,
+	[IBP_VERB_QUERY_PKEY]			= ibp_cmd_query_pkey,
+	[IBP_VERB_MODIFY_DEVICE]		= ibp_cmd_not_supported,
+	[IBP_VERB_MODIFY_PORT]			= ibp_cmd_not_supported,
+	[IBP_VERB_ALLOC_UCONTEXT]		= ibp_cmd_alloc_ucontext,
+	[IBP_VERB_DEALLOC_UCONTEXT]		= ibp_cmd_dealloc_ucontext,
+	[IBP_VERB_REG_BUF]			= ibp_cmd_reg_buf,
+	[IBP_VERB_DEREG_BUF]			= ibp_cmd_dereg_buf,
+	[IBP_VERB_MMAP]				= ibp_cmd_mmap,
+	[IBP_VERB_UNMMAP]			= ibp_cmd_unmmap,
+	[IBP_VERB_ALLOC_PD]			= ibp_cmd_alloc_pd,
+	[IBP_VERB_DEALLOC_PD]			= ibp_cmd_dealloc_pd,
+	[IBP_VERB_CREATE_AH]			= ibp_cmd_create_ah,
+	[IBP_VERB_MODIFY_AH]			= ibp_cmd_not_supported,
+	[IBP_VERB_QUERY_AH]			= ibp_cmd_query_ah,
+	[IBP_VERB_DESTROY_AH]			= ibp_cmd_destroy_ah,
+	[IBP_VERB_CREATE_SRQ]			= ibp_cmd_create_srq,
+	[IBP_VERB_MODIFY_SRQ]			= ibp_cmd_modify_srq,
+	[IBP_VERB_QUERY_SRQ]			= ibp_cmd_query_srq,
+	[IBP_VERB_DESTROY_SRQ]			= ibp_cmd_destroy_srq,
+	[IBP_VERB_POST_SRQ_RECV]		= ibp_cmd_not_supported,
+	[IBP_VERB_CREATE_QP]			= ibp_cmd_create_qp,
+	[IBP_VERB_MODIFY_QP]			= ibp_cmd_modify_qp,
+	[IBP_VERB_QUERY_QP]			= ibp_cmd_query_qp,
+	[IBP_VERB_DESTROY_QP]			= ibp_cmd_destroy_qp,
+	[IBP_VERB_POST_SEND]			= ibp_cmd_not_supported,
+	[IBP_VERB_POST_RECV]			= ibp_cmd_not_supported,
+	[IBP_VERB_CREATE_CQ]			= ibp_cmd_create_cq,
+	[IBP_VERB_MODIFY_CQ]			= ibp_cmd_not_supported,
+	[IBP_VERB_DESTROY_CQ]			= ibp_cmd_destroy_cq,
+	[IBP_VERB_RESIZE_CQ]			= ibp_cmd_resize_cq,
+	[IBP_VERB_POLL_CQ]			= ibp_cmd_not_supported,
+	[IBP_VERB_PEEK_CQ]			= ibp_cmd_not_supported,
+	[IBP_VERB_REQ_NOTIFY_CQ]		= ibp_cmd_not_supported,
+	[IBP_VERB_REQ_NCOMP_NOTIF]		= ibp_cmd_not_supported,
+	[IBP_VERB_GET_DMA_MR]			= ibp_cmd_not_supported,
+	[IBP_VERB_REG_PHYS_MR]			= ibp_cmd_not_supported,
+	[IBP_VERB_REG_USER_MR]			= ibp_cmd_reg_user_mr,
+	[IBP_VERB_QUERY_MR]			= ibp_cmd_not_supported,
+	[IBP_VERB_DEREG_MR]			= ibp_cmd_dereg_mr,
+	[IBP_VERB_ALLOC_FAST_REG_MR]		= ibp_cmd_not_supported,
+	[IBP_VERB_ALLOC_FAST_REG_PAGE_LIST]	= ibp_cmd_not_supported,
+	[IBP_VERB_FREE_FAST_REG_PAGE_LIST]	= ibp_cmd_not_supported,
+	[IBP_VERB_REREG_PHYS_MR]		= ibp_cmd_not_supported,
+	[IBP_VERB_ALLOC_MW]			= ibp_cmd_not_supported,
+	[IBP_VERB_BIND_MW]			= ibp_cmd_not_supported,
+	[IBP_VERB_DEALLOC_MW]			= ibp_cmd_not_supported,
+	[IBP_VERB_ALLOC_FMR]			= ibp_cmd_not_supported,
+	[IBP_VERB_MAP_PHYS_FMR]			= ibp_cmd_not_supported,
+	[IBP_VERB_UNMAP_FMR]			= ibp_cmd_not_supported,
+	[IBP_VERB_DEALLOC_FMR]			= ibp_cmd_not_supported,
+	[IBP_VERB_ATTACH_MCAST]			= ibp_cmd_attach_mcast,
+	[IBP_VERB_DETACH_MCAST]			= ibp_cmd_detach_mcast,
+	[IBP_VERB_PROCESS_MAD]			= ibp_cmd_not_supported,
+	[IBP_VERB_ALLOC_XRCD]			= ibp_cmd_not_supported,
+	[IBP_VERB_DEALLOC_XRCD]			= ibp_cmd_not_supported,
+};
+
+int ibp_init()
+{
+	a_stack = ibp_init_stack();
+	c_stack = ibp_init_stack();
+	o_stack = ibp_init_stack();
+
+	if (!a_stack || !c_stack || !o_stack) {
+		print_err("stack allocation failed\n");
+		return -ENOMEM;
+	}
+
+	return 0;
+}
+
+void ibp_cleanup()
+{
+	ibp_clear_stack(a_stack);
+	ibp_clear_stack(c_stack);
+	ibp_clear_stack(o_stack);
+}
+
+int ibp_process_recvs(struct ibp_client *client, void *rx_buf, void *tx_buf)
+{
+	struct ibp_msg_header		*hdr;
+	int				ret;
+
+	hdr = (struct ibp_msg_header *) rx_buf;
+
+	for (;;) {
+		wait_event_interruptible(client->rx_wait_queue,
+					 !atomic_xchg(&client->rx_in_process,
+						      1));
+
+		ret = ibp_recv(client->ep, hdr, sizeof(*hdr));
+		if (ret)
+			goto err;
+
+		if (hdr->length > MAX_MSG_SIZE) {
+			print_err("message too large, len %u max %lu\n",
+				  hdr->length, MAX_MSG_SIZE);
+			ret = -EMSGSIZE;
+			goto err;
+		}
+
+		ret = ibp_recv(client->ep, hdr->data,
+			       hdr->length - sizeof(*hdr));
+		if (ret)
+			goto err;
+
+		atomic_set(&client->rx_in_process, 0);
+		wake_up_interruptible(&client->rx_wait_queue);
+
+		if ((hdr->opcode >= ARRAY_SIZE(ibp_msg_table)) ||
+		    !ibp_msg_table[hdr->opcode]) {
+			ibp_cmd_bad_request(client, hdr, tx_buf);
+			continue;
+		}
+
+		ret = ibp_msg_table[hdr->opcode](client, hdr, tx_buf);
+		if (ret)
+			goto err;
+	}
+
+	goto out;
+err:
+	atomic_set(&client->rx_in_process, 0);
+	wake_up_interruptible(&client->rx_wait_queue);
+
+out:
+	return ret;
+}
diff -ruN a6/drivers/infiniband/ibp/drv/stack.c a7/drivers/infiniband/ibp/drv/stack.c
--- a6/drivers/infiniband/ibp/drv/stack.c	1969-12-31 16:00:00.000000000 -0800
+++ a7/drivers/infiniband/ibp/drv/stack.c	2015-09-10 09:33:35.331960564 -0700
@@ -0,0 +1,102 @@
+/*
+ * Copyright (c) 2011-2013 Intel Corporation. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *	  copyright notice, this list of conditions and the following
+ *	  disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *	  copyright notice, this list of conditions and the following
+ *	  disclaimer in the documentation and/or other materials
+ *	  provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include "common.h"
+#include "stack.h"
+
+static DEFINE_SPINLOCK(stack_lock);
+
+struct ibp_stack *ibp_init_stack(void)
+{
+	struct ibp_stack	*s;
+
+	s = kzalloc(sizeof(struct ibp_stack), GFP_KERNEL);
+	if (s)
+		s->top_pointer = &s->base[0];
+
+	return s;
+}
+
+void ibp_clear_stack(struct ibp_stack *s)
+{
+	while (s->top_pointer != s->base) {
+		s->top_pointer--;
+		kfree(*s->top_pointer);
+	}
+	kfree(s);
+}
+
+void ibp_add_to_stack(struct ibp_stack *s, void *p)
+{
+	spin_lock_irq(&stack_lock);
+
+	if (unlikely(++s->sample_cnt == STACK_GC_SAMPLE)) {
+		s->sample_cnt = 0;
+		if (unlikely(++s->gc_cnt == STACK_GC_RATE)) {
+			s->gc_cnt = 0;
+			while (s->current_count > s->high_water_mark) {
+				s->top_pointer--;
+				s->current_count--;
+				kfree(*s->top_pointer);
+			}
+		} else if (s->high_water_mark < s->current_count)
+			s->high_water_mark = s->current_count;
+	}
+
+	if (likely(s->current_count < MAX_STACK)) {
+		*s->top_pointer++ = p;
+		s->current_count++;
+	} else
+		kfree(p);
+
+	spin_unlock_irq(&stack_lock);
+}
+
+void *ibp_pull_from_stack(struct ibp_stack *s, size_t size, int gfp_mask)
+{
+	void			*p;
+	unsigned long		flag;
+
+	spin_lock_irqsave(&stack_lock, flag);
+
+	if (s->top_pointer == s->base)
+		p = kmalloc(size, gfp_mask);
+	else {
+		s->current_count--;
+		s->top_pointer--;
+		p = *s->top_pointer;
+	}
+
+	spin_unlock_irqrestore(&stack_lock, flag);
+
+	return p;
+}
diff -ruN a6/drivers/infiniband/ibp/drv/stack.h a7/drivers/infiniband/ibp/drv/stack.h
--- a6/drivers/infiniband/ibp/drv/stack.h	1969-12-31 16:00:00.000000000 -0800
+++ a7/drivers/infiniband/ibp/drv/stack.h	2015-09-10 09:33:35.331960564 -0700
@@ -0,0 +1,57 @@
+/*
+ * Copyright (c) 2011-2013 Intel Corporation. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *	  copyright notice, this list of conditions and the following
+ *	  disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *	  copyright notice, this list of conditions and the following
+ *	  disclaimer in the documentation and/or other materials
+ *	  provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#ifndef _IBP_STACK_H_
+#define _IBP_STACK_H_
+
+#define STACK_GC_SAMPLE		5
+#define STACK_GC_RATE		10
+#define MAX_STACK		128
+
+struct ibp_stack {
+	int			current_count;
+	int			high_water_mark;
+	int			gc_cnt;
+	int			sample_cnt;
+	void			**top_pointer;
+	void			*base[MAX_STACK+1];
+};
+
+struct ibp_stack *ibp_init_stack(void);
+
+void ibp_add_to_stack(struct ibp_stack *s, void *p);
+
+void *ibp_pull_from_stack(struct ibp_stack *s, size_t size, int gfp_mask);
+
+void ibp_clear_stack(struct ibp_stack *s);
+
+#endif /* _IBP_STACK_H_ */
diff -ruN a6/drivers/infiniband/ibp/Kconfig a7/drivers/infiniband/ibp/Kconfig
--- a6/drivers/infiniband/ibp/Kconfig	1969-12-31 16:00:00.000000000 -0800
+++ a7/drivers/infiniband/ibp/Kconfig	2015-09-10 09:33:35.331960564 -0700
@@ -0,0 +1,16 @@
+config IBP_SERVER
+	tristate "CCL Direct IB Server drivers"
+	---help---
+	  Server drivers for CCL Direct including server proxies for
+	  hw drivers, and core drivers ib_sa and ib_cm.
+	  Also includes is a kernel mode test module
+
+	  To compile this driver as a module, choose M here.
+	  If unsure, say N.
+
+config IBP_DEBUG
+	bool "CCL Direct debugging"
+	depends on IBP_SERVER
+	default y
+	---help---
+	  This option causes debug code to be compiled into the CCL Direct drivers.
diff -ruN a6/drivers/infiniband/ibp/Makefile a7/drivers/infiniband/ibp/Makefile
--- a6/drivers/infiniband/ibp/Makefile	1969-12-31 16:00:00.000000000 -0800
+++ a7/drivers/infiniband/ibp/Makefile	2015-09-10 09:33:35.331960564 -0700
@@ -0,0 +1,3 @@
+obj-$(CONFIG_IBP_SERVER)		+= drv/
+obj-$(CONFIG_IBP_SERVER)		+= cm/
+obj-$(CONFIG_IBP_SERVER)		+= sa/
diff -ruN a6/drivers/infiniband/ibp/sa/common.h a7/drivers/infiniband/ibp/sa/common.h
--- a6/drivers/infiniband/ibp/sa/common.h	1969-12-31 16:00:00.000000000 -0800
+++ a7/drivers/infiniband/ibp/sa/common.h	2015-09-10 09:33:35.331960564 -0700
@@ -0,0 +1,108 @@
+/*
+ * Copyright (c) 2011-2013 Intel Corporation. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *	  copyright notice, this list of conditions and the following
+ *	  disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *	  copyright notice, this list of conditions and the following
+ *	  disclaimer in the documentation and/or other materials
+ *	  provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#ifndef COMMON_H
+#define COMMON_H
+
+#include <linux/module.h>
+#include <linux/kthread.h>
+#include <linux/types.h>
+#include <linux/slab.h>
+#include <linux/poll.h>
+#include <linux/mman.h>
+#include <linux/pci.h>
+#include <linux/net.h>
+#include <rdma/ib_verbs.h>
+#include <scif.h>
+
+#define DRV_DESC	"CCL Direct SA " DRV_ROLE
+#define DRV_VERSION	"1.0"
+#define DRV_BASE	"ibp_sa"
+#define PFX		DRV_BASE "_"
+#define DRV_PFX		DRV_NAME ": "
+
+#define DRV_COPYRIGHT	"Copyright (c) 2011-2013 Intel Corporation"
+#define DRV_SIGNON	DRV_DESC " v" DRV_VERSION "\n" DRV_COPYRIGHT "\n"
+
+#define MODULE_PARAM(name, var, type, value, desc)	\
+	type var = value;				\
+	module_param_named(name, var, type, 0644);	\
+	MODULE_PARM_DESC(name, desc)
+
+#ifdef IBP_DEBUG
+extern int debug_level;
+#endif
+
+enum {
+	IBP_DEBUG_NONE,
+	IBP_DEBUG_TARGETED,
+	IBP_DEBUG_VERBOSE,
+};
+
+#define _PRINTK(l, f, arg...)	\
+	printk(l DRV_PFX "%s(%d) " f, __func__, __LINE__, ##arg)
+
+#ifdef IBP_DEBUG
+#define PRINTK(dbg, l, f, arg...)				\
+	do {							\
+		if (debug_level >= dbg)				\
+			printk(l DRV_PFX "%s(%d) " f,		\
+			       __func__, __LINE__, ##arg);	\
+	} while (0)
+#else
+#define PRINTK(dbg, l, f, arg...) do { } while (0)
+#endif
+
+#define print_dbg(f, arg...) PRINTK(IBP_DEBUG_TARGETED, KERN_DEBUG, f, ##arg)
+#define print_err(f, arg...) _PRINTK(KERN_ERR, f, ##arg)
+#define print_info(f, arg...) pr_info(f, ##arg)
+
+#if 0
+#define FORCED_FUNCTION_TRACING
+#endif
+
+#ifdef FORCED_FUNCTION_TRACING
+#define print_trace(f, arg...) _PRINTK(KERN_ERR, f, ##arg)
+#else
+#define print_trace(f, arg...) PRINTK(IBP_DEBUG_VERBOSE, KERN_ERR, f, ##arg)
+#endif
+
+#ifndef IBP_SA_PORT		/* unique scif port for this service */
+#define IBP_SA_PORT		SCIF_OFED_PORT_4
+#endif
+
+#define IS_NULL_OR_ERR(p) (!(p) || IS_ERR_VALUE((unsigned long)p))
+
+int ibp_send(scif_epd_t ep, void *buf, size_t len);
+int ibp_recv(scif_epd_t ep, void *buf, size_t len);
+
+#endif /* COMMON_H */
diff -ruN a6/drivers/infiniband/ibp/sa/ibp-abi.h a7/drivers/infiniband/ibp/sa/ibp-abi.h
--- a6/drivers/infiniband/ibp/sa/ibp-abi.h	1969-12-31 16:00:00.000000000 -0800
+++ a7/drivers/infiniband/ibp/sa/ibp-abi.h	2015-09-10 09:33:35.331960564 -0700
@@ -0,0 +1,101 @@
+/*
+ * Copyright (c) 2011-2013 Intel Corporation. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *	copyright notice, this list of conditions and the following
+ *	disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *	copyright notice, this list of conditions and the following
+ *	disclaimer in the documentation and/or other materials
+ *	provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#ifndef IBP_ABI_H
+#define IBP_ABI_H
+
+#include <linux/types.h>
+#include <rdma/ib_verbs.h>
+#include <rdma/ib_sa.h>
+
+/* Increment this value if any changes break compatibility. */
+#define IBP_CM_ABI_VERSION	1
+#define MAX_MSG_SIZE		PAGE_SIZE
+
+/* Client to server message enums. */
+enum {
+	/* have callback */
+	IBP_SA_PATH_REC_GET,
+	IBP_SA_JOIN_MCAST,
+
+	/* no callback */
+	IBP_SA_FREE_MCAST,
+	IBP_SA_GET_MCMEMBER_REC,
+	IBP_SA_REGISTER_CLIENT,
+	IBP_SA_UNREGISTER_CLIENT,
+	IBP_SA_CANCEL_QUERY,
+	IBP_INIT_AH_FROM_PATH,
+	IBP_INIT_AH_FROM_MCMEMBER,
+#if 0
+	/* not used or local to client */
+	IBP_SA_SERVICE_REC_QUERY,
+	IBP_SA_UNPACK_PATH,
+#endif
+};
+
+/* Server to client message enums. */
+enum {
+	IBP_CALLBACK,
+	IBP_RESPONSE,
+};
+
+enum {
+	PATH_REC_GET_CB,
+	JOIN_MCAST_CB,
+};
+
+/*
+ * Make sure that all structs defined in this file are laid out to pack
+ * the same way on different architectures to avoid incompatibility.
+ *
+ * Specifically:
+ *  - Do not use pointer types -- pass pointers in a u64 instead.
+ *  - Make sure that any structure larger than 4 bytes is padded
+ *    to a multiple of 8 bytes; otherwise the structure size may
+ *    be different between architectures.
+ */
+
+struct ibp_msg_header {			/* present in all messages */
+	u32			opcode;
+	u32			length;
+	u32			status;
+	u32			reserved;
+	u64			request;
+	u64			data[0];
+};
+
+struct ibp_verb_response_msg {
+	struct ibp_msg_header		header;
+	u64				data[0];
+};
+
+#endif /* IBP_ABI_H */
diff -ruN a6/drivers/infiniband/ibp/sa/ibp_exports.h a7/drivers/infiniband/ibp/sa/ibp_exports.h
--- a6/drivers/infiniband/ibp/sa/ibp_exports.h	1969-12-31 16:00:00.000000000 -0800
+++ a7/drivers/infiniband/ibp/sa/ibp_exports.h	2015-09-10 09:33:35.331960564 -0700
@@ -0,0 +1,49 @@
+/*
+ * Copyright (c) 2011-2013 Intel Corporation. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *	  copyright notice, this list of conditions and the following
+ *	  disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *	  copyright notice, this list of conditions and the following
+ *	  disclaimer in the documentation and/or other materials
+ *	  provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#ifndef IBP_EXPORTS_H
+#define IBP_EXPORTS_H
+
+#include <rdma/ib_verbs.h>
+
+/*
+ ibp_resolve_ib_device - Return the host ib_device handle
+ @ibdev:Card IB device
+
+ Upper level drivers may require the host ib_device handle associated
+ with the card ib_device.  This routine resolves the card ib_device to
+ the cooresponding host ib_device handle.  A value of 0 is returned if
+ no match was found.
+*/
+u64 ibp_resolve_ib_device(struct ib_device *ibdev);
+
+#endif /* IBP_EXPORTS_H */
diff -ruN a6/drivers/infiniband/ibp/sa/Makefile a7/drivers/infiniband/ibp/sa/Makefile
--- a6/drivers/infiniband/ibp/sa/Makefile	1969-12-31 16:00:00.000000000 -0800
+++ a7/drivers/infiniband/ibp/sa/Makefile	2015-09-10 09:33:35.331960564 -0700
@@ -0,0 +1,26 @@
+KERNEL_V := $(shell uname -r)
+
+KDIR ?= /lib/modules/$(KERNEL_V)/build
+
+SCIF_INCL := /usr/src/kernels/$(KERNEL_V)/include/modules/
+
+obj-$(CONFIG_IBP_SERVER) += ibp_sa_server.o
+
+ccflags-y += -I$(SCIF_INCL)
+ccflags-$(CONFIG_IBP_DEBUG) += -g -DIBP_DEBUG
+
+ibp_sa_server-y :=	server.o		\
+			server_msg.o		\
+			sa_server_msg.o
+
+default:
+	$(MAKE) -C $(KDIR) M=`pwd`
+
+modules_install:
+	$(MAKE) -C $(KDIR) M=`pwd` modules_install
+
+clean:
+	rm -rf *.ko *.o .*.ko.cmd .*.o.cmd *.mod.c Module.* modules.order .tmp_versions
+
+unix:
+	dos2unix *.[ch] Kconfig Makefile
diff -ruN a6/drivers/infiniband/ibp/sa/sa_ibp_abi.h a7/drivers/infiniband/ibp/sa/sa_ibp_abi.h
--- a6/drivers/infiniband/ibp/sa/sa_ibp_abi.h	1969-12-31 16:00:00.000000000 -0800
+++ a7/drivers/infiniband/ibp/sa/sa_ibp_abi.h	2015-09-10 09:33:35.332958325 -0700
@@ -0,0 +1,251 @@
+/*
+ * Copyright (c) 2011-2013 Intel Corporation. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *	copyright notice, this list of conditions and the following
+ *	disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *	copyright notice, this list of conditions and the following
+ *	disclaimer in the documentation and/or other materials
+ *	provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#ifndef SA_IBP_ABI_H
+#define SA_IBP_ABI_H
+
+#include <linux/types.h>
+#include <rdma/ib_verbs.h>
+#include <rdma/ib_sa.h>
+
+/* Increment this value if any changes break compatibility. */
+#define IBP_SA_ABI_VERSION	1
+
+/*
+ * Make sure that all structs defined in this file are laid out to pack
+ * the same way on different architectures to avoid incompatibility.
+ *
+ * Specifically:
+ *  - Do not use pointer types -- pass pointers in a u64 instead.
+ *  - Make sure that any structure larger than 4 bytes is padded
+ *    to a multiple of 8 bytes; otherwise the structure size may
+ *    be different between architectures.
+ */
+
+struct cb_header {
+	u64				cb_type;
+	u64				status;
+	u64				ibp_client;
+};
+
+struct ibp_sa_path_rec {
+	__be64				service_id;
+	u64				dgid_prefix;
+	u64				dgid_id;
+	u64				sgid_prefix;
+	u64				sgid_id;
+	__be16				dlid;
+	__be16				slid;
+	u32				raw_traffic;
+	__be32				flow_label;
+	u8				hop_limit;
+	u8				traffic_class;
+	u32				reversible;
+	u8				numb_path;
+	__be16				pkey;
+	__be16				qos_class;
+	u8				sl;
+	u8				mtu_selector;
+	u8				mtu;
+	u8				rate_selector;
+	u8				rate;
+	u8				packet_life_time_selector;
+	u8				packet_life_time;
+	u8				preference;
+};
+
+struct path_rec_data {
+	u64				entry;
+	u64				query;
+	struct ibp_sa_path_rec		resp;
+	u8				reserved[1];
+};
+
+struct ibp_sa_mcmember_rec {
+	u64				mgid_prefix;
+	u64				mgid_id;
+	u64				port_gid_prefix;
+	u64				port_gid_id;
+	__be32				qkey;
+	__be16				mlid;
+	u8				mtu_selector;
+	u8				mtu;
+	u8				traffic_class;
+	__be16				pkey;
+	u8				rate_selector;
+	u8				rate;
+	u8				packet_life_time_selector;
+	u8				packet_life_time;
+	u8				sl;
+	__be32				flow_label;
+	u8				hop_limit;
+	u8				scope;
+	u8				join_state;
+	u64				proxy_join;
+	u8				reserved[1];
+};
+
+struct mc_join_data {
+	u64				mcentry;
+	u64				ibp_mcast;
+	struct ibp_sa_mcmember_rec	rec;
+};
+
+struct callback_msg {
+	struct cb_header		header;
+	union {
+		struct path_rec_data	path_rec;
+		struct mc_join_data	mc_join;
+	} u;
+};
+
+struct ibp_callback_msg {
+	struct ibp_msg_header		header;
+	u8				data[0];
+};
+
+struct ibp_sa_path_rec_get_cmd {
+	struct ibp_msg_header		header;
+	u64				ibp_client;
+	u64				entry;
+	u64				query;
+	u64				device;
+	u64				port_num;
+	u64				comp_mask;
+	u64				timeout_ms;
+	u64				gfp_mask;
+	struct ibp_sa_path_rec		rec;
+};
+
+struct ibp_sa_path_rec_get_resp {
+	u64				sa_query;
+	u64				query_id;
+};
+
+struct ibp_sa_register_client_cmd {
+	struct ibp_msg_header		header;
+};
+
+struct ibp_sa_register_client_resp {
+	u64				ibp_client;
+};
+
+struct ibp_sa_unregister_client_cmd {
+	struct ibp_msg_header		header;
+	u64				ibp_client;
+};
+
+struct ibp_sa_cancel_query_cmd {
+	struct ibp_msg_header		header;
+	u64				id;
+	u64				client;
+};
+
+struct ibp_init_ah_from_path_cmd {
+	struct ibp_msg_header		header;
+	u64				device;
+	u8				port_num;
+	struct ibp_sa_path_rec		rec;
+};
+
+struct ibp_ah_attr {
+	u64			dgid_prefix;
+	u64			dgid_id;
+	u32			flow_label;
+	u8			sgid_index;
+	u8			hop_limit;
+	u8			traffic_class;
+	u16			dlid;
+	u8			sl;
+	u8			src_path_bits;
+	u8			static_rate;
+	u8			ah_flags;
+	u8			port_num;
+};
+struct ibp_init_ah_from_path_resp {
+	struct ibp_ah_attr		attr;
+};
+
+struct ibp_init_ah_from_mcmember_cmd {
+	struct ibp_msg_header		header;
+	u64				device;
+	u8				port_num;
+	struct ib_sa_mcmember_rec	rec;
+};
+
+struct ibp_init_ah_from_mcmember_resp {
+	struct ibp_ah_attr		attr;
+};
+
+struct ibp_sa_join_multicast_cmd {
+	struct ibp_msg_header		header;
+	u64				ibp_client;
+	u64				mcentry;
+	u64				device;
+	u8				port_num;
+	u64				comp_mask;
+	u64				gfp_mask;
+	struct ib_sa_mcmember_rec	rec;
+};
+
+struct ibp_sa_join_multicast_resp {
+	u64				ibp_mcast;
+};
+
+struct ibp_sa_free_multicast_cmd {
+	struct ibp_msg_header		header;
+	u64				ibp_mcast;
+};
+
+struct ibp_sa_get_mcmember_rec_cmd {
+	struct ibp_msg_header		header;
+	u64				device;
+	u8				port_num;
+	u64				subnet_prefix;
+	u64				interface_id;
+};
+
+struct ibp_sa_get_mcmember_rec_resp {
+	struct ib_sa_mcmember_rec	rec;
+};
+
+struct ibp_sa_event {
+	enum ib_event_type		event_type;
+	u64				ibp_client;
+	union {
+		__u32			send_status;
+	} u;
+	u64				data_length;
+	u8				data[0];
+};
+
+#endif /* SA_IBP_ABI_H */
diff -ruN a6/drivers/infiniband/ibp/sa/sa_server_msg.c a7/drivers/infiniband/ibp/sa/sa_server_msg.c
--- a6/drivers/infiniband/ibp/sa/sa_server_msg.c	1969-12-31 16:00:00.000000000 -0800
+++ a7/drivers/infiniband/ibp/sa/sa_server_msg.c	2015-09-10 09:33:35.332958325 -0700
@@ -0,0 +1,970 @@
+/*
+ * Copyright (c) 2011-2013 Intel Corporation. All rights reserved.
+ * * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *     - Redistributions of source code must retain the above
+ *	 copyright notice, this list of conditions and the following
+ *	 disclaimer.
+ *
+ *     - Redistributions in binary form must reproduce the above
+ *	 copyright notice, this list of conditions and the following
+ *	 disclaimer in the documentation and/or other materials
+ *	 provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include "server.h"
+
+LIST_HEAD(sa_entry_list);
+LIST_HEAD(query_list);
+LIST_HEAD(mcast_list);
+
+static void free_query_list(struct sa_query_entry *entry)
+{
+	if (entry) {
+		down_write(&list_rwsem);
+
+		list_del(&entry->list);
+
+		up_write(&list_rwsem);
+	}
+}
+
+static struct sa_query_entry *add_query_list(struct ibp_client *client)
+{
+	struct sa_query_entry			*entry;
+
+	print_trace("in\n");
+
+	entry = kzalloc(sizeof(struct sa_query_entry), GFP_KERNEL);
+	if (!entry) {
+		print_err("kzalloc failed\n");
+		return ERR_PTR(-ENOMEM);
+	}
+
+	entry->ibp_client	= client;
+
+	down_write(&list_rwsem);
+
+	list_add(&entry->list, &query_list);
+
+	up_write(&list_rwsem);
+
+	return entry;
+}
+
+static struct sa_query_entry *find_query_entry(struct ib_sa_client *client)
+{
+	struct sa_query_entry			*query = NULL;
+
+	down_read(&list_rwsem);
+
+	list_for_each_entry(query, &query_list, list)
+		if (query->sa_client == client)
+			goto out;
+
+	print_err("Could not find sa_query_entry\n");
+
+out:
+	up_read(&list_rwsem);
+
+	return query;
+}
+
+static struct sa_entry *find_sa_entry(struct ib_sa_client *ib_client)
+{
+	struct sa_entry				*entry = NULL;
+
+	down_read(&list_rwsem);
+
+	list_for_each_entry(entry, &sa_entry_list, list)
+		if (&entry->ib_client == ib_client)
+			goto out;
+
+	print_err("Could not find sa_entry\n");
+
+out:
+	up_read(&list_rwsem);
+
+	return entry;
+}
+
+/* Translate from server side "true" SA client to proxied SA client on the
+ * client
+ */
+static struct ib_sa_client *find_ibp_client(struct ibp_client *ibp_client)
+{
+	struct sa_entry				*entry;
+	struct ib_sa_client			*client = NULL;
+
+	down_read(&list_rwsem);
+
+	list_for_each_entry(entry, &sa_entry_list, list)
+		if (entry->client == ibp_client) {
+			client = &entry->ib_client;
+			goto out;
+		}
+
+	print_err("Could not find proxied sa_client %p\n", ibp_client);
+
+out:
+	up_read(&list_rwsem);
+
+	return client;
+}
+
+int ibp_cmd_sa_register_client(struct ibp_client *ibp_client,
+			       struct ibp_msg_header *hdr)
+{
+	struct sa_entry				*entry;
+	struct ibp_verb_response_msg		*msg;
+	struct ibp_sa_register_client_resp	*resp;
+	size_t					len;
+	int					status = 0;
+	int					ret;
+
+	print_trace("in\n");
+
+	msg = (struct ibp_verb_response_msg *) ibp_client->tx_buf;
+	len = sizeof(*msg);
+
+	entry = kzalloc((sizeof(struct sa_entry)), GFP_KERNEL);
+	if (!entry) {
+		print_err("kzalloc failed\n");
+		status = -ENOMEM;
+		goto send_resp;
+	}
+
+	entry->client = ibp_client;
+
+	len  += sizeof(*resp);
+
+	resp = (struct ibp_sa_register_client_resp *) msg->data;
+
+	resp->ibp_client = (u64) &entry->ib_client;
+send_resp:
+	IBP_INIT_RESP(msg, len, RESPONSE, hdr->request, status);
+
+	ret = ibp_send(ibp_client->ep, msg, len);
+	if (ret) {
+		kfree(entry);
+		print_err("ibp_send returned %d\n", ret);
+		return ret;
+	}
+	if (status)
+		return status;
+
+	ib_sa_register_client(&entry->ib_client);
+
+	down_write(&list_rwsem);
+	list_add(&entry->list, &sa_entry_list);
+	up_write(&list_rwsem);
+
+	return 0;
+}
+
+int ibp_cmd_sa_unregister_client(struct ibp_client *ibp_client,
+				 struct ibp_msg_header *hdr)
+{
+	struct sa_entry				*entry;
+	struct ibp_sa_unregister_client_cmd	*cmd;
+	struct ibp_verb_response_msg		*msg;
+	struct ib_sa_client			*client;
+	size_t					len;
+	int					ret = 0;
+
+	print_trace("in\n");
+
+	cmd = (struct ibp_sa_unregister_client_cmd *) hdr;
+	client = (struct ib_sa_client *) cmd->ibp_client;
+	msg = (struct ibp_verb_response_msg *) ibp_client->tx_buf;
+	len = sizeof(*msg);
+
+	entry = find_sa_entry(client);
+	if (!entry) {
+		ret = -EINVAL;
+		goto send_resp;
+	}
+
+	down_write(&list_rwsem);
+	list_del(&entry->list);
+	up_write(&list_rwsem);
+
+	ib_sa_unregister_client(&entry->ib_client);
+
+send_resp:
+	IBP_INIT_RESP(msg, len, RESPONSE, hdr->request, ret);
+
+	ret = ibp_send(ibp_client->ep, msg, len);
+	if (ret)
+		print_err("ibp_send returned %d\n", ret);
+
+	return ret;
+}
+
+int ibp_cmd_sa_cancel_query(struct ibp_client *ibp_client,
+			    struct ibp_msg_header *hdr)
+{
+	struct sa_query_entry			*entry;
+	struct ibp_sa_cancel_query_cmd		*cmd;
+	struct ibp_verb_response_msg		*msg;
+	size_t					len;
+	int					ret = 0;
+
+	print_trace("in\n");
+
+	cmd = (struct ibp_sa_cancel_query_cmd *) hdr;
+	msg = (struct ibp_verb_response_msg *) ibp_client->tx_buf;
+	len = sizeof(*msg);
+
+	entry = find_query_entry((struct ib_sa_client *) cmd->client);
+	if (!entry) {
+		ret = -EINVAL;
+		goto send_resp;
+	}
+
+	ib_sa_cancel_query(cmd->id, entry->query);
+
+	free_query_list(entry);
+
+send_resp:
+	IBP_INIT_RESP(msg, len, RESPONSE, hdr->request, ret);
+
+	ret = ibp_send(ibp_client->ep, msg, len);
+	if (ret)
+		print_err("ibp_send returned %d\n", ret);
+
+	return ret;
+}
+
+int ibp_cmd_init_ah_from_path(struct ibp_client *ibp_client,
+			      struct ibp_msg_header *hdr)
+{
+	struct ib_device			*device;
+	struct ibp_verb_response_msg		*msg;
+	struct ibp_init_ah_from_path_cmd	*cmd;
+	struct ibp_init_ah_from_path_resp	*resp;
+	struct ib_sa_path_rec			rec;
+	struct ib_ah_attr			attr;
+	size_t					len;
+	u8					port_num;
+	int					ret;
+
+	print_trace("in\n");
+
+	cmd = (struct ibp_init_ah_from_path_cmd *) hdr;
+	device = (struct ib_device *) cmd->device;
+	msg = (struct ibp_verb_response_msg *) ibp_client->tx_buf;
+	len = sizeof(*msg);
+
+	port_num  = cmd->port_num;
+
+	rec.service_id		= cmd->rec.service_id;
+	rec.dgid.global.interface_id
+				= cmd->rec.dgid_id;
+	rec.dgid.global.subnet_prefix
+				= cmd->rec.dgid_prefix;
+	rec.sgid.global.interface_id
+				= cmd->rec.sgid_id;
+	rec.sgid.global.subnet_prefix
+				= cmd->rec.sgid_prefix;
+	rec.dlid		= cmd->rec.dlid;
+	rec.slid		= cmd->rec.slid;
+	rec.raw_traffic		= cmd->rec.raw_traffic;
+	rec.flow_label		= cmd->rec.flow_label;
+	rec.hop_limit		= cmd->rec.hop_limit;
+	rec.traffic_class	= cmd->rec.traffic_class;
+	rec.reversible		= cmd->rec.reversible;
+	rec.numb_path		= cmd->rec.numb_path;
+	rec.pkey		= cmd->rec.pkey;
+	rec.qos_class		= cmd->rec.qos_class;
+	rec.sl			= cmd->rec.sl;
+	rec.mtu_selector	= cmd->rec.mtu_selector;
+	rec.mtu			= cmd->rec.mtu;
+	rec.rate_selector	= cmd->rec.rate_selector;
+	rec.rate		= cmd->rec.rate;
+	rec.packet_life_time_selector
+				= cmd->rec.packet_life_time_selector;
+	rec.packet_life_time	= cmd->rec.packet_life_time;
+	rec.preference		= cmd->rec.preference;
+
+	ret = ib_init_ah_from_path(device, port_num, &rec, &attr);
+	if (ret)
+		print_err("init_ah_from_path returned %d\n", ret);
+
+	len += sizeof(*resp);
+	resp = (struct ibp_init_ah_from_path_resp *) msg->data;
+
+	resp->attr.dgid_prefix	= attr.grh.dgid.global.subnet_prefix;
+	resp->attr.dgid_id	= attr.grh.dgid.global.interface_id;
+	resp->attr.flow_label	= attr.grh.flow_label;
+	resp->attr.sgid_index	= attr.grh.sgid_index;
+	resp->attr.hop_limit	= attr.grh.hop_limit;
+	resp->attr.traffic_class
+				= attr.grh.traffic_class;
+	resp->attr.dlid		= attr.dlid;
+	resp->attr.sl		= attr.sl;
+	resp->attr.src_path_bits
+				= attr.src_path_bits;
+	resp->attr.static_rate	= attr.static_rate;
+	resp->attr.ah_flags	= attr.ah_flags;
+	resp->attr.port_num	= attr.port_num;
+
+	IBP_INIT_RESP(msg, len, RESPONSE, hdr->request, ret);
+
+	ret = ibp_send(ibp_client->ep, msg, len);
+	if (ret)
+		print_err("ibp_send returned %d\n", ret);
+
+	return ret;
+}
+
+int ibp_cmd_init_ah_from_mcmember(struct ibp_client *ibp_client,
+				  struct ibp_msg_header *hdr)
+{
+	struct ib_device			*device;
+	struct ibp_init_ah_from_mcmember_cmd	*cmd;
+	struct ibp_verb_response_msg		*msg;
+	struct ibp_init_ah_from_mcmember_resp	*resp;
+	struct ib_sa_mcmember_rec		rec;
+	struct ib_ah_attr			attr;
+	size_t					len;
+	int					ret;
+
+	print_trace("in\n");
+
+	cmd = (struct ibp_init_ah_from_mcmember_cmd *) hdr;
+	device = (struct ib_device *) cmd->device;
+	msg = (struct ibp_verb_response_msg *) ibp_client->tx_buf;
+	len = sizeof(*msg);
+
+	rec.mgid.global.subnet_prefix	= cmd->rec.mgid.global.subnet_prefix;
+	rec.mgid.global.interface_id	= cmd->rec.mgid.global.interface_id;
+	rec.port_gid.global.subnet_prefix
+				= cmd->rec.port_gid.global.subnet_prefix;
+	rec.port_gid.global.interface_id
+				= cmd->rec.port_gid.global.interface_id;
+	rec.qkey		= cmd->rec.qkey;
+	rec.mlid		= cmd->rec.mlid;
+	rec.mtu_selector	= cmd->rec.mtu_selector;
+	rec.mtu			= cmd->rec.mtu;
+	rec.traffic_class	= cmd->rec.traffic_class;
+	rec.pkey		= cmd->rec.pkey;
+	rec.rate_selector	= cmd->rec.rate_selector;
+	rec.rate		= cmd->rec.rate;
+	rec.packet_life_time_selector
+				= cmd->rec.packet_life_time_selector;
+	rec.packet_life_time	= cmd->rec.packet_life_time;
+	rec.sl			= cmd->rec.sl;
+	rec.flow_label		= cmd->rec.flow_label;
+	rec.hop_limit		= cmd->rec.hop_limit;
+	rec.scope		= cmd->rec.scope;
+	rec.join_state		= cmd->rec.join_state;
+	rec.proxy_join		= cmd->rec.proxy_join;
+
+	ret = ib_init_ah_from_mcmember(device, cmd->port_num, &rec, &attr);
+	if (ret) {
+		print_err("ib_init_ah_from_mcmember returned %d\n", ret);
+		goto send_resp;
+	}
+
+	len += sizeof(*resp);
+	resp = (struct ibp_init_ah_from_mcmember_resp *) msg->data;
+
+	resp->attr.dgid_prefix	= attr.grh.dgid.global.subnet_prefix;
+	resp->attr.dgid_id	= attr.grh.dgid.global.interface_id;
+	resp->attr.flow_label	= attr.grh.flow_label;
+	resp->attr.sgid_index	= attr.grh.sgid_index;
+	resp->attr.hop_limit	= attr.grh.hop_limit;
+	resp->attr.traffic_class
+				= attr.grh.traffic_class;
+	resp->attr.dlid		= attr.dlid;
+	resp->attr.sl		= attr.sl;
+	resp->attr.src_path_bits
+				= attr.src_path_bits;
+	resp->attr.static_rate	= attr.static_rate;
+	resp->attr.ah_flags	= attr.ah_flags;
+	resp->attr.port_num	= attr.port_num;
+
+
+send_resp:
+	IBP_INIT_RESP(msg, len, RESPONSE, hdr->request, ret);
+
+	ret = ibp_send(ibp_client->ep, msg, len);
+	if (ret)
+		print_err("ibp_send returned %d\n", ret);
+
+	return ret;
+}
+
+static void ibp_send_callback(struct work_struct *work)
+{
+	struct callback_work			*cb_work;
+	struct ibp_callback_msg			*msg;
+	struct cb_header			*header;
+	struct ibp_client			*client;
+	size_t					len;
+	int					data_length;
+	int					cb_type;
+	int					ret;
+
+	print_trace("in\n");
+
+	cb_work = (struct callback_work *) work;
+	len = sizeof(*msg);
+
+	if (!cb_work) {
+		print_err("Invalid callback work_struct\n");
+		return;
+	}
+
+	header = &cb_work->msg.header;
+	cb_type = header->cb_type;
+
+	client = cb_work->client;
+	if (!client) {
+		print_err("Invalid callback client\n");
+		goto err;
+	}
+	if (!client->ep) {
+		print_err("Invalid callback client ep\n");
+		goto err;
+	}
+	if (cb_work->data->ret) {
+		print_err("caller failed to send msg to card\n");
+		goto err;
+	}
+
+	data_length = cb_work->length;
+
+	if (cb_type == PATH_REC_GET_CB) {
+		ret = sizeof(struct path_rec_data) + sizeof(struct cb_header);
+		if (data_length != ret) {
+			print_err("Invalid data length %d, expecting %d\n",
+				  data_length, ret);
+			goto err;
+		}
+	} else if (cb_type == JOIN_MCAST_CB) {
+		ret = sizeof(struct mc_join_data) + sizeof(struct cb_header);
+		if (data_length != ret) {
+			print_err("Invalid data length %d, expecting %d\n",
+				  data_length, ret);
+			goto err;
+		}
+	} else {
+		print_err("Invalid callback type %d\n", cb_type);
+		goto err;
+	}
+
+	len += data_length;
+
+	msg = kzalloc(len, GFP_KERNEL);
+	if (!msg) {
+		print_err("kzmalloc failed\n");
+		goto err;
+	}
+	IBP_INIT_MSG(msg, len, CALLBACK);
+
+	memcpy(msg->data, &cb_work->msg, data_length);
+
+	/* wait for host to send message to card before processing cb */
+	mutex_lock(&cb_work->data->lock);
+
+	ret = ibp_send(client->ep, msg, len);
+	if (ret)
+		print_err("ibp_send returned %d\n", ret);
+
+	mutex_unlock(&cb_work->data->lock);
+
+	kfree(msg);
+err:
+	if (cb_type == PATH_REC_GET_CB)
+		kfree(cb_work->data);
+
+	kfree(cb_work);
+}
+
+static void path_rec_get_callback(int status, struct ib_sa_path_rec *resp,
+				  void *context)
+{
+	struct path_rec_cb_data			*data;
+	struct sa_query_entry			*entry;
+	struct ibp_client			*client;
+	struct ib_sa_client			*ib_client;
+	struct callback_work			*cb_work;
+	struct cb_header			*header;
+	struct path_rec_data			*path_rec;
+
+	print_trace("in\n");
+
+	data = (struct path_rec_cb_data *) context;
+	entry = data->entry;
+	client = entry->ibp_client;
+
+	cb_work = kzalloc(sizeof(struct callback_work), GFP_KERNEL);
+	if (!cb_work) {
+		print_err("kzalloc failed\n");
+		goto err1;
+	}
+
+	ib_client = find_ibp_client(client);
+	if (!ib_client) {
+		print_err("Could not find client for event handler\n");
+		goto err2;
+	}
+
+	if (!entry->query) {
+		print_err("Callback occurred before call returned\n");
+		goto err2;
+	}
+
+	cb_work->data		= (struct generic_cb_data *) data;
+	cb_work->client		= client;
+	cb_work->length		= sizeof(*header) + sizeof(*path_rec);
+
+	header			= &cb_work->msg.header;
+	header->cb_type		= PATH_REC_GET_CB;
+	header->status		= status;
+	header->ibp_client	= (u64) ib_client;
+
+	path_rec		= &cb_work->msg.u.path_rec;
+	path_rec->entry		= data->ibp_entry;
+	path_rec->query		= data->ibp_query;
+
+	if (status) {
+		print_err("callback status %d\n", status);
+		// XXX How is data deallocated in error cases?
+		goto queue_work;
+	}
+
+	path_rec->resp.service_id	= resp->service_id;
+	path_rec->resp.dgid_prefix	= resp->dgid.global.subnet_prefix;
+	path_rec->resp.dgid_id		= resp->dgid.global.interface_id;
+	path_rec->resp.sgid_prefix	= resp->sgid.global.subnet_prefix;
+	path_rec->resp.sgid_id		= resp->sgid.global.interface_id;
+	path_rec->resp.dlid		= resp->dlid;
+	path_rec->resp.slid		= resp->slid;
+	path_rec->resp.raw_traffic	= resp->raw_traffic;
+	path_rec->resp.flow_label	= resp->flow_label;
+	path_rec->resp.hop_limit	= resp->hop_limit;
+	path_rec->resp.traffic_class	= resp->traffic_class;
+	path_rec->resp.reversible	= resp->reversible;
+	path_rec->resp.numb_path	= resp->numb_path;
+	path_rec->resp.pkey		= resp->pkey;
+	path_rec->resp.qos_class	= resp->qos_class;
+	path_rec->resp.sl		= resp->sl;
+	path_rec->resp.mtu_selector	= resp->mtu_selector;
+	path_rec->resp.mtu		= resp->mtu;
+	path_rec->resp.rate_selector	= resp->rate_selector;
+	path_rec->resp.rate		= resp->rate;
+	path_rec->resp.packet_life_time_selector
+					= resp->packet_life_time_selector;
+	path_rec->resp.packet_life_time	= resp->packet_life_time;
+	path_rec->resp.preference	= resp->preference;
+
+queue_work:
+	free_query_list(entry);
+
+	INIT_WORK(&cb_work->work, ibp_send_callback);
+	queue_work(client->workqueue, &cb_work->work);
+	return;
+err2:
+	kfree(cb_work);
+err1:
+	kfree(data);
+	return;
+}
+
+int ibp_cmd_sa_path_rec_get(struct ibp_client *ibp_client,
+			    struct ibp_msg_header *hdr)
+{
+	struct ib_device			*ib_device;
+	struct ibp_verb_response_msg		*msg;
+	struct ibp_sa_path_rec_get_cmd		*cmd;
+	struct ibp_sa_path_rec_get_resp		*resp;
+	struct ib_sa_client			*client;
+	struct ib_sa_query			*sa_query;
+	struct sa_query_entry			*entry;
+	struct path_rec_cb_data			*data = NULL;
+	struct ib_sa_path_rec			rec;
+	size_t					len;
+	int					query_id;
+	int					ret = 0;
+
+	print_trace("in\n");
+
+	cmd = (struct ibp_sa_path_rec_get_cmd *) hdr;
+	ib_device = (struct ib_device *) cmd->device;
+	client = (struct ib_sa_client *) cmd->ibp_client;
+	msg = (struct ibp_verb_response_msg *) ibp_client->tx_buf;
+	len = sizeof(*msg);
+
+	entry = add_query_list(ibp_client);
+	if (IS_ERR(entry)) {
+		ret = PTR_ERR(entry);
+		goto send_resp;
+	}
+
+	data = kzalloc(sizeof(*data), GFP_KERNEL);
+	if (!data) {
+		free_query_list(entry);
+		print_err("kzalloc failed\n");
+		ret = -ENOMEM;
+		goto send_resp;
+	}
+
+	data->entry = entry;
+	data->ibp_entry = cmd->entry;
+	data->ibp_query = cmd->query;
+
+	rec.service_id		= cmd->rec.service_id;
+	rec.dgid.global.interface_id
+				= cmd->rec.dgid_id;
+	rec.dgid.global.subnet_prefix
+				= cmd->rec.dgid_prefix;
+	rec.sgid.global.interface_id
+				= cmd->rec.sgid_id;
+	rec.sgid.global.subnet_prefix
+				= cmd->rec.sgid_prefix;
+	rec.dlid		= cmd->rec.dlid;
+	rec.slid		= cmd->rec.slid;
+	rec.raw_traffic		= cmd->rec.raw_traffic;
+	rec.flow_label		= cmd->rec.flow_label;
+	rec.hop_limit		= cmd->rec.hop_limit;
+	rec.traffic_class	= cmd->rec.traffic_class;
+	rec.reversible		= cmd->rec.reversible;
+	rec.numb_path		= cmd->rec.numb_path;
+	rec.pkey		= cmd->rec.pkey;
+	rec.qos_class		= cmd->rec.qos_class;
+	rec.sl			= cmd->rec.sl;
+	rec.mtu_selector	= cmd->rec.mtu_selector;
+	rec.mtu			= cmd->rec.mtu;
+	rec.rate_selector	= cmd->rec.rate_selector;
+	rec.rate		= cmd->rec.rate;
+	rec.packet_life_time_selector
+				= cmd->rec.packet_life_time_selector;
+	rec.packet_life_time	= cmd->rec.packet_life_time;
+	rec.preference		= cmd->rec.preference;
+
+	mutex_init(&data->lock);
+	mutex_lock(&data->lock);
+
+	query_id = ib_sa_path_rec_get(client, ib_device, cmd->port_num, &rec,
+				      cmd->comp_mask, cmd->timeout_ms,
+				      GFP_KERNEL, path_rec_get_callback, data,
+				      &sa_query);
+	if (query_id < 0) {
+		ret = query_id;
+		print_err("ib_sa_path_rec_get returned %d\n", ret);
+		free_query_list(entry);
+		mutex_unlock(&data->lock);
+		kfree(data);
+		data = NULL;
+		goto send_resp;
+	}
+	entry->query	 = sa_query;
+	entry->sa_client = client;
+	entry->id	 = query_id;
+
+	len += sizeof(*resp);
+	resp = (struct ibp_sa_path_rec_get_resp *) msg->data;
+	resp->query_id = query_id;
+	resp->sa_query = (u64)sa_query;
+
+send_resp:
+	IBP_INIT_RESP(msg, len, RESPONSE, hdr->request, ret);
+
+	ret = ibp_send(ibp_client->ep, msg, len);
+
+	if (data) {
+		data->ret = ret;
+		mutex_unlock(&data->lock);
+	}
+
+	if (ret)
+		print_err("ibp_send returned %d\n", ret);
+
+	return ret;
+}
+
+static int sa_join_callback(int status, struct ib_sa_multicast *multicast)
+{
+	struct join_mcast_cb_data		*data;
+	struct ibp_client			*client;
+	struct ib_sa_client			*ib_client;
+	struct callback_work			*cb_work;
+	struct cb_header			*header;
+	struct mc_join_data			*mc_join;
+	struct ib_sa_mcmember_rec		*ib_rec;
+	struct ibp_sa_mcmember_rec		*ibp_rec;
+	int					ret = 0;
+
+	print_trace("in\n");
+
+	data = (struct join_mcast_cb_data *) multicast->context;
+
+	if (status == -ENETRESET)
+		goto err1;
+
+	cb_work = kzalloc(sizeof(struct callback_work), GFP_KERNEL);
+	if (!cb_work) {
+		print_err("kzalloc failed\n");
+		ret = -ENOMEM;
+		goto err1;
+	}
+
+	client = data->client;
+
+	ib_client = find_ibp_client(client);
+	if (!ib_client) {
+		print_err("Could not find client for event handler\n");
+		ret = -EINVAL;
+		goto err2;
+	}
+
+	cb_work->data		= (struct generic_cb_data *) data;
+	cb_work->client		= client;
+	cb_work->length		= sizeof(*header) + sizeof(*mc_join);
+
+	header			= &cb_work->msg.header;
+	header->cb_type		= JOIN_MCAST_CB;
+	header->status		= status;
+	header->ibp_client	= (u64) ib_client;
+
+	mc_join			= &cb_work->msg.u.mc_join;
+	mc_join->ibp_mcast	= (u64) multicast;
+	mc_join->mcentry	= data->mcentry;
+
+	if (status) {
+		print_err("callback status %d\n", status);
+		goto queue_work;
+	}
+
+	ib_rec = &multicast->rec;
+	ibp_rec = &mc_join->rec;
+
+	ibp_rec->mgid_prefix	  = ib_rec->mgid.global.subnet_prefix;
+	ibp_rec->mgid_id	  = ib_rec->mgid.global.interface_id;
+	ibp_rec->port_gid_prefix  = ib_rec->port_gid.global.subnet_prefix;
+	ibp_rec->port_gid_id	  = ib_rec->port_gid.global.interface_id;
+	ibp_rec->qkey		  = ib_rec->qkey;
+	ibp_rec->mlid		  = ib_rec->mlid;
+	ibp_rec->mtu_selector	  = ib_rec->mtu_selector;
+	ibp_rec->mtu		  = ib_rec->mtu;
+	ibp_rec->traffic_class	  = ib_rec->traffic_class;
+	ibp_rec->pkey		  = ib_rec->pkey;
+	ibp_rec->rate_selector	  = ib_rec->rate_selector;
+	ibp_rec->rate		  = ib_rec->rate;
+	ibp_rec->packet_life_time_selector
+				  = ib_rec->packet_life_time_selector;
+	ibp_rec->packet_life_time = ib_rec->packet_life_time;
+	ibp_rec->sl		  = ib_rec->sl;
+	ibp_rec->flow_label	  = ib_rec->flow_label;
+	ibp_rec->hop_limit	  = ib_rec->hop_limit;
+	ibp_rec->join_state	  = ib_rec->join_state;
+	ibp_rec->proxy_join	  = ib_rec->proxy_join;
+
+queue_work:
+	INIT_WORK(&cb_work->work, ibp_send_callback);
+	queue_work(client->workqueue, &cb_work->work);
+	return 0;
+err2:
+	kfree(cb_work);
+err1:
+	return ret;
+}
+
+int ibp_cmd_sa_join_multicast(struct ibp_client *ibp_client,
+			      struct ibp_msg_header *hdr)
+{
+	struct ib_device			*ib_device;
+	struct ibp_verb_response_msg		*msg;
+	struct ibp_sa_join_multicast_cmd	*cmd;
+	struct ibp_sa_join_multicast_resp	*resp;
+	struct ib_sa_client			*client;
+	struct ib_sa_multicast			*multicast;
+	struct join_mcast_cb_data		*data;
+	size_t					len;
+	int					ret = 0;
+
+	print_trace("in\n");
+
+	cmd = (struct ibp_sa_join_multicast_cmd *) hdr;
+	ib_device = (struct ib_device *) cmd->device;
+	client = (struct ib_sa_client *) cmd->ibp_client;
+	msg = (struct ibp_verb_response_msg *) ibp_client->tx_buf;
+	len = sizeof(*msg);
+
+	data = kzalloc(sizeof(*data), GFP_KERNEL);
+	if (!data) {
+		ret = -ENOMEM;
+		goto send_resp;
+	}
+
+	data->client = ibp_client;
+	data->mcentry = cmd->mcentry;
+
+	mutex_init(&data->lock);
+	mutex_lock(&data->lock);
+
+	down_write(&list_rwsem);
+	list_add(&data->list, &mcast_list);
+	up_write(&list_rwsem);
+
+	multicast = ib_sa_join_multicast(client, ib_device,
+					 cmd->port_num, &cmd->rec,
+					 cmd->comp_mask, GFP_KERNEL,
+					 sa_join_callback, data);
+
+	if (IS_ERR(multicast)) {
+		ret = PTR_ERR(multicast);
+		print_err("ib_sa_join_multicast returned %d\n", ret);
+		mutex_unlock(&data->lock);
+		down_write(&list_rwsem);
+		list_del(&data->list);
+		up_write(&list_rwsem);
+		kfree(data);
+		data = NULL;
+		goto send_resp;
+	}
+	data->mcast = multicast;
+
+	len += sizeof(*resp);
+	resp = (struct ibp_sa_join_multicast_resp *) msg->data;
+
+	resp->ibp_mcast = (u64) multicast;
+
+send_resp:
+	IBP_INIT_RESP(msg, len, RESPONSE, hdr->request, ret);
+
+	ret = ibp_send(ibp_client->ep, msg, len);
+
+	if (data) {
+		data->ret = ret;
+		mutex_unlock(&data->lock);
+	}
+
+	if (ret)
+		print_err("ibp_send returned %d\n", ret);
+
+	return ret;
+}
+
+int ibp_cmd_sa_free_multicast(struct ibp_client *ibp_client,
+			      struct ibp_msg_header *hdr)
+{
+	struct ibp_verb_response_msg		*msg;
+	struct ibp_sa_free_multicast_cmd	*cmd;
+	struct ib_sa_multicast			*multicast;
+	struct join_mcast_cb_data		*data;
+	size_t					len;
+	int					ret = 0;
+
+	print_trace("in\n");
+
+	cmd = (struct ibp_sa_free_multicast_cmd *) hdr;
+	multicast = (struct ib_sa_multicast *) cmd->ibp_mcast;
+	data = (struct join_mcast_cb_data *) multicast->context;
+	msg = (struct ibp_verb_response_msg *) ibp_client->tx_buf;
+	len = sizeof(*msg);
+
+	ib_sa_free_multicast(multicast);
+
+	down_write(&list_rwsem);
+	list_del(&data->list);
+	up_write(&list_rwsem);
+
+	kfree(data);
+
+	IBP_INIT_RESP(msg, len, RESPONSE, hdr->request, ret);
+
+	ret = ibp_send(ibp_client->ep, msg, len);
+	if (ret)
+		print_err("ibp_send returned %d\n", ret);
+
+	return ret;
+}
+
+int ibp_cmd_sa_get_mcmember_rec(struct ibp_client *ibp_client,
+				struct ibp_msg_header *hdr)
+{
+	struct ib_device			*ib_device;
+	struct ibp_verb_response_msg		*msg;
+	struct ibp_sa_get_mcmember_rec_cmd	*cmd;
+	struct ibp_sa_get_mcmember_rec_resp	*resp;
+	struct ib_sa_mcmember_rec		rec;
+	union  ib_gid				mgid;
+	size_t					len;
+	int					ret;
+
+	print_trace("in\n");
+
+	cmd = (struct ibp_sa_get_mcmember_rec_cmd *) hdr;
+	ib_device = (struct ib_device *) cmd->device;
+	msg = (struct ibp_verb_response_msg *) ibp_client->tx_buf;
+	len = sizeof(*msg);
+
+	mgid.global.subnet_prefix = cmd->subnet_prefix;
+	mgid.global.interface_id  = cmd->interface_id;
+
+	ret = ib_sa_get_mcmember_rec(ib_device, cmd->port_num, &mgid, &rec);
+	if (ret) {
+		print_err("ib_sa_get_mcmember_rec returned %d\n", ret);
+		goto send_resp;
+	}
+
+	len += sizeof(*resp);
+	resp = (struct ibp_sa_get_mcmember_rec_resp *) msg->data;
+
+	resp->rec.mgid.global.subnet_prefix
+				= rec.mgid.global.subnet_prefix;
+	resp->rec.mgid.global.interface_id
+				= rec.mgid.global.interface_id;
+	resp->rec.port_gid.global.subnet_prefix
+				= rec.port_gid.global.subnet_prefix;
+	resp->rec.port_gid.global.interface_id
+				= rec.port_gid.global.interface_id;
+	resp->rec.qkey		= rec.qkey;
+	resp->rec.mlid		= rec.mlid;
+	resp->rec.mtu_selector	= rec.mtu_selector;
+	resp->rec.mtu		= rec.mtu;
+	resp->rec.traffic_class	= rec.traffic_class;
+	resp->rec.pkey		= rec.pkey;
+	resp->rec.rate_selector	= rec.rate_selector;
+	resp->rec.rate		= rec.rate;
+	resp->rec.packet_life_time_selector
+				= rec.packet_life_time_selector;
+	resp->rec.packet_life_time
+				= rec.packet_life_time;
+	resp->rec.sl		= rec.sl;
+	resp->rec.flow_label	= rec.flow_label;
+	resp->rec.hop_limit	= rec.hop_limit;
+	resp->rec.scope		= rec.scope;
+	resp->rec.join_state	= rec.join_state;
+	resp->rec.proxy_join	= rec.proxy_join;
+
+send_resp:
+	IBP_INIT_RESP(msg, len, RESPONSE, hdr->request, ret);
+
+	ret = ibp_send(ibp_client->ep, msg, len);
+	if (ret)
+		print_err("ibp_send returned %d\n", ret);
+
+	return ret;
+}
diff -ruN a6/drivers/infiniband/ibp/sa/sa_table.h a7/drivers/infiniband/ibp/sa/sa_table.h
--- a6/drivers/infiniband/ibp/sa/sa_table.h	1969-12-31 16:00:00.000000000 -0800
+++ a7/drivers/infiniband/ibp/sa/sa_table.h	2015-09-10 09:33:35.332958325 -0700
@@ -0,0 +1,131 @@
+/*"
+ * Copyright (c) 2011-2013 Intel Corporation. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *      copyright notice, this list of conditions and the following
+ *      disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *      copyright notice, this list of conditions and the following
+ *      disclaimer in the documentation and/or other materials
+ *      provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#define PATH_REC_FIELD(field) \
+	.struct_offset_bytes = offsetof(struct ib_sa_path_rec, field),     \
+	.struct_size_bytes   = sizeof((struct ib_sa_path_rec *) 0)->field, \
+	.field_name	     = "sa_path_rec:" #field
+
+static const struct ib_field path_rec_table[] = {
+	{ PATH_REC_FIELD(service_id),
+	  .offset_words = 0,
+	  .offset_bits  = 0,
+	  .size_bits    = 64 },
+	{ PATH_REC_FIELD(dgid),
+	  .offset_words = 2,
+	  .offset_bits  = 0,
+	  .size_bits    = 128 },
+	{ PATH_REC_FIELD(sgid),
+	  .offset_words = 6,
+	  .offset_bits  = 0,
+	  .size_bits    = 128 },
+	{ PATH_REC_FIELD(dlid),
+	  .offset_words = 10,
+	  .offset_bits  = 0,
+	  .size_bits    = 16 },
+	{ PATH_REC_FIELD(slid),
+	  .offset_words = 10,
+	  .offset_bits  = 16,
+	  .size_bits    = 16 },
+	{ PATH_REC_FIELD(raw_traffic),
+	  .offset_words = 11,
+	  .offset_bits  = 0,
+	  .size_bits    = 1 },
+	{ RESERVED,
+	  .offset_words = 11,
+	  .offset_bits  = 1,
+	  .size_bits    = 3 },
+	{ PATH_REC_FIELD(flow_label),
+	  .offset_words = 11,
+	  .offset_bits  = 4,
+	  .size_bits    = 20 },
+	{ PATH_REC_FIELD(hop_limit),
+	  .offset_words = 11,
+	  .offset_bits  = 24,
+	  .size_bits    = 8 },
+	{ PATH_REC_FIELD(traffic_class),
+	  .offset_words = 12,
+	  .offset_bits  = 0,
+	  .size_bits    = 8 },
+	{ PATH_REC_FIELD(reversible),
+	  .offset_words = 12,
+	  .offset_bits  = 8,
+	  .size_bits    = 1 },
+	{ PATH_REC_FIELD(numb_path),
+	  .offset_words = 12,
+	  .offset_bits  = 9,
+	  .size_bits    = 7 },
+	{ PATH_REC_FIELD(pkey),
+	  .offset_words = 12,
+	  .offset_bits  = 16,
+	  .size_bits    = 16 },
+	{ PATH_REC_FIELD(qos_class),
+	  .offset_words = 13,
+	  .offset_bits  = 0,
+	  .size_bits    = 12 },
+	{ PATH_REC_FIELD(sl),
+	  .offset_words = 13,
+	  .offset_bits  = 12,
+	  .size_bits    = 4 },
+	{ PATH_REC_FIELD(mtu_selector),
+	  .offset_words = 13,
+	  .offset_bits  = 16,
+	  .size_bits    = 2 },
+	{ PATH_REC_FIELD(mtu),
+	  .offset_words = 13,
+	  .offset_bits  = 18,
+	  .size_bits    = 6 },
+	{ PATH_REC_FIELD(rate_selector),
+	  .offset_words = 13,
+	  .offset_bits  = 24,
+	  .size_bits    = 2 },
+	{ PATH_REC_FIELD(rate),
+	  .offset_words = 13,
+	  .offset_bits  = 26,
+	  .size_bits    = 6 },
+	{ PATH_REC_FIELD(packet_life_time_selector),
+	  .offset_words = 14,
+	  .offset_bits  = 0,
+	  .size_bits    = 2 },
+	{ PATH_REC_FIELD(packet_life_time),
+	  .offset_words = 14,
+	  .offset_bits  = 2,
+	  .size_bits    = 6 },
+	{ PATH_REC_FIELD(preference),
+	  .offset_words = 14,
+	  .offset_bits  = 8,
+	  .size_bits    = 8 },
+	{ RESERVED,
+	  .offset_words = 14,
+	  .offset_bits  = 16,
+	  .size_bits    = 48 },
+};
diff -ruN a6/drivers/infiniband/ibp/sa/server.c a7/drivers/infiniband/ibp/sa/server.c
--- a6/drivers/infiniband/ibp/sa/server.c	1969-12-31 16:00:00.000000000 -0800
+++ a7/drivers/infiniband/ibp/sa/server.c	2015-09-10 09:33:35.332958325 -0700
@@ -0,0 +1,221 @@
+/*
+ * Copyright (c) 2011-2013 Intel Corporation. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *	  copyright notice, this list of conditions and the following
+ *	  disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *	  copyright notice, this list of conditions and the following
+ *	  disclaimer in the documentation and/or other materials
+ *	  provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include "server.h"
+
+MODULE_AUTHOR("Jerrie Coffman");
+MODULE_AUTHOR("Phil Cayton");
+MODULE_AUTHOR("Jay Sternberg");
+MODULE_LICENSE("Dual BSD/GPL");
+MODULE_DESCRIPTION(DRV_DESC);
+MODULE_VERSION(DRV_VERSION);
+
+MODULE_PARAM(port, port, int, IBP_SA_PORT, "Connection port");
+MODULE_PARAM(backlog, backlog, int, 8, "Connection backlog");
+MODULE_PARAM(timeout, timeout, int, 1000, "Listen/Poll time in milliseconds");
+
+#ifdef IBP_DEBUG
+MODULE_PARAM(debug_level, debug_level, int, 0, "Debug: 0-none, 1-some, 2-all");
+#endif
+
+struct rw_semaphore				list_rwsem;
+
+LIST_HEAD(client_list);
+
+static struct task_struct			*listen_thread;
+
+static struct ibp_client *ibp_create_client(scif_epd_t ep, uint16_t node)
+{
+	struct ibp_client		*client;
+	int				ret = -ENOMEM;
+
+	client = kzalloc(sizeof(*client), GFP_KERNEL);
+	if (!client) {
+		print_err("kzalloc failed\n");
+		return ERR_PTR(ret);
+	}
+
+	client->ep = ep;
+
+	client->rx_buf = (void *)__get_free_page(GFP_KERNEL);
+	if (!client->rx_buf) {
+		print_err("__get_free_page rx_buf failed\n");
+		goto err0;
+	}
+
+	client->tx_buf = (void *)__get_free_page(GFP_KERNEL);
+	if (!client->tx_buf) {
+		print_err("__get_free_page tx_buf failed\n");
+		goto err1;
+	}
+
+	client->workqueue = create_singlethread_workqueue(DRV_NAME);
+	if (!client->workqueue) {
+		print_err("create_singlethread_workqueue failed\n");
+		goto err2;
+	}
+
+	down_write(&list_rwsem);
+	list_add(&client->list, &client_list);
+	up_write(&list_rwsem);
+
+	client->ibp_sa_client_thread = kthread_run(ibp_process_recvs,
+						   client, DRV_NAME);
+	if (!client->ibp_sa_client_thread) {
+		print_err("create client thread failed\n");
+		goto err3;
+	}
+
+	return client;
+err3:
+	down_write(&list_rwsem);
+	list_del(&client->list);
+	up_write(&list_rwsem);
+
+	destroy_workqueue(client->workqueue);
+err2:
+	free_page((uintptr_t)client->tx_buf);
+err1:
+	free_page((uintptr_t)client->rx_buf);
+err0:
+	kfree(client);
+	return ERR_PTR(ret);
+}
+
+static int ibp_sa_listen(void *data)
+{
+	struct ibp_client		*client;
+	struct scif_pollepd		listen;
+	struct scif_portID		peer;
+	scif_epd_t			ep;
+	int				ret;
+
+	listen.epd = scif_open();
+	if (IS_NULL_OR_ERR(listen.epd)) {
+		print_err("scif_open failed\n");
+		ret = -EIO;
+		goto err0;
+	}
+	listen.events = POLLIN;
+
+	ret = scif_bind(listen.epd, port);
+	if (ret < 0) {
+		print_err("scif_bind returned %d\n", ret);
+		goto err1;
+	}
+
+	ret = scif_listen(listen.epd, backlog);
+	if (ret) {
+		print_err("scif_listen returned %d\n", ret);
+		goto err1;
+	}
+
+	while (!kthread_should_stop()) {
+
+		schedule();
+
+		ret = scif_poll(&listen, 1, timeout);
+		if (ret == 0)	/* timeout */
+			continue;
+		if (ret < 0) {
+			print_err("scif_poll revents 0x%x\n", listen.revents);
+			continue;
+		}
+
+		ret = scif_accept(listen.epd, &peer, &ep, 0);
+		if (ret) {
+			print_err("scif_accept returned %d\n", ret);
+			continue;
+		}
+
+		print_dbg("accepted node %d port %d\n", peer.node, peer.port);
+
+		client = ibp_create_client(ep, peer.node);
+		if (IS_ERR(client)) {
+			ret = PTR_ERR(client);
+			print_err("ibp_create_client returned %d\n", ret);
+			scif_close(ep);
+		}
+	}
+err1:
+	scif_close(listen.epd);
+err0:
+	return ret;
+}
+
+static int __init ibp_sa_server_init(void)
+{
+	int				ret = 0;
+
+	print_info(DRV_SIGNON);
+
+	init_rwsem(&list_rwsem);
+
+	/* Start a thread for inbound connections. */
+	listen_thread = kthread_run(ibp_sa_listen, NULL, DRV_NAME);
+	if (IS_NULL_OR_ERR(listen_thread)) {
+		ret = PTR_ERR(listen_thread);
+		print_err("kthread_run returned %d\n", ret);
+	}
+
+	return ret;
+}
+
+static void __exit ibp_sa_server_exit(void)
+{
+	struct ibp_client		*client, *next;
+	struct completion		done;
+
+	kthread_stop(listen_thread);
+
+	down_write(&list_rwsem);
+	list_for_each_entry_safe(client, next, &client_list, list) {
+		init_completion(&done);
+		client->done = &done;
+
+		/* Close scif ep to unblock the client thread scif_recv */
+		scif_close(client->ep);
+
+		up_write(&list_rwsem);
+
+		/* Wait for client thread to finish */
+		wait_for_completion(&done);
+
+		down_write(&list_rwsem);
+	}
+	up_write(&list_rwsem);
+
+	print_info(DRV_DESC " unloaded\n");
+}
+
+module_init(ibp_sa_server_init);
+module_exit(ibp_sa_server_exit);
diff -ruN a6/drivers/infiniband/ibp/sa/server.h a7/drivers/infiniband/ibp/sa/server.h
--- a6/drivers/infiniband/ibp/sa/server.h	1969-12-31 16:00:00.000000000 -0800
+++ a7/drivers/infiniband/ibp/sa/server.h	2015-09-10 09:33:35.332958325 -0700
@@ -0,0 +1,172 @@
+/*
+ * Copyright (c) 2011-2013 Intel Corporation. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *	- Redistributions of source code must retain the above
+ *	  copyright notice, this list of conditions and the following
+ *	  disclaimer.
+ *
+ *	- Redistributions in binary form must reproduce the above
+ *	  copyright notice, this list of conditions and the following
+ *	  disclaimer in the documentation and/or other materials
+ *	  provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#ifndef SERVER_H
+#define SERVER_H
+
+#include <linux/fs.h>
+#include <linux/cdev.h>
+#include <linux/anon_inodes.h>
+#include <rdma/ib_umem.h>
+#include <rdma/ib_cache.h>
+#include "ibp-abi.h"
+#include "sa_ibp_abi.h"
+#include "common.h"
+
+#define DRV_ROLE	"Server"
+#define DRV_NAME	"ibp_sa_server"
+
+extern int timeout;
+extern struct rw_semaphore	list_rwsem;
+extern struct list_head		client_list;
+extern struct list_head		sa_entry_list;
+extern struct list_head		query_list;
+extern struct list_head		mcast_list;
+
+struct ib_sa_sm_ah {
+	struct ib_ah		*ah;
+	struct kref		ref;
+	u16			pkey_index;
+	u8			src_path_mask;
+};
+
+struct ib_sa_port {
+	struct ib_mad_agent	*agent;
+	struct ib_mad_agent	*notice_agent;
+	struct ib_sa_sm_ah	*sm_ah;
+	struct work_struct	update_task;
+	spinlock_t		ah_lock;
+	u8			port_num;
+	struct ib_device	*device;
+};
+
+struct ib_sa_device {
+	int			start_port, end_port;
+	struct ib_event_handler	event_handler;
+	struct ib_sa_port	port[0];
+};
+
+struct ibp_client {
+	struct list_head	list;
+	scif_epd_t		ep;
+	void			*rx_buf;
+	void			*tx_buf;
+	struct completion	*done;
+	struct workqueue_struct	*workqueue;
+	struct task_struct	*ibp_sa_client_thread;
+};
+
+struct sa_entry {
+	struct list_head	list;
+	struct ib_sa_client	ib_client;
+	struct ibp_client	*client;
+};
+
+struct sa_query_entry {
+	struct list_head	list;
+	int			id;
+	struct ibp_client	*ibp_client;
+	struct ib_sa_client     *sa_client;
+	struct ib_sa_query	*query;
+};
+
+struct path_rec_cb_data {
+	struct mutex		lock;
+	int			ret;
+	struct sa_query_entry	*entry;
+	u64			ibp_entry;
+	u64			ibp_query;
+};
+
+struct join_mcast_cb_data {
+	struct mutex		lock;
+	int			ret;
+	struct ibp_client       *client;
+	struct ib_sa_multicast	*mcast;
+	struct list_head	list;
+	u64			entry;
+	u64			mcentry;
+};
+
+struct generic_cb_data {
+	struct mutex		lock;
+	int			ret;
+};
+
+struct callback_work {
+	struct work_struct      work;
+	struct ibp_client       *client;
+	struct generic_cb_data	*data;
+	int			length;
+	struct callback_msg	msg;
+};
+
+#define IBP_INIT_MSG(msg, size, op)				\
+	do {							\
+		(msg)->header.opcode	= IBP_##op;		\
+		(msg)->header.length	= (size);		\
+		(msg)->header.status	= 0;			\
+		(msg)->header.reserved	= 0;			\
+		(msg)->header.request	= 0;			\
+	} while (0)
+
+#define IBP_INIT_RESP(resp, size, op, req, stat)		\
+	do {							\
+		(resp)->header.opcode	= IBP_##op;		\
+		(resp)->header.length	= (size);		\
+		(resp)->header.status	= (stat);		\
+		(resp)->header.reserved	= 0;			\
+		(resp)->header.request	= (req);		\
+	} while (0)
+
+int ibp_process_recvs(void *p);
+
+int ibp_cmd_sa_path_rec_get(struct ibp_client *client,
+			    struct ibp_msg_header *hdr);
+int ibp_cmd_sa_register_client(struct ibp_client *client,
+			       struct ibp_msg_header *hdr);
+int ibp_cmd_sa_unregister_client(struct ibp_client *client,
+				 struct ibp_msg_header *hdr);
+int ibp_cmd_sa_cancel_query(struct ibp_client *client,
+			    struct ibp_msg_header *hdr);
+int ibp_cmd_init_ah_from_path(struct ibp_client *client,
+			      struct ibp_msg_header *hdr);
+int ibp_cmd_init_ah_from_mcmember(struct ibp_client *client,
+				  struct ibp_msg_header *hdr);
+int ibp_cmd_sa_join_multicast(struct ibp_client *client,
+			      struct ibp_msg_header *hdr);
+int ibp_cmd_sa_free_multicast(struct ibp_client *client,
+			      struct ibp_msg_header *hdr);
+int ibp_cmd_sa_get_mcmember_rec(struct ibp_client *client,
+				struct ibp_msg_header *hdr);
+
+#endif /* SERVER_H */
diff -ruN a6/drivers/infiniband/ibp/sa/server_msg.c a7/drivers/infiniband/ibp/sa/server_msg.c
--- a6/drivers/infiniband/ibp/sa/server_msg.c	1969-12-31 16:00:00.000000000 -0800
+++ a7/drivers/infiniband/ibp/sa/server_msg.c	2015-09-10 09:33:35.332958325 -0700
@@ -0,0 +1,185 @@
+/*
+ * Copyright (c) 2011-2013 Intel Corporation. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *	- Redistributions of source code must retain the above
+ *	  copyright notice, this list of conditions and the following
+ *	  disclaimer.
+ *
+ *	- Redistributions in binary form must reproduce the above
+ *	  copyright notice, this list of conditions and the following
+ *	  disclaimer in the documentation and/or other materials
+ *	  provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <linux/delay.h>
+
+#include "server.h"
+#include "sa_ibp_abi.h"
+
+int ibp_send(scif_epd_t ep, void *buf, size_t len)
+{
+	int				ret;
+
+	while (len) {
+		ret = scif_send(ep, buf, (uint32_t)len, SCIF_SEND_BLOCK);
+		if (ret < 0) {
+			print_dbg("scif_send returned %d\n", ret);
+			return ret;
+		}
+		buf += ret;
+		len -= ret;
+	}
+
+	return 0;
+}
+
+int ibp_recv(scif_epd_t ep, void *buf, size_t len)
+{
+	int				ret;
+
+	while (len) {
+		ret = scif_recv(ep, buf, (uint32_t)len, SCIF_RECV_BLOCK);
+		if (ret < 0) {
+			print_dbg("scif_recv returned %d\n", ret);
+			return ret;
+		}
+		buf += ret;
+		len -= ret;
+	}
+
+	return 0;
+}
+
+static int
+ibp_cmd_bad_request(struct ibp_client *client, struct ibp_msg_header *hdr)
+{
+	struct ibp_verb_response_msg	*msg;
+	size_t				len;
+	int				status = -EBADRQC;
+
+	msg = (struct ibp_verb_response_msg *) client->tx_buf;
+	len = sizeof(*msg);
+
+	print_dbg("opcode 0x%x\n", hdr->opcode);
+
+	IBP_INIT_RESP(msg, len, RESPONSE, hdr->request, status);
+	return ibp_send(client->ep, msg, len);
+}
+
+static void
+ibp_sa_destroy_client(struct ibp_client *client)
+{
+	struct join_mcast_cb_data	*mcast, *next_mcast;
+	struct sa_query_entry		*query, *next_query;
+	struct sa_entry			*sa, *next_sa;
+
+	down_write(&list_rwsem);
+	list_del(&client->list);
+	list_for_each_entry_safe(mcast, next_mcast, &mcast_list, list)
+		if (mcast->client == client) {
+			ib_sa_free_multicast(mcast->mcast);
+			list_del(&mcast->list);
+			kfree(mcast);
+		}
+	list_for_each_entry_safe(query, next_query, &query_list, list)
+		if (query->ibp_client == client) {
+			ib_sa_cancel_query(query->id, query->query);
+			list_del(&query->list);
+			kfree(query);
+		}
+	list_for_each_entry_safe(sa, next_sa, &sa_entry_list, list)
+		if (sa->client == client) {
+			ib_sa_unregister_client(&sa->ib_client);
+			list_del(&sa->list);
+			kfree(sa);
+		}
+	up_write(&list_rwsem);
+
+	destroy_workqueue(client->workqueue);
+
+	free_page((uintptr_t)client->tx_buf);
+	free_page((uintptr_t)client->rx_buf);
+
+	if (client->done)
+		complete(client->done);
+	else
+		scif_close(client->ep);
+
+	kfree(client);
+}
+
+static int
+(*ibp_msg_table[])(struct ibp_client *c, struct ibp_msg_header *h) = {
+	[IBP_SA_PATH_REC_GET]		= ibp_cmd_sa_path_rec_get,
+	[IBP_SA_REGISTER_CLIENT]	= ibp_cmd_sa_register_client,
+	[IBP_SA_UNREGISTER_CLIENT]	= ibp_cmd_sa_unregister_client,
+	[IBP_SA_CANCEL_QUERY]		= ibp_cmd_sa_cancel_query,
+	[IBP_INIT_AH_FROM_PATH]		= ibp_cmd_init_ah_from_path,
+	[IBP_INIT_AH_FROM_MCMEMBER]	= ibp_cmd_init_ah_from_mcmember,
+	[IBP_SA_JOIN_MCAST]		= ibp_cmd_sa_join_multicast,
+	[IBP_SA_FREE_MCAST]		= ibp_cmd_sa_free_multicast,
+	[IBP_SA_GET_MCMEMBER_REC]	= ibp_cmd_sa_get_mcmember_rec,
+};
+
+int ibp_process_recvs(void *p)
+{
+	struct ibp_client		*client;
+	struct ibp_msg_header		*hdr;
+	int				ret;
+
+	client = (struct ibp_client *) p;
+	hdr = (struct ibp_msg_header *) client->rx_buf;
+
+	for (;;) {
+		ret = ibp_recv(client->ep, hdr, sizeof(*hdr));
+		if (ret)
+			break;
+
+		if (hdr->length > MAX_MSG_SIZE) {
+			print_err("message too large, len %u max %lu\n",
+				  hdr->length, MAX_MSG_SIZE);
+			ret = -EMSGSIZE;
+			break;
+		}
+
+		if (hdr->length > sizeof(*hdr)) {
+			ret = ibp_recv(client->ep, hdr->data,
+				       hdr->length - sizeof(*hdr));
+			if (ret)
+				break;
+		}
+
+		if ((hdr->opcode >= ARRAY_SIZE(ibp_msg_table)) ||
+		    !ibp_msg_table[hdr->opcode]) {
+			ibp_cmd_bad_request(client, hdr);
+			continue;
+		}
+
+		ret = ibp_msg_table[hdr->opcode](client, hdr);
+		if (ret)
+			break;
+	}
+
+	ibp_sa_destroy_client(client);
+
+	return ret;
+}
